{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person Re-ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-10T10:17:34.803499Z",
     "iopub.status.busy": "2026-02-10T10:17:34.802815Z",
     "iopub.status.idle": "2026-02-10T10:17:41.560184Z",
     "shell.execute_reply": "2026-02-10T10:17:41.559396Z",
     "shell.execute_reply.started": "2026-02-10T10:17:34.803457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:17:51.805827Z",
     "iopub.status.busy": "2026-02-10T10:17:51.804987Z",
     "iopub.status.idle": "2026-02-10T10:17:56.417254Z",
     "shell.execute_reply": "2026-02-10T10:17:56.416517Z",
     "shell.execute_reply.started": "2026-02-10T10:17:51.805781Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtommaso-perniola\u001b[0m (\u001b[33munibo-ai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import wandb\n",
    "\n",
    "!pip install -q wandb\n",
    "!wandb login\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"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\"\n",
    "#wandb.login(key=os.environ[\"WANDB_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:18:04.148242Z",
     "iopub.status.busy": "2026-02-10T10:18:04.147648Z",
     "iopub.status.idle": "2026-02-10T10:18:04.400185Z",
     "shell.execute_reply": "2026-02-10T10:18:04.399437Z",
     "shell.execute_reply.started": "2026-02-10T10:18:04.148209Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good, a GPU is available.\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "  print(\"All good, a GPU is available.\")\n",
    "  device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "  print(\"Please set GPU via Edit -> Notebook Settings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility & deterministic mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:18:08.289415Z",
     "iopub.status.busy": "2026-02-10T10:18:08.289121Z",
     "iopub.status.idle": "2026-02-10T10:18:08.300468Z",
     "shell.execute_reply": "2026-02-10T10:18:08.299773Z",
     "shell.execute_reply.started": "2026-02-10T10:18:08.289386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed = 42\n",
    "fix_random(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:18:32.952752Z",
     "iopub.status.busy": "2026-02-10T10:18:32.952422Z",
     "iopub.status.idle": "2026-02-10T10:18:32.981581Z",
     "shell.execute_reply": "2026-02-10T10:18:32.980701Z",
     "shell.execute_reply.started": "2026-02-10T10:18:32.952723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Dict, Any, List, Set\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import functional as FT\n",
    "\n",
    "class PRW_dataset(Dataset):\n",
    "    @staticmethod\n",
    "    def _load_mat_list(mat_path: Path, key: str):\n",
    "        d = scipy.io.loadmat(mat_path)\n",
    "        if key not in d:\n",
    "            raise KeyError(f\"Key '{key}' not found in {mat_path}. Keys: {list(d.keys())}\")\n",
    "        arr = d[key]\n",
    "        return [x[0].item() for x in arr]  # e.g. 'c1s1_000151'\n",
    "\n",
    "    @classmethod\n",
    "    def find_train_test_data(cls, frames_path: Path, train_frames_path: Path, test_frames_path: Path):\n",
    "        frames = [p.stem for p in sorted(frames_path.glob(\"*.jpg\"))]  # 'c1s1_000151'\n",
    "        frames_set = set(frames)\n",
    "\n",
    "        train_names = cls._load_mat_list(train_frames_path, \"img_index_train\")\n",
    "        test_names  = cls._load_mat_list(test_frames_path,  \"img_index_test\")\n",
    "\n",
    "        train_set = set(train_names)\n",
    "        test_set  = set(test_names)\n",
    "\n",
    "        list_train_frames = [f for f in frames if f in train_set]\n",
    "        list_test_frames  = [f for f in frames if f in test_set]\n",
    "\n",
    "        if len(list_train_frames) != len(train_names):\n",
    "            missing = [n for n in train_names if n not in frames_set]\n",
    "            raise AssertionError(f\"Train mismatch: matched={len(list_train_frames)} vs mat={len(train_names)}. Missing (first 10): {missing[:10]}\")\n",
    "        if len(list_test_frames) != len(test_names):\n",
    "            missing = [n for n in test_names if n not in frames_set]\n",
    "            raise AssertionError(f\"Test mismatch: matched={len(list_test_frames)} vs mat={len(test_names)}. Missing (first 10): {missing[:10]}\")\n",
    "\n",
    "        return list_train_frames, list_test_frames\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        frames_path: Path,\n",
    "        path_annotations: Path,\n",
    "        train_frames_path: Path,\n",
    "        test_frames_path: Path,\n",
    "        split: str = \"train\",\n",
    "        img_transform=None,\n",
    "        filter_invalid_ids: bool = False,   # if True: keep only ids > 0\n",
    "        allowed_pids: Optional[Set[int]] = None,  # keep only these IDs (positive ids)\n",
    "        drop_empty: bool = False,           # if True: drop images that have zero boxes after filtering\n",
    "    ):\n",
    "        self.img_transform = img_transform\n",
    "        self.filter_invalid_ids = filter_invalid_ids\n",
    "        self.allowed_pids = allowed_pids\n",
    "        self.drop_empty = drop_empty\n",
    "\n",
    "        split = split.lower()\n",
    "        if split not in {\"train\", \"test\"}:\n",
    "            raise ValueError(\"split must be 'train' or 'test'\")\n",
    "\n",
    "        train_frames, test_frames = self.find_train_test_data(frames_path, train_frames_path, test_frames_path)\n",
    "        allowed_frames = set(train_frames if split == \"train\" else test_frames)\n",
    "\n",
    "        self.images = [p for p in sorted(frames_path.glob(\"*.jpg\")) if p.stem in allowed_frames]\n",
    "\n",
    "        # annotations are named like: c1s1_002876.jpg.mat\n",
    "        annots = {p.stem: p for p in path_annotations.rglob(\"*.mat\")}  # key: 'c1s1_002876.jpg'\n",
    "\n",
    "        # building tuples (img, bbox)\n",
    "        pairs = []\n",
    "        for img_path in self.images:\n",
    "            ann_key = img_path.name  # e.g. 'c1s1_002876.jpg'\n",
    "            ann_path = annots.get(ann_key)\n",
    "            if ann_path is None:\n",
    "                raise RuntimeError(f\"Missing annotation for frame {img_path.name}\")\n",
    "            pairs.append((img_path, ann_path))\n",
    "\n",
    "        # pre-loading .mat files for bboxes\n",
    "        self.box_cache = {}\n",
    "        for img_path, ann_path in pairs:\n",
    "            mat = scipy.io.loadmat(ann_path)\n",
    "            arr = mat.get(\"box_new\", mat.get(\"anno_file\", mat.get(\"box\", None)))\n",
    "\n",
    "            if arr is None:\n",
    "                boxes = np.zeros((0, 4), np.float32)\n",
    "                ids   = np.zeros((0,), np.int64)\n",
    "            else:\n",
    "                arr = np.asarray(arr).reshape(-1, 5)\n",
    "                ids = arr[:, 0].astype(np.int64)\n",
    "                x = arr[:, 1].astype(np.float32)\n",
    "                y = arr[:, 2].astype(np.float32)\n",
    "                w = arr[:, 3].astype(np.float32)\n",
    "                h = arr[:, 4].astype(np.float32)\n",
    "                boxes = np.stack([x, y, x + w, y + h], axis=1).astype(np.float32)\n",
    "\n",
    "            self.box_cache[str(ann_path)] = (boxes, ids)\n",
    "\n",
    "        # Now build self.pairs, optionally filtering boxes by allowed IDs and dropping empty images\n",
    "        self.pairs = []\n",
    "        for img_path, ann_path in pairs:\n",
    "            boxes_np, ids_np = self.box_cache[str(ann_path)]\n",
    "\n",
    "            # filter invalid ids (e.g. -2 distractors, 0 background)\n",
    "            if self.filter_invalid_ids:\n",
    "                keep = ids_np > 0\n",
    "                boxes_np = boxes_np[keep]\n",
    "                ids_np = ids_np[keep]\n",
    "\n",
    "            # filter by allowed_pids (ID-disjoint train/val)\n",
    "            if self.allowed_pids is not None:\n",
    "                keep = np.isin(ids_np, np.array(list(self.allowed_pids), dtype=np.int64))\n",
    "                boxes_np = boxes_np[keep]\n",
    "                ids_np = ids_np[keep]\n",
    "\n",
    "            # update cache (filtered view)\n",
    "            self.box_cache[str(ann_path)] = (boxes_np, ids_np)\n",
    "\n",
    "            if self.drop_empty and boxes_np.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            self.pairs.append((img_path, ann_path))\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "        img_path, ann_path = self.pairs[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        boxes_np, ids_np = self.box_cache[str(ann_path)]\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": torch.as_tensor(boxes_np, dtype=torch.float32),\n",
    "            \"labels\": torch.ones((boxes_np.shape[0],), dtype=torch.int64),\n",
    "            \"image_id\": torch.tensor([idx], dtype=torch.int64),\n",
    "            \"person_id\": torch.as_tensor(ids_np, dtype=torch.int64),\n",
    "        }\n",
    "\n",
    "        if self.img_transform is not None:\n",
    "            img = self.img_transform(img)\n",
    "        if not torch.is_tensor(img):\n",
    "            img = FT.to_tensor(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def unique_positive_pids(self) -> Set[int]:\n",
    "        \"\"\"Collect unique IDs > 0 present in this dataset view (after any filtering).\"\"\"\n",
    "        s = set()\n",
    "        for _, ann_path in self.pairs:\n",
    "            _, ids_np = self.box_cache[str(ann_path)]\n",
    "            for pid in ids_np.tolist():\n",
    "                if pid > 0:\n",
    "                    s.add(int(pid))\n",
    "        return s\n",
    "\n",
    "\n",
    "def make_id_disjoint_train_val(\n",
    "    trainval_ds: PRW_dataset,\n",
    "    val_ratio: float = 0.15,\n",
    "    seed: int = 42,\n",
    "    ensure_disjoint_from_test: Optional[PRW_dataset] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Split TRAIN IDs into train/val (ID-disjoint).\n",
    "    Optionally remove IDs that appear in test split too (strict disjoint across train/val/test).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    train_ids = sorted(list(trainval_ds.unique_positive_pids()))\n",
    "\n",
    "    if ensure_disjoint_from_test is not None:\n",
    "        test_ids = ensure_disjoint_from_test.unique_positive_pids()\n",
    "        # remove any overlap with test (strict setting)\n",
    "        train_ids = [pid for pid in train_ids if pid not in test_ids]\n",
    "\n",
    "    train_ids = np.array(train_ids, dtype=np.int64)\n",
    "    rng.shuffle(train_ids)\n",
    "\n",
    "    n_val = int(round(len(train_ids) * val_ratio))\n",
    "    val_ids = set(map(int, train_ids[:n_val].tolist()))\n",
    "    trn_ids = set(map(int, train_ids[n_val:].tolist()))\n",
    "\n",
    "    # sanity: disjoint\n",
    "    assert val_ids.isdisjoint(trn_ids), \"Train/Val ID sets overlap! Bug in split.\"\n",
    "    if ensure_disjoint_from_test is not None:\n",
    "        test_ids = ensure_disjoint_from_test.unique_positive_pids()\n",
    "        assert val_ids.isdisjoint(test_ids), \"Val overlaps with test IDs!\"\n",
    "        assert trn_ids.isdisjoint(test_ids), \"Train overlaps with test IDs!\"\n",
    "\n",
    "    # build dataset views\n",
    "    train_ds = PRW_dataset(\n",
    "        frames_path=trainval_ds.images[0].parent,  # hack-safe? better pass original path you used\n",
    "        path_annotations=Path(str(trainval_ds.pairs[0][1])).parents[0],  # not ideal; see note below\n",
    "        train_frames_path=None,  # NOTE: don't use this constructor path hack in production\n",
    "        test_frames_path=None,\n",
    "    )\n",
    "    raise NotImplementedError(\"See the note below for clean construction.\")\n",
    "\n",
    "\n",
    "def build_train_val_views(\n",
    "    frames_path: Path,\n",
    "    path_annotations: Path,\n",
    "    train_frames_mat: Path,\n",
    "    test_frames_mat: Path,\n",
    "    img_transform=None,\n",
    "    filter_invalid_ids: bool = True,\n",
    "    val_ratio: float = 0.15,\n",
    "    seed: int = 42,\n",
    "    strict_disjoint_from_test: bool = True,\n",
    "):\n",
    "    # base datasets\n",
    "    trainval = PRW_dataset(\n",
    "        frames_path=frames_path,\n",
    "        path_annotations=path_annotations,\n",
    "        train_frames_path=train_frames_mat,\n",
    "        test_frames_path=test_frames_mat,\n",
    "        split=\"train\",\n",
    "        img_transform=img_transform,\n",
    "        filter_invalid_ids=filter_invalid_ids,\n",
    "        allowed_pids=None,\n",
    "        drop_empty=False,\n",
    "    )\n",
    "\n",
    "    test = PRW_dataset(\n",
    "        frames_path=frames_path,\n",
    "        path_annotations=path_annotations,\n",
    "        train_frames_path=train_frames_mat,\n",
    "        test_frames_path=test_frames_mat,\n",
    "        split=\"test\",\n",
    "        img_transform=img_transform,\n",
    "        filter_invalid_ids=filter_invalid_ids,\n",
    "        allowed_pids=None,\n",
    "        drop_empty=False,\n",
    "    )\n",
    "\n",
    "    train_ids = sorted(list(trainval.unique_positive_pids()))\n",
    "    test_ids = test.unique_positive_pids()\n",
    "\n",
    "    if strict_disjoint_from_test:\n",
    "        train_ids = [pid for pid in train_ids if pid not in test_ids]\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    train_ids = np.array(train_ids, dtype=np.int64)\n",
    "    rng.shuffle(train_ids)\n",
    "\n",
    "    n_val = int(round(len(train_ids) * val_ratio))\n",
    "    val_ids = set(map(int, train_ids[:n_val].tolist()))\n",
    "    trn_ids = set(map(int, train_ids[n_val:].tolist()))\n",
    "\n",
    "    assert val_ids.isdisjoint(trn_ids)\n",
    "\n",
    "    if strict_disjoint_from_test:\n",
    "        assert val_ids.isdisjoint(test_ids)\n",
    "        assert trn_ids.isdisjoint(test_ids)\n",
    "\n",
    "    # views: keep only boxes whose person_id is in the allowed set, drop images with no boxes\n",
    "    train_view = PRW_dataset(\n",
    "        frames_path=frames_path,\n",
    "        path_annotations=path_annotations,\n",
    "        train_frames_path=train_frames_mat,\n",
    "        test_frames_path=test_frames_mat,\n",
    "        split=\"train\",\n",
    "        img_transform=img_transform,\n",
    "        filter_invalid_ids=filter_invalid_ids,\n",
    "        allowed_pids=trn_ids,\n",
    "        drop_empty=True,\n",
    "    )\n",
    "\n",
    "    val_view = PRW_dataset(\n",
    "        frames_path=frames_path,\n",
    "        path_annotations=path_annotations,\n",
    "        train_frames_path=train_frames_mat,\n",
    "        test_frames_path=test_frames_mat,\n",
    "        split=\"train\",\n",
    "        img_transform=img_transform,\n",
    "        filter_invalid_ids=filter_invalid_ids,\n",
    "        allowed_pids=val_ids,\n",
    "        drop_empty=True,\n",
    "    )\n",
    "\n",
    "    return train_view, val_view, test, trn_ids, val_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:18:51.495809Z",
     "iopub.status.busy": "2026-02-10T10:18:51.495501Z",
     "iopub.status.idle": "2026-02-10T10:18:51.500020Z",
     "shell.execute_reply": "2026-02-10T10:18:51.499212Z",
     "shell.execute_reply.started": "2026-02-10T10:18:51.495776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "path_imgs = Path(\"/kaggle/input/prw-person-re-identification-in-the-wild/frames\")\n",
    "path_annot = Path(\"/kaggle/input/prw-person-re-identification-in-the-wild/annotations\")\n",
    "train_frames_mat = Path(\"/kaggle/input/prw-person-re-identification-in-the-wild/frame_train.mat\")\n",
    "test_frames_mat = Path(\"/kaggle/input/prw-person-re-identification-in-the-wild/frame_test.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T11:56:19.804747Z",
     "iopub.status.busy": "2026-02-10T11:56:19.804098Z",
     "iopub.status.idle": "2026-02-10T11:56:58.641283Z",
     "shell.execute_reply": "2026-02-10T11:56:58.640666Z",
     "shell.execute_reply.started": "2026-02-10T11:56:19.804713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DET train images: 5704\n",
      "ReID train images: 4863 ReID val images: 1551\n",
      "Test images: 6112\n",
      "ReID Train IDs: 331 ReID Val IDs: 58\n"
     ]
    }
   ],
   "source": [
    "# 1) FULL train for detection (100% frame_train.mat, no ID filtering)\n",
    "det_train_ds = PRW_dataset(\n",
    "    frames_path=path_imgs,\n",
    "    path_annotations=path_annot,\n",
    "    train_frames_path=train_frames_mat,\n",
    "    test_frames_path=test_frames_mat,\n",
    "    split=\"train\",\n",
    "    img_transform=None,\n",
    "    filter_invalid_ids=False,   # detection: keep -2\n",
    "    allowed_pids=None,          \n",
    "    drop_empty=False,\n",
    ")\n",
    "\n",
    "# 2) ReID train/val + test (ID-disjoint)\n",
    "train_view, val_view, test_ds, train_ids, val_ids = build_train_val_views(\n",
    "    frames_path=path_imgs,\n",
    "    path_annotations=path_annot,\n",
    "    train_frames_mat=train_frames_mat,\n",
    "    test_frames_mat=test_frames_mat,\n",
    "    img_transform=None,\n",
    "    filter_invalid_ids=True,    # ignore -2 for re-id\n",
    "    val_ratio=0.15,\n",
    "    seed=42,\n",
    "    strict_disjoint_from_test=True,\n",
    ")\n",
    "\n",
    "print(\"DET train images:\", len(det_train_ds))\n",
    "print(\"ReID train images:\", len(train_view), \"ReID val images:\", len(val_view))\n",
    "print(\"Test images:\", len(test_ds))\n",
    "print(\"ReID Train IDs:\", len(train_ids), \"ReID Val IDs:\", len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T11:56:58.642676Z",
     "iopub.status.busy": "2026-02-10T11:56:58.642409Z",
     "iopub.status.idle": "2026-02-10T11:56:58.647659Z",
     "shell.execute_reply": "2026-02-10T11:56:58.646917Z",
     "shell.execute_reply.started": "2026-02-10T11:56:58.642655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # https://discuss.pytorch.org/t/dataloader-gives-stack-expects-each-tensor-to-be-equal-size-due-to-different-image-has-different-objects-number/91941/4\n",
    "    return tuple(zip(*batch)) #unpacks the batch and groups the individual elements together based on their position.\n",
    "    #this is useful for datasets where each item contains multiple outputs (e.g., image and targets) of varying sizes.\n",
    "\n",
    "num_workers = 4\n",
    "batch_size = 2\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "    det_train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "data_loader_test = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed strategy: Two-step person search\n",
    "We will treat detection and re-id as two distinct tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting with Faster-RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:19:37.791049Z",
     "iopub.status.busy": "2026-02-10T10:19:37.790726Z",
     "iopub.status.idle": "2026-02-10T10:19:37.821132Z",
     "shell.execute_reply": "2026-02-10T10:19:37.820582Z",
     "shell.execute_reply.started": "2026-02-10T10:19:37.791022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load predictions\n",
    "with open(\"/kaggle/input/detection-weights/test_preds.pkl\", \"rb\") as fp:\n",
    "    test_detections = pickle.load(fp)\n",
    "\n",
    "# load predictions\n",
    "with open(\"/kaggle/input/detection-weights/train_preds.pkl\", \"rb\") as fp:\n",
    "    train_detections = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:19:42.428865Z",
     "iopub.status.busy": "2026-02-10T10:19:42.428554Z",
     "iopub.status.idle": "2026-02-10T10:19:42.437743Z",
     "shell.execute_reply": "2026-02-10T10:19:42.436992Z",
     "shell.execute_reply.started": "2026-02-10T10:19:42.428838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test detections: 6112\n",
      "Per-img\n",
      "- min num_det: 1\n",
      "- mean num_det: 5\n",
      "- max num_det: 23\n",
      "\n",
      "Total val detections: 5704\n",
      "Per-img\n",
      "- min num_det: 1\n",
      "- mean num_det: 3\n",
      "- max num_det: 14\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "num_detections = [test_detections[i].shape[0] for i in range(len(test_detections))]\n",
    "print(f\"Total test detections: {len(test_detections)}\")  # should be len(test_ds)\n",
    "print(\"Per-img\")\n",
    "print(\"- min num_det:\", min(num_detections))\n",
    "print(\"- mean num_det:\", int(sum(num_detections) / len(num_detections)))\n",
    "print(\"- max num_det:\", max(num_detections))\n",
    "\n",
    "# sanity check\n",
    "num_detections = [train_detections[i].shape[0] for i in range(len(train_detections))]\n",
    "print(f\"\\nTotal val detections: {len(train_detections)}\")  # should be len(test_ds)\n",
    "print(\"Per-img\")\n",
    "print(\"- min num_det:\", min(num_detections))\n",
    "print(\"- mean num_det:\", int(sum(num_detections) / len(num_detections)))\n",
    "print(\"- max num_det:\", max(num_detections))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-IDentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:19:52.766414Z",
     "iopub.status.busy": "2026-02-10T10:19:52.766119Z",
     "iopub.status.idle": "2026-02-10T10:19:52.770844Z",
     "shell.execute_reply": "2026-02-10T10:19:52.770209Z",
     "shell.execute_reply.started": "2026-02-10T10:19:52.766390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Callable, Dict, List, Tuple\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.amp import autocast\n",
    "from typing import Callable\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as FT\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random, numpy as np\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:20:01.484511Z",
     "iopub.status.busy": "2026-02-10T10:20:01.483897Z",
     "iopub.status.idle": "2026-02-10T10:20:01.502556Z",
     "shell.execute_reply": "2026-02-10T10:20:01.501862Z",
     "shell.execute_reply.started": "2026-02-10T10:20:01.484477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def parse_cam_id_from_stem(stem: str) -> int:\n",
    "    \"\"\"\n",
    "    PRW frame names look like: c1s3_016471 (stem)\n",
    "    We parse 'c1' -> cam_id=1\n",
    "    \"\"\"\n",
    "    m = re.match(r\"c(\\d+)\", stem)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse cam_id from stem: {stem}\")\n",
    "    return int(m.group(1))\n",
    "\n",
    "\n",
    "def clip_box_xyxy(box: np.ndarray, w: int, h: int) -> np.ndarray:\n",
    "    x1, y1, x2, y2 = box\n",
    "    x1 = float(np.clip(x1, 0, w - 1))\n",
    "    y1 = float(np.clip(y1, 0, h - 1))\n",
    "    x2 = float(np.clip(x2, 0, w - 1))\n",
    "    y2 = float(np.clip(y2, 0, h - 1))\n",
    "    x1, x2 = min(x1, x2), max(x1, x2)\n",
    "    y1, y2 = min(y1, y2), max(y1, y2)\n",
    "    return np.array([x1, y1, x2, y2], dtype=np.float32)\n",
    "\n",
    "\n",
    "def expand_and_jitter_box_xyxy(\n",
    "    box: np.ndarray,\n",
    "    img_w: int,\n",
    "    img_h: int,\n",
    "    expand_ratio: float = 0.2,\n",
    "    jitter_ratio: float = 0.05,\n",
    "    do_jitter: bool = True,\n",
    ") -> np.ndarray:\n",
    "    x1, y1, x2, y2 = box.astype(np.float32)\n",
    "    bw, bh = (x2 - x1), (y2 - y1)\n",
    "    cx, cy = x1 + 0.5 * bw, y1 + 0.5 * bh\n",
    "\n",
    "    # expand\n",
    "    bw2 = bw * (1.0 + expand_ratio)\n",
    "    bh2 = bh * (1.0 + expand_ratio)\n",
    "\n",
    "    if do_jitter:\n",
    "        cx += (random.uniform(-1, 1) * jitter_ratio) * bw\n",
    "        cy += (random.uniform(-1, 1) * jitter_ratio) * bh\n",
    "        scale = 1.0 + random.uniform(-jitter_ratio, jitter_ratio)\n",
    "        bw2 *= scale\n",
    "        bh2 *= scale\n",
    "\n",
    "    nx1 = cx - 0.5 * bw2\n",
    "    ny1 = cy - 0.5 * bh2\n",
    "    nx2 = cx + 0.5 * bw2\n",
    "    ny2 = cy + 0.5 * bh2\n",
    "    return clip_box_xyxy(np.array([nx1, ny1, nx2, ny2], dtype=np.float32), img_w, img_h)\n",
    "\n",
    "\n",
    "def load_id_list(mat_path: Path, key: str) -> List[int]:\n",
    "    d = scipy.io.loadmat(mat_path)\n",
    "    if key not in d:\n",
    "        raise KeyError(f\"Key '{key}' not found in {mat_path}. Keys: {list(d.keys())}\")\n",
    "    arr = np.asarray(d[key]).reshape(-1)\n",
    "    return [int(x) for x in arr]\n",
    "\n",
    "\n",
    "class PRWReIDDatasetCE(Dataset):\n",
    "    \"\"\"\n",
    "    Crops GT boxes from the PRW_dataset and returns:\n",
    "      crop_tensor, label (0..C-1), pid, camid\n",
    "\n",
    "    CE needs contiguous labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prw_det_ds,                                # the PRW_dataset(split=\"train\" or \"test\")\n",
    "        crop_transform: Optional[Callable] = None,\n",
    "        id_train_mat: Optional[Path] = None,       # e.g. ID_train.mat (recommended for training)\n",
    "        id_test_mat: Optional[Path] = None,        # e.g. ID_test.mat (recommended for test eval)\n",
    "        split: str = \"train\",                      # \"train\" or \"test\" just for ID filtering\n",
    "        filter_invalid_ids: bool = True,           # ignore pid <= 0\n",
    "        min_box_size: int = 10,\n",
    "        expand_ratio: float = 0.2,\n",
    "        jitter_ratio: float = 0.05,\n",
    "        jitter: bool = True,\n",
    "    ):\n",
    "        self.base = prw_det_ds\n",
    "        self.crop_transform = crop_transform\n",
    "        self.filter_invalid_ids = filter_invalid_ids\n",
    "        self.min_box_size = min_box_size\n",
    "        self.expand_ratio = expand_ratio\n",
    "        self.jitter_ratio = jitter_ratio\n",
    "        self.jitter = jitter\n",
    "\n",
    "        split = split.lower()\n",
    "        assert split in {\"train\", \"test\"}\n",
    "        self.split = split\n",
    "\n",
    "        # Optional: restrict to train/test IDs based on provided mats\n",
    "        allowed_ids = None\n",
    "        if split == \"train\" and id_train_mat is not None:\n",
    "            # common key name in PRW releases is \"ID_train\"\n",
    "            allowed_ids = set(load_id_list(id_train_mat, \"ID_train\"))\n",
    "        if split == \"test\" and id_test_mat is not None:\n",
    "            allowed_ids = set(load_id_list(id_test_mat, \"ID_test2\"))\n",
    "\n",
    "        self.samples: List[Dict] = []\n",
    "        for base_idx, (img_path, ann_path) in enumerate(self.base.pairs):\n",
    "            boxes_np, ids_np = self.base.box_cache[str(ann_path)]\n",
    "            if boxes_np is None or len(boxes_np) == 0:\n",
    "                continue\n",
    "\n",
    "            if self.filter_invalid_ids:\n",
    "                keep = ids_np > 0\n",
    "                boxes_np = boxes_np[keep]\n",
    "                ids_np = ids_np[keep]\n",
    "\n",
    "            if allowed_ids is not None:\n",
    "                keep = np.array([pid in allowed_ids for pid in ids_np], dtype=bool)\n",
    "                boxes_np = boxes_np[keep]\n",
    "                ids_np = ids_np[keep]\n",
    "\n",
    "            stem = Path(img_path).stem\n",
    "            camid = parse_cam_id_from_stem(stem)\n",
    "\n",
    "            for b, pid in zip(boxes_np, ids_np):\n",
    "                x1, y1, x2, y2 = b.tolist()\n",
    "                if (x2 - x1) < self.min_box_size or (y2 - y1) < self.min_box_size:\n",
    "                    continue\n",
    "                self.samples.append(\n",
    "                    {\n",
    "                        \"img_path\": str(img_path),\n",
    "                        \"bbox\": b.astype(np.float32),\n",
    "                        \"pid\": int(pid),\n",
    "                        \"camid\": int(camid),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # CE needs contiguous labels\n",
    "        self.pids = sorted({s[\"pid\"] for s in self.samples})\n",
    "        self.pid2label = {pid: i for i, pid in enumerate(self.pids)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        s = self.samples[i]\n",
    "        img = Image.open(s[\"img_path\"]).convert(\"RGB\")\n",
    "        W, H = img.size\n",
    "\n",
    "        box = expand_and_jitter_box_xyxy(\n",
    "            s[\"bbox\"], W, H,\n",
    "            expand_ratio=self.expand_ratio,\n",
    "            jitter_ratio=self.jitter_ratio,\n",
    "            do_jitter=self.jitter,\n",
    "        )\n",
    "\n",
    "        x1, y1, x2, y2 = box\n",
    "        crop = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "        if self.crop_transform is not None:\n",
    "            crop = self.crop_transform(crop)\n",
    "        else:\n",
    "            crop = FT.to_tensor(crop)\n",
    "\n",
    "        pid = s[\"pid\"]\n",
    "        label = self.pid2label[pid]\n",
    "        camid = s[\"camid\"]\n",
    "\n",
    "        return crop, torch.tensor(label, dtype=torch.long), torch.tensor(pid), torch.tensor(camid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:20:09.028108Z",
     "iopub.status.busy": "2026-02-10T10:20:09.027621Z",
     "iopub.status.idle": "2026-02-10T10:20:09.033057Z",
     "shell.execute_reply": "2026-02-10T10:20:09.032461Z",
     "shell.execute_reply.started": "2026-02-10T10:20:09.028077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Performing augmentation just on training bboxes\n",
    "train_reid_tf = T.Compose([\n",
    "    T.Resize((256, 128)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_reid_tf = T.Compose([\n",
    "    T.Resize((256, 128)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T11:57:27.148427Z",
     "iopub.status.busy": "2026-02-10T11:57:27.147868Z",
     "iopub.status.idle": "2026-02-10T11:57:27.292538Z",
     "shell.execute_reply": "2026-02-10T11:57:27.291977Z",
     "shell.execute_reply.started": "2026-02-10T11:57:27.148399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train on GT bboxes\n",
    "train_reid_ds = PRWReIDDatasetCE(\n",
    "    train_view,\n",
    "    crop_transform=train_reid_tf,\n",
    "    split=\"train\",\n",
    "    filter_invalid_ids=True,\n",
    "    id_train_mat=None, \n",
    ")\n",
    "\n",
    "val_reid_ds = PRWReIDDatasetCE(\n",
    "    val_view,\n",
    "    crop_transform=test_reid_tf,\n",
    "    split=\"train\",\n",
    "    filter_invalid_ids=True,\n",
    "    id_train_mat=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T11:57:41.293364Z",
     "iopub.status.busy": "2026-02-10T11:57:41.292629Z",
     "iopub.status.idle": "2026-02-10T11:57:41.297311Z",
     "shell.execute_reply": "2026-02-10T11:57:41.296718Z",
     "shell.execute_reply.started": "2026-02-10T11:57:41.293335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train_reid_loader = DataLoader(\n",
    "    train_reid_ds,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,            \n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,  # it makes sense only if num_workers>0\n",
    "    prefetch_factor=2         # default is 2\n",
    ")\n",
    "\n",
    "val_reid_loader = DataLoader(\n",
    "    val_reid_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,            \n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,  # it makes sense only if num_workers>0\n",
    "    prefetch_factor=2         # default is 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:20:16.404108Z",
     "iopub.status.busy": "2026-02-10T10:20:16.403589Z",
     "iopub.status.idle": "2026-02-10T10:20:17.074099Z",
     "shell.execute_reply": "2026-02-10T10:20:17.073327Z",
     "shell.execute_reply.started": "2026-02-10T10:20:16.404081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import average_precision_score\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:20:21.654097Z",
     "iopub.status.busy": "2026-02-10T10:20:21.653332Z",
     "iopub.status.idle": "2026-02-10T10:20:21.673617Z",
     "shell.execute_reply": "2026-02-10T10:20:21.672741Z",
     "shell.execute_reply.started": "2026-02-10T10:20:21.654065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is a minimally modified version of the eval function from the SeqNet repository (https://github.com/serend1p1ty/SeqNet/blob/master/eval_func.py)\n",
    "# Changes:\n",
    "# - Removed code related to CBGM (Context Bipartite Graph Matching)\n",
    "# - Adjusted top-k accuracy calculation to only consider top-1 accuracy\n",
    "# - Clarified function docstring and added recall rate scaling explanation\n",
    "\n",
    "def _compute_iou(a, b):\n",
    "    x1 = max(a[0], b[0])\n",
    "    y1 = max(a[1], b[1])\n",
    "    x2 = min(a[2], b[2])\n",
    "    y2 = min(a[3], b[3])\n",
    "    inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    union = (a[2] - a[0]) * (a[3] - a[1]) + (b[2] - b[0]) * (b[3] - b[1]) - inter\n",
    "    return inter * 1.0 / union\n",
    "\n",
    "def eval_search_prw(\n",
    "    gallery_dataset,\n",
    "    query_dataset,\n",
    "    gallery_dets,\n",
    "    gallery_feats,\n",
    "    query_box_feats,\n",
    "    det_thresh,\n",
    "    ignore_cam_id=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate person search performance on PRW dataset.\n",
    "\n",
    "    Args:\n",
    "        gallery_dataset (Dataset): dataset containing gallery images.\n",
    "        query_dataset (Dataset): dataset containing query images.\n",
    "        gallery_dets (list of ndarray): n_det x [x1, x2, y1, y2, score] per image. \n",
    "        gallery_feats (list of ndarray): n_det x D features per image.\n",
    "        query_box_feats (list of ndarray): D dimensional features per query image.\n",
    "        det_thresh (float): filter out gallery detections whose scores below this.\n",
    "        ignore_cam_id (bool): whether to ignore camera ID during evaluation. If set to False,\n",
    "                            gallery images from the same camera as the query will be excluded. Default: True.\n",
    "    \"\"\"\n",
    "    assert len(gallery_dataset) == len(gallery_dets)\n",
    "    assert len(gallery_dataset) == len(gallery_feats)\n",
    "    assert len(query_dataset) == len(query_box_feats)\n",
    "\n",
    "    annos = gallery_dataset.annotations\n",
    "    name_to_det_feat = {}\n",
    "    for anno, det, feat in zip(annos, gallery_dets, gallery_feats):\n",
    "        name = anno[\"img_name\"]\n",
    "        scores = det[:, 4].ravel()\n",
    "        inds = np.where(scores >= det_thresh)[0]\n",
    "        if len(inds) > 0:\n",
    "            name_to_det_feat[name] = (det[inds], feat[inds])\n",
    "\n",
    "    aps = []\n",
    "    accs = []\n",
    "    topk = [1] # we are only interested in top-1 accuracy\n",
    "    ret = {\"image_root\": gallery_dataset.img_prefix, \"results\": []}\n",
    "    for i in range(len(query_dataset)):\n",
    "        y_true, y_score = [], []\n",
    "        imgs, rois = [], []\n",
    "        count_gt, count_tp = 0, 0\n",
    "\n",
    "        feat_p = query_box_feats[i].ravel()\n",
    "\n",
    "        query_imname = query_dataset.annotations[i][\"img_name\"]\n",
    "        query_roi = query_dataset.annotations[i][\"boxes\"]\n",
    "        query_pid = query_dataset.annotations[i][\"pids\"]\n",
    "        query_cam = query_dataset.annotations[i][\"cam_id\"]\n",
    "\n",
    "        # Find all occurence of this query\n",
    "        gallery_imgs = []\n",
    "        for x in annos:\n",
    "            if query_pid in x[\"pids\"] and x[\"img_name\"] != query_imname:\n",
    "                gallery_imgs.append(x)\n",
    "        query_gts = {}\n",
    "        for item in gallery_imgs:\n",
    "            query_gts[item[\"img_name\"]] = item[\"boxes\"][item[\"pids\"] == query_pid]\n",
    "\n",
    "        # Construct gallery set for this query\n",
    "        if ignore_cam_id:\n",
    "            gallery_imgs = []\n",
    "            for x in annos:\n",
    "                if x[\"img_name\"] != query_imname:\n",
    "                    gallery_imgs.append(x)\n",
    "        else:\n",
    "            gallery_imgs = []\n",
    "            for x in annos:\n",
    "                if x[\"img_name\"] != query_imname and x[\"cam_id\"] != query_cam:\n",
    "                    gallery_imgs.append(x)\n",
    "\n",
    "        name2sim = {}\n",
    "        sims = []\n",
    "        # 1. Go through all gallery samples\n",
    "        for item in gallery_imgs:\n",
    "            gallery_imname = item[\"img_name\"]\n",
    "            # some contain the query (gt not empty), some not\n",
    "            count_gt += gallery_imname in query_gts\n",
    "            # compute distance between query and gallery dets\n",
    "            if gallery_imname not in name_to_det_feat:\n",
    "                continue\n",
    "            det, feat_g = name_to_det_feat[gallery_imname]\n",
    "            # get L2-normalized feature matrix NxD\n",
    "            #assert feat_g.size == np.prod(feat_g.shape[:2])\n",
    "            #feat_g = feat_g.reshape(feat_g.shape[:2])\n",
    "            feat_g = np.asarray(feat_g).reshape(len(det), -1)   # (Nd, D)\n",
    "            feat_p = np.asarray(feat_p).reshape(-1)            # (D,)\n",
    "            # compute cosine similarities\n",
    "            sim = feat_g.dot(feat_p).ravel()\n",
    "\n",
    "            if gallery_imname in name2sim:\n",
    "                continue\n",
    "            name2sim[gallery_imname] = sim\n",
    "            sims.extend(list(sim))\n",
    "\n",
    "        for gallery_imname, sim in name2sim.items():\n",
    "            det, feat_g = name_to_det_feat[gallery_imname]\n",
    "            # assign label for each det\n",
    "            label = np.zeros(len(sim), dtype=np.int32)\n",
    "            if gallery_imname in query_gts:\n",
    "                gt = query_gts[gallery_imname].ravel()\n",
    "                w, h = gt[2] - gt[0], gt[3] - gt[1]\n",
    "                iou_thresh = min(0.5, (w * h * 1.0) / ((w + 10) * (h + 10)))\n",
    "                inds = np.argsort(sim)[::-1]\n",
    "                sim = sim[inds]\n",
    "                det = det[inds]\n",
    "                # only set the first matched det as true positive\n",
    "                for j, roi in enumerate(det[:, :4]):\n",
    "                    if _compute_iou(roi, gt) >= iou_thresh:\n",
    "                        label[j] = 1\n",
    "                        count_tp += 1\n",
    "                        break\n",
    "            y_true.extend(list(label))\n",
    "            y_score.extend(list(sim))\n",
    "            imgs.extend([gallery_imname] * len(sim))\n",
    "            rois.extend(list(det))\n",
    "\n",
    "        # 2. Compute AP for this query (need to scale by recall rate)\n",
    "        y_score = np.asarray(y_score)\n",
    "        y_true = np.asarray(y_true)\n",
    "        assert count_tp <= count_gt\n",
    "        # Important: at the pedestrian detection stage, the model might have missed the person (failed to detect a box with IoU > 0.5).\n",
    "        # To penalize the model for these False Negatives at the detection stage, scale the AP by recall (the ratio of found matches to total ground truth matches). \n",
    "        # E.g. if the detector missed the person entirely 50% of the time, the final AP score is cut in half.\n",
    "        recall_rate = 0.0 if count_gt == 0 else (count_tp * 1.0 / count_gt)\n",
    "        ap = 0 if count_tp == 0 else average_precision_score(y_true, y_score) * recall_rate\n",
    "        #ap = 0 if count_tp == 0 else average_precision_score(y_true, y_score) # easier case\n",
    "\n",
    "        \n",
    "        aps.append(ap)\n",
    "        inds = np.argsort(y_score)[::-1]\n",
    "        y_score = y_score[inds]\n",
    "        y_true = y_true[inds]\n",
    "        accs.append([min(1, sum(y_true[:k])) for k in topk])\n",
    "        # 4. Save result for JSON dump\n",
    "        new_entry = {\n",
    "            \"query_img\": str(query_imname),\n",
    "            \"query_roi\": list(map(float, list(query_roi.squeeze()))),\n",
    "            \"query_gt\": query_gts,\n",
    "            \"gallery\": [],\n",
    "        }\n",
    "        # only save top-10 predictions\n",
    "        for k in range(10):\n",
    "            new_entry[\"gallery\"].append(\n",
    "                {\n",
    "                    \"img\": str(imgs[inds[k]]),\n",
    "                    \"roi\": list(map(float, list(rois[inds[k]]))),\n",
    "                    \"score\": float(y_score[k]),\n",
    "                    \"correct\": int(y_true[k]),\n",
    "                }\n",
    "            )\n",
    "        ret[\"results\"].append(new_entry)\n",
    "\n",
    "    print(\"search ranking:\")\n",
    "    mAP = np.mean(aps)\n",
    "    print(\"  mAP = {:.2%}\".format(mAP))\n",
    "    accs = np.mean(accs, axis=0)\n",
    "    for i, k in enumerate(topk):\n",
    "        print(\"  top-{:2d} = {:.2%}\".format(k, accs[i]))\n",
    "\n",
    "    # write_json(ret, \"vis/results.json\")\n",
    "\n",
    "    ret[\"mAP\"] = np.mean(aps)\n",
    "    ret[\"accs\"] = accs\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:20:28.458014Z",
     "iopub.status.busy": "2026-02-10T10:20:28.457707Z",
     "iopub.status.idle": "2026-02-10T10:20:28.465831Z",
     "shell.execute_reply": "2026-02-10T10:20:28.465106Z",
     "shell.execute_reply.started": "2026-02-10T10:20:28.457986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_prw_query_info_pid_xywh_imglast(query_info_path):\n",
    "    queries = []\n",
    "    with open(query_info_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            pid_s, x_s, y_s, w_s, h_s, stem = line.split()\n",
    "            pid = int(pid_s)\n",
    "            x, y, w, h = map(float, (x_s, y_s, w_s, h_s))\n",
    "            x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "            queries.append({\n",
    "                \"pid\": pid,\n",
    "                \"stem\": stem,  # c1s3_016471\n",
    "                \"img_name\": stem + \".jpg\",\n",
    "                \"box_xyxy\": np.array([x1, y1, x2, y2], dtype=np.float32),\n",
    "                \"cam_id\": parse_cam_id_from_stem(stem),\n",
    "            })\n",
    "    return queries\n",
    "\n",
    "@dataclass\n",
    "class SimpleQueryDataset:\n",
    "    annotations: list\n",
    "    img_prefix: str = \"\"\n",
    "    def __len__(self): return len(self.annotations)\n",
    "\n",
    "def build_query_dataset_from_query_info(query_info_path):\n",
    "    queries = load_prw_query_info_pid_xywh_imglast(query_info_path)\n",
    "    ann = []\n",
    "    for q in queries:\n",
    "        ann.append({\n",
    "            \"img_name\": q[\"img_name\"],\n",
    "            \"boxes\": q[\"box_xyxy\"][None, :],\n",
    "            \"pids\": np.array([q[\"pid\"]], dtype=np.int32),\n",
    "            \"cam_id\": int(q[\"cam_id\"]),\n",
    "        })\n",
    "    return SimpleQueryDataset(annotations=ann, img_prefix=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:20:32.334303Z",
     "iopub.status.busy": "2026-02-10T10:20:32.333468Z",
     "iopub.status.idle": "2026-02-10T10:20:32.340493Z",
     "shell.execute_reply": "2026-02-10T10:20:32.339751Z",
     "shell.execute_reply.started": "2026-02-10T10:20:32.334262Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def forward_embed(model, batch):\n",
    "    'Call this to ignore logits but consider the embedding.'\n",
    "    out = model(batch)\n",
    "    if isinstance(out, (tuple, list)) and len(out) == 2:\n",
    "        logits, emb = out\n",
    "        return emb              # <-- 512\n",
    "    return out                  # fallback: model returns embedding directly\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_query_box_feats_from_querybox(\n",
    "    reid_model,\n",
    "    query_info_path,\n",
    "    query_box_dir,\n",
    "    transform,\n",
    "    device,\n",
    "):\n",
    "    reid_model.eval()\n",
    "    queries = load_prw_query_info_pid_xywh_imglast(query_info_path)\n",
    "\n",
    "    feats = []\n",
    "    for q in queries:\n",
    "        pid = q[\"pid\"]\n",
    "        stem = q[\"stem\"]\n",
    "        path = osp.join(query_box_dir, f\"{pid}_{stem}.jpg\")\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        x = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        emb = forward_embed(reid_model, x)             # <-- 512\n",
    "        emb = F.normalize(emb, p=2, dim=1)             # useful as sanity check\n",
    "        feats.append(emb.squeeze(0).detach().cpu().numpy().astype(np.float32))\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:20:36.435417Z",
     "iopub.status.busy": "2026-02-10T10:20:36.434723Z",
     "iopub.status.idle": "2026-02-10T10:20:36.443322Z",
     "shell.execute_reply": "2026-02-10T10:20:36.442627Z",
     "shell.execute_reply.started": "2026-02-10T10:20:36.435385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def build_gallery_feats_from_dets_prw_dataset(\n",
    "    reid_model,\n",
    "    prw_dataset,\n",
    "    detections,\n",
    "    transform,\n",
    "    device,\n",
    "):\n",
    "    reid_model.eval()\n",
    "    gallery_feats = []\n",
    "    assert len(prw_dataset) == len(detections)\n",
    "\n",
    "    for idx in range(len(prw_dataset)):\n",
    "        img_path, _ = prw_dataset.pairs[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        det = detections[idx]\n",
    "        if det.shape[0] == 0:\n",
    "            gallery_feats.append(np.zeros((0, 1), dtype=np.float32))\n",
    "            continue\n",
    "\n",
    "        feats_img = []\n",
    "        for box in det:\n",
    "            x1, y1, x2, y2 = box[:4]\n",
    "            x1, y1, x2, y2 = map(int, map(round, (x1, y1, x2, y2)))\n",
    "            x1, y1 = max(0, x1), max(0, y1)\n",
    "            x2, y2 = max(x1 + 1, x2), max(y1 + 1, y2)\n",
    "\n",
    "            crop = img.crop((x1, y1, x2, y2))\n",
    "            x = transform(crop).unsqueeze(0).to(device)\n",
    "\n",
    "            emb = forward_embed(reid_model, x)         # <-- 512\n",
    "            emb = F.normalize(emb, p=2, dim=1)         # useful for sanity check\n",
    "            feats_img.append(emb.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "        gallery_feats.append(np.vstack(feats_img).astype(np.float32))\n",
    "\n",
    "    # fix empty dim\n",
    "    D = None\n",
    "    for f in gallery_feats:\n",
    "        if f.shape[0] > 0:\n",
    "            D = f.shape[1]\n",
    "            break\n",
    "    if D is None:\n",
    "        raise ValueError(\"All gallery feats are empty (no detections?).\")\n",
    "    for i, f in enumerate(gallery_feats):\n",
    "        if f.shape[0] == 0 and f.shape[1] != D:\n",
    "            gallery_feats[i] = np.zeros((0, D), dtype=np.float32)\n",
    "\n",
    "    return gallery_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:20:40.522596Z",
     "iopub.status.busy": "2026-02-10T10:20:40.522284Z",
     "iopub.status.idle": "2026-02-10T10:20:40.530769Z",
     "shell.execute_reply": "2026-02-10T10:20:40.529929Z",
     "shell.execute_reply.started": "2026-02-10T10:20:40.522568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PRWGalleryForEval:\n",
    "    annotations: list\n",
    "    img_prefix: str\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "def build_gallery_eval_view(prw_dataset):\n",
    "    \"\"\"\n",
    "    Create a lightweight object with .annotations and .img_prefix\n",
    "    compatible with eval_search_prw.\n",
    "    \"\"\"\n",
    "    annos = []\n",
    "    # img_prefix: parent dir of frames\n",
    "    # pairs[idx][0] is .../frames/c1s3_016471.jpg\n",
    "    # so prefix is .../frames\n",
    "    img_prefix = str(prw_dataset.pairs[0][0].parent)\n",
    "\n",
    "    for idx, (img_path, ann_path) in enumerate(prw_dataset.pairs):\n",
    "        stem = img_path.stem              # c1s3_016471\n",
    "        img_name = img_path.name          # c1s3_016471.jpg\n",
    "\n",
    "        boxes_np, ids_np = prw_dataset.box_cache[str(ann_path)]  # GT xyxy + ids\n",
    "\n",
    "        # filter out invalid IDs (e.g. -2) if needed\n",
    "        keep = ids_np > 0\n",
    "        boxes = boxes_np[keep]\n",
    "        pids = ids_np[keep]\n",
    "\n",
    "        cam_id = parse_cam_id_from_stem(stem)\n",
    "\n",
    "        annos.append({\n",
    "            \"img_name\": img_name,  # must match exactly what eval expects\n",
    "            \"boxes\": boxes.astype(np.float32),\n",
    "            \"pids\": pids.astype(np.int32),\n",
    "            \"cam_id\": cam_id,\n",
    "        })\n",
    "\n",
    "    return PRWGalleryForEval(annotations=annos, img_prefix=img_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:20:44.454354Z",
     "iopub.status.busy": "2026-02-10T10:20:44.453762Z",
     "iopub.status.idle": "2026-02-10T10:20:44.463750Z",
     "shell.execute_reply": "2026-02-10T10:20:44.462916Z",
     "shell.execute_reply.started": "2026-02-10T10:20:44.454324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_checkpoint_prw(\n",
    "    ckpt_path,\n",
    "    model,\n",
    "    query_ds,\n",
    "    gallery_eval,\n",
    "    test_ds,\n",
    "    test_detections,\n",
    "    test_reid_tf,\n",
    "    device,\n",
    "):\n",
    "    def _fmt_pct(x):\n",
    "        x = float(x)\n",
    "        return f\"{x:.2f}%\" if x > 1.0 else f\"{100*x:.2f}%\"\n",
    "\n",
    "    def _extract_map_top1(ret):\n",
    "        # --- mAP ---\n",
    "        map_val = ret.get(\"mAP\", ret.get(\"map\", ret.get(\"MAP\", None)))\n",
    "\n",
    "        # --- top-1 (rank-1) ---\n",
    "        top1_val = None\n",
    "        accs = ret.get(\"accs\", None)\n",
    "\n",
    "        if isinstance(accs, (list, tuple)):\n",
    "            if len(accs) > 0:\n",
    "                top1_val = accs[0]\n",
    "        elif hasattr(accs, \"shape\"):  # numpy array / torch tensor\n",
    "            try:\n",
    "                # numpy\n",
    "                if getattr(accs, \"size\", 0) > 0:\n",
    "                    top1_val = accs[0]\n",
    "            except Exception:\n",
    "                # torch tensor fallback\n",
    "                if accs.numel() > 0:\n",
    "                    top1_val = accs.flatten()[0].item()\n",
    "        elif isinstance(accs, dict):\n",
    "            for k in [\"top1\", \"top-1\", \"rank1\", \"r1\", \"acc1\"]:\n",
    "                if k in accs:\n",
    "                    top1_val = accs[k]\n",
    "                    break\n",
    "\n",
    "        return map_val, top1_val\n",
    "\n",
    "    print(f\"\\n[Eval] Loading checkpoint: {ckpt_path}\")\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "    state_dict = ckpt[\"model\"] if isinstance(ckpt, dict) and \"model\" in ckpt else ckpt\n",
    "\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    query_feats = compute_query_box_feats_from_querybox(\n",
    "        reid_model=model,\n",
    "        query_info_path=\"/kaggle/input/prw-person-re-identification-in-the-wild/query_info.txt\",\n",
    "        query_box_dir=\"/kaggle/input/prw-person-re-identification-in-the-wild/query_box\",\n",
    "        transform=test_reid_tf,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    gallery_feats = build_gallery_feats_from_dets_prw_dataset(\n",
    "        reid_model=model,\n",
    "        prw_dataset=test_ds,\n",
    "        detections=test_detections,\n",
    "        transform=test_reid_tf,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    ret = eval_search_prw(\n",
    "        gallery_dataset=gallery_eval,\n",
    "        query_dataset=query_ds,\n",
    "        gallery_dets=test_detections,\n",
    "        gallery_feats=gallery_feats,\n",
    "        query_box_feats=query_feats,\n",
    "        det_thresh=0.3,\n",
    "        ignore_cam_id=True,\n",
    "    )\n",
    "\n",
    "    map_val, top1_val = _extract_map_top1(ret)\n",
    "\n",
    "    if map_val is not None and top1_val is not None:\n",
    "        print(f\"[Eval] {ckpt_path}  mAP={_fmt_pct(map_val)} | top-1={_fmt_pct(top1_val)}\")\n",
    "    else:\n",
    "        print(f\"[Eval] {ckpt_path}  cannot find mAP/top-1 in ret. keys={list(ret.keys())}\")\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T11:58:08.668951Z",
     "iopub.status.busy": "2026-02-10T11:58:08.668654Z",
     "iopub.status.idle": "2026-02-10T11:58:08.749587Z",
     "shell.execute_reply": "2026-02-10T11:58:08.748985Z",
     "shell.execute_reply.started": "2026-02-10T11:58:08.668925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1) Build gallery view for eval (GT annos etc.)\n",
    "gallery_eval = build_gallery_eval_view(test_ds)\n",
    "\n",
    "# 2) Build query dataset from query_info (metadata only)\n",
    "query_ds = build_query_dataset_from_query_info(\n",
    "    \"/kaggle/input/prw-person-re-identification-in-the-wild/query_info.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T11:58:13.323380Z",
     "iopub.status.busy": "2026-02-10T11:58:13.322781Z",
     "iopub.status.idle": "2026-02-10T11:58:13.327639Z",
     "shell.execute_reply": "2026-02-10T11:58:13.326881Z",
     "shell.execute_reply.started": "2026-02-10T11:58:13.323351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Defining hyperparams\n",
    "emb_dim = 512\n",
    "n_epochs = 20\n",
    "num_classes = len(train_reid_ds.pids)\n",
    "\n",
    "# optimizer params\n",
    "lr = 3e-4\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# setup device \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# setup training\n",
    "use_amp = (device == \"cuda\")          \n",
    "scaler = torch.amp.GradScaler(\"cuda\", enabled=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T09:45:39.018314Z",
     "iopub.status.busy": "2026-02-08T09:45:39.018011Z",
     "iopub.status.idle": "2026-02-08T09:45:39.023189Z",
     "shell.execute_reply": "2026-02-08T09:45:39.022603Z",
     "shell.execute_reply.started": "2026-02-08T09:45:39.018288Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "len(train_reid_ds.pids) # num. train samples for re-id (331 IDs for 85% view (originally 483))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T11:58:18.001115Z",
     "iopub.status.busy": "2026-02-10T11:58:18.000390Z",
     "iopub.status.idle": "2026-02-10T11:58:18.019560Z",
     "shell.execute_reply": "2026-02-10T11:58:18.019008Z",
     "shell.execute_reply.started": "2026-02-10T11:58:18.001083Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) SeqNet-like dataset wrapper for eval_search_prw\n",
    "# =========================\n",
    "@dataclass\n",
    "class SeqNetLikeDataset:\n",
    "    img_prefix: str                 # root folder for images (string)\n",
    "    annotations: List[Dict[str, Any]]  # list of dicts: img_name, boxes, pids, cam_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.annotations[idx]\n",
    "\n",
    "# =========================\n",
    "# 2) Utility: parse cam_id from PRW filename\n",
    "#    PRW: \"c1s1_000151.jpg\" -> cam_id = 1\n",
    "# =========================\n",
    "def cam_id_from_prw_name(img_name: str) -> int:\n",
    "    stem = img_name[:-4] if img_name.endswith(\".jpg\") else img_name\n",
    "    if stem.startswith(\"c\") and \"s\" in stem:\n",
    "        try:\n",
    "            return int(stem[1:stem.index(\"s\")])\n",
    "        except Exception:\n",
    "            return -1\n",
    "    return -1\n",
    "\n",
    "# =========================\n",
    "# 3) Build GALLERY eval dataset from PRW_dataset\n",
    "# =========================\n",
    "def build_gallery_eval_from_prw(gallery_ds, img_prefix: str) -> SeqNetLikeDataset:\n",
    "    ann = []\n",
    "    for idx in range(len(gallery_ds)):\n",
    "        img_path, ann_path = gallery_ds.pairs[idx]\n",
    "        boxes, pids = gallery_ds.box_cache[str(ann_path)]\n",
    "\n",
    "        ann.append({\n",
    "            \"img_name\": img_path.name,                         # must match what eval_search_prw uses\n",
    "            \"boxes\": np.asarray(boxes, dtype=np.float32),       # (N,4) xyxy\n",
    "            \"pids\":  np.asarray(pids,  dtype=np.int64),         # (N,)\n",
    "            \"cam_id\": cam_id_from_prw_name(img_path.name),\n",
    "        })\n",
    "    return SeqNetLikeDataset(img_prefix=str(img_prefix), annotations=ann)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Build QUERY eval dataset for VALIDATION (custom queries):\n",
    "#    One query per PID, chosen as the largest GT box (more stable).\n",
    "# =========================\n",
    "def build_query_eval_from_val_view_one_per_pid(val_view, img_prefix: str) -> SeqNetLikeDataset:\n",
    "    # pid -> (area, img_name, box_1x4, cam_id)\n",
    "    best = {}\n",
    "\n",
    "    for idx in range(len(val_view)):\n",
    "        img_path, ann_path = val_view.pairs[idx]\n",
    "        boxes, pids = val_view.box_cache[str(ann_path)]\n",
    "        cam = cam_id_from_prw_name(img_path.name)\n",
    "\n",
    "        for box, pid in zip(boxes, pids):\n",
    "            pid = int(pid)\n",
    "            if pid <= 0:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = map(float, box)\n",
    "            area = max(0.0, x2 - x1) * max(0.0, y2 - y1)\n",
    "\n",
    "            if (pid not in best) or (area > best[pid][0]):\n",
    "                best[pid] = (area, img_path.name, np.asarray([box], dtype=np.float32), cam)\n",
    "\n",
    "    # Build query annotations in deterministic PID order\n",
    "    query_ann = []\n",
    "    for pid in sorted(best.keys()):\n",
    "        _, img_name, box_1x4, cam = best[pid]\n",
    "        query_ann.append({\n",
    "            \"img_name\": img_name,\n",
    "            \"boxes\": box_1x4,          # (1,4) xyxy\n",
    "            \"pids\": int(pid),          \n",
    "            \"cam_id\": cam,\n",
    "        })\n",
    "\n",
    "    return SeqNetLikeDataset(img_prefix=str(img_prefix), annotations=query_ann)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) Compute query features from query_eval (PIL crop + transform, same style as gallery feats)\n",
    "#    Returns: list of (D,) ordered with query_eval annotations\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def build_query_feats_from_query_eval(\n",
    "    reid_model,\n",
    "    query_eval: SeqNetLikeDataset,\n",
    "    transform,\n",
    "    device: str,\n",
    ") -> List[np.ndarray]:\n",
    "    reid_model.eval()\n",
    "    feats = []\n",
    "\n",
    "    for q in query_eval.annotations:\n",
    "        img_path = f\"{query_eval.img_prefix}/{q['img_name']}\"\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        box = np.asarray(q[\"boxes\"], dtype=np.float32).reshape(-1, 4)[0]\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        x1, y1, x2, y2 = map(int, map(round, (x1, y1, x2, y2)))\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = max(x1 + 1, x2), max(y1 + 1, y2)\n",
    "\n",
    "        crop = img.crop((x1, y1, x2, y2))\n",
    "        x = transform(crop).unsqueeze(0).to(device)\n",
    "\n",
    "        emb = forward_embed(reid_model, x)     # must return (1,D)\n",
    "        emb = F.normalize(emb, p=2, dim=1)     # consistent with gallery\n",
    "        feats.append(emb.squeeze(0).detach().cpu().numpy().astype(np.float32))\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) safety check: ensure alignment between gallery_eval and detections\n",
    "# =========================\n",
    "def assert_gallery_alignment(gallery_eval: SeqNetLikeDataset, gallery_ds, detections):\n",
    "    assert len(gallery_ds) == len(detections) == len(gallery_eval.annotations)\n",
    "    for i in range(min(10, len(gallery_ds))):\n",
    "        img_path, _ = gallery_ds.pairs[i]\n",
    "        assert gallery_eval.annotations[i][\"img_name\"] == img_path.name, \\\n",
    "            f\"Mismatch at {i}: eval={gallery_eval.annotations[i]['img_name']} vs ds={img_path.name}\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 7) Minimal \"correct\" evaluation entrypoint for VALIDATION\n",
    "#    (use this for model selection)\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def eval_prw_validation_person_search(\n",
    "    ckpt_path: str,\n",
    "    model,\n",
    "    val_view,          # GT-filtered view, allowed_pids=val_ids, drop_empty=True\n",
    "    val_ds,            # gallery images dataset\n",
    "    val_detections,    # list len = len(val_ds), each: Nd x [x1,y1,x2,y2,score,...]\n",
    "    transform,         # PIL -> tensor\n",
    "    device: str,\n",
    "    det_thresh: float = 0.3,\n",
    "    ignore_cam_id: bool = True,\n",
    "):\n",
    "    # ---- load checkpoint\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    state_dict = ckpt[\"model\"] if isinstance(ckpt, dict) and \"model\" in ckpt else ckpt\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model.to(device).eval()\n",
    "\n",
    "    print(f\"\\n[Eval] Loading checkpoint: {ckpt_path}\")\n",
    "\n",
    "    # ---- build eval datasets\n",
    "    gallery_eval = build_gallery_eval_from_prw(val_ds, img_prefix=str(val_ds.pairs[0][0].parent))\n",
    "    query_eval   = build_query_eval_from_val_view_one_per_pid(val_view, img_prefix=gallery_eval.img_prefix)\n",
    "\n",
    "    # ----  alignment sanity check\n",
    "    assert_gallery_alignment(gallery_eval, val_ds, val_detections)\n",
    "\n",
    "    # ---- features\n",
    "    query_feats   = build_query_feats_from_query_eval(model, query_eval, transform, device)\n",
    "    gallery_feats = build_gallery_feats_from_dets_prw_dataset(model, val_ds, val_detections, transform, device)\n",
    "\n",
    "    # ---- eval\n",
    "    ret = eval_search_prw(\n",
    "        gallery_dataset=gallery_eval,\n",
    "        query_dataset=query_eval,\n",
    "        gallery_dets=val_detections,\n",
    "        gallery_feats=gallery_feats,\n",
    "        query_box_feats=query_feats,\n",
    "        det_thresh=det_thresh,\n",
    "        ignore_cam_id=ignore_cam_id,\n",
    "    )\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on candidate models (using train/val split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosFaceClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes, s=30.0, m=0.35):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(num_classes, in_dim))\n",
    "        nn.init.normal_(self.weight, std=0.01)\n",
    "        self.s = float(s)\n",
    "        self.m = float(m)\n",
    "\n",
    "    def forward(self, x_normed, labels=None):\n",
    "        # x_normed: (B, D), already normalized\n",
    "        w = F.normalize(self.weight, dim=1)     # (C, D)\n",
    "        cosine = x_normed @ w.t()                 # (B, C)\n",
    "\n",
    "        if labels is None:\n",
    "            # inference\n",
    "            return self.s * cosine\n",
    "\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, labels.view(-1, 1), 1.0)\n",
    "\n",
    "        cosine_m = cosine - one_hot * self.m\n",
    "        return self.s * cosine_m\n",
    "\n",
    "class ReIDNetCosFace(nn.Module):\n",
    "    def __init__(self, emb_dim, num_classes, s=30.0, m=0.35):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet50(\n",
    "            weights=models.ResNet50_Weights.IMAGENET1K_V2\n",
    "        )\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-2])\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(2048, emb_dim)\n",
    "        self.cls = CosFaceClassifier(emb_dim, num_classes, s=s, m=m)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        f = self.backbone(x)\n",
    "        f = self.pool(f).flatten(1)\n",
    "        z = self.fc(f)\n",
    "        z = F.normalize(z, dim=1)\n",
    "\n",
    "        logits = self.cls(z, labels=labels)\n",
    "        return logits, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReIDNetArcFace(nn.Module):\n",
    "    def __init__(self, emb_dim, num_classes, s=30.0, m=0.35):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet50(\n",
    "            weights=models.ResNet50_Weights.IMAGENET1K_V2\n",
    "        )\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-2])\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(2048, emb_dim)\n",
    "\n",
    "        self.cls = ArcFaceClassifier(\n",
    "            in_dim=emb_dim,\n",
    "            num_classes=num_classes,\n",
    "            s=s,\n",
    "            m=m\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        f = self.backbone(x)\n",
    "        f = self.pool(f).flatten(1)\n",
    "        z = self.fc(f)\n",
    "        z = F.normalize(z, dim=1)  # IMPORTANT\n",
    "\n",
    "        logits = self.cls(z, labels=labels)\n",
    "        return logits, z\n",
    "\n",
    "class ArcFaceClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes, s=30.0, m=0.35):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(num_classes, in_dim))\n",
    "        nn.init.normal_(self.weight, std=0.01)\n",
    "\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "\n",
    "        # cos(m) and sin(m) are constants\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, x_normed, labels=None):\n",
    "        # x_normed: (B, D), already L2-normalized\n",
    "        w = F.normalize(self.weight, dim=1)        # (C, D)\n",
    "        cosine = torch.matmul(x_normed, w.t())     # (B, C)\n",
    "\n",
    "        if labels is None:\n",
    "            # inference\n",
    "            return self.s * cosine\n",
    "\n",
    "        # ---- ArcFace margin ----\n",
    "        sine = torch.sqrt(1.0 - torch.clamp(cosine ** 2, 0, 1))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m  # cos(theta + m)\n",
    "\n",
    "        # optional safeguard (standard ArcFace trick)\n",
    "        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, labels.view(-1, 1), 1.0)\n",
    "\n",
    "        logits = one_hot * phi + (1.0 - one_hot) * cosine\n",
    "        return self.s * logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReIDNetEmbed(nn.Module):\n",
    "    \"\"\"\n",
    "    Same backbone+pool+fc as ReIDNet, but no classifier head.\n",
    "    Returns L2-normalized embedding (B, D), ready for angular losses.\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dim: int = 512):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-2])\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(2048, emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)\n",
    "        f = self.pool(f).flatten(1)\n",
    "        z = self.fc(f)\n",
    "        z = F.normalize(z, dim=1)  # IMPORTANT for angular triplet\n",
    "        return z\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Angular Triplet Loss\n",
    "# =====================\n",
    "class AngularTripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Batch-hard angular triplet:\n",
    "      L_i = relu( theta_ap - theta_an + margin )\n",
    "    where theta = arccos(cosine_similarity), in radians.\n",
    "\n",
    "    Requirements:\n",
    "      - embeddings are L2-normalized\n",
    "      - batch should contain >=2 samples for some labels (use PK sampler!)\n",
    "    \"\"\"\n",
    "    def __init__(self, margin_rad: float = 0.35, eps: float = 1e-7):\n",
    "        super().__init__()\n",
    "        self.margin = float(margin_rad)\n",
    "        self.eps = float(eps)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, labels: torch.Tensor):\n",
    "        \"\"\"\n",
    "        emb: (B,D) normalized\n",
    "        labels: (B,) long\n",
    "        \"\"\"\n",
    "        device = emb.device\n",
    "        B = emb.size(0)\n",
    "        if B < 2:\n",
    "            return emb.new_tensor(0.0)\n",
    "\n",
    "        labels = labels.view(-1)\n",
    "        # cosine similarity matrix (B,B)\n",
    "        cos = emb @ emb.t()\n",
    "        cos = cos.clamp(-1.0 + self.eps, 1.0 - self.eps)\n",
    "\n",
    "        # angle matrix (B,B)\n",
    "        theta = torch.acos(cos)  # in [0, pi]\n",
    "\n",
    "        # masks\n",
    "        same = labels.unsqueeze(0) == labels.unsqueeze(1)      # positives (incl diag)\n",
    "        diff = ~same                                           # negatives\n",
    "\n",
    "        # exclude self from positives\n",
    "        eye = torch.eye(B, dtype=torch.bool, device=device)\n",
    "        pos_mask = same & ~eye\n",
    "        neg_mask = diff\n",
    "\n",
    "        # We want:\n",
    "        #   hardest positive = MAX angle among positives\n",
    "        #   hardest negative = MIN angle among negatives\n",
    "        # For anchors with no positives in-batch, we skip them.\n",
    "\n",
    "        # set invalid entries to -inf / +inf appropriately\n",
    "        theta_pos = theta.masked_fill(~pos_mask, float(\"-inf\"))\n",
    "        theta_neg = theta.masked_fill(~neg_mask, float(\"inf\"))\n",
    "\n",
    "        hardest_pos, _ = theta_pos.max(dim=1)  # (B,)\n",
    "        hardest_neg, _ = theta_neg.min(dim=1)  # (B,)\n",
    "\n",
    "        valid = (hardest_pos > float(\"-inf\")) & (hardest_neg < float(\"inf\"))\n",
    "        if valid.sum().item() == 0:\n",
    "            # no usable triplets in this batch\n",
    "            return emb.new_tensor(0.0)\n",
    "\n",
    "        diff = hardest_pos[valid] - hardest_neg[valid] + self.margin\n",
    "        loss = F.softplus(diff)   # <-- instead of relu\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupInfoNCELoss(nn.Module):\n",
    "    def __init__(self, temperature: float = 0.07, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.tau = float(temperature)\n",
    "        self.eps = float(eps)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        B = emb.size(0)\n",
    "        if B < 2:\n",
    "            return emb.sum() * 0.0\n",
    "\n",
    "        # emb is expected float32 here\n",
    "        emb = F.normalize(emb, dim=1)\n",
    "        labels = labels.view(-1).long()\n",
    "        device = emb.device\n",
    "\n",
    "        logits = (emb @ emb.t()) / self.tau  # float32\n",
    "        eye = torch.eye(B, dtype=torch.bool, device=device)\n",
    "\n",
    "        # safe big negative in fp32\n",
    "        logits = logits.masked_fill(eye, -1e9)\n",
    "\n",
    "        lab = labels.view(-1, 1)\n",
    "        pos_mask = (lab == lab.t()) & (~eye)\n",
    "        pos_count = pos_mask.sum(dim=1)\n",
    "\n",
    "        valid = pos_count > 0\n",
    "        if valid.sum() == 0:\n",
    "            return emb.sum() * 0.0\n",
    "\n",
    "        log_prob = F.log_softmax(logits, dim=1)\n",
    "        pos_log_prob_sum = (log_prob * pos_mask.float()).sum(dim=1)\n",
    "        loss_i = -pos_log_prob_sum / (pos_count.float() + self.eps)\n",
    "\n",
    "        return loss_i[valid].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReIDNetArcFaceConvNeXt(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_dim: int,\n",
    "        num_classes: int,\n",
    "        s: float = 30.0,\n",
    "        m: float = 0.35,\n",
    "        variant: str = \"tiny\",   # \"tiny\" | \"small\" | \"base\" | \"large\"\n",
    "        pretrained: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # ------------- pick ConvNeXt variant + weights -------------\n",
    "        variant = variant.lower()\n",
    "        if variant == \"tiny\":\n",
    "            weights = models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "            backbone = models.convnext_tiny(weights=weights)\n",
    "        elif variant == \"small\":\n",
    "            weights = models.ConvNeXt_Small_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "            backbone = models.convnext_small(weights=weights)\n",
    "        elif variant == \"base\":\n",
    "            weights = models.ConvNeXt_Base_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "            backbone = models.convnext_base(weights=weights)\n",
    "        elif variant == \"large\":\n",
    "            weights = models.ConvNeXt_Large_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "            backbone = models.convnext_large(weights=weights)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ConvNeXt variant: {variant}\")\n",
    "\n",
    "        # ConvNeXt in torchvision: backbone.features is the conv trunk\n",
    "        self.backbone = backbone.features\n",
    "\n",
    "        # ------------- head: GAP -> fc -> normalize -> ArcFace -------------\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # robust way to get feature dimension:\n",
    "        # ConvNeXt classifier ends with Linear(in_features -> 1000)\n",
    "        feat_dim = backbone.classifier[-1].in_features\n",
    "\n",
    "        self.fc = nn.Linear(feat_dim, emb_dim)\n",
    "\n",
    "        self.cls = ArcFaceClassifier(\n",
    "            in_dim=emb_dim,\n",
    "            num_classes=num_classes,\n",
    "            s=s,\n",
    "            m=m\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        f = self.backbone(x)              # (N, C, H, W)\n",
    "        f = self.pool(f).flatten(1)       # (N, C)\n",
    "        z = self.fc(f)                    # (N, emb_dim)\n",
    "        z = F.normalize(z, dim=1)\n",
    "\n",
    "        logits = self.cls(z, labels=labels)\n",
    "        return logits, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Val utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:23:29.234477Z",
     "iopub.status.busy": "2026-02-10T10:23:29.234166Z",
     "iopub.status.idle": "2026-02-10T10:23:29.240908Z",
     "shell.execute_reply": "2026-02-10T10:23:29.240202Z",
     "shell.execute_reply.started": "2026-02-10T10:23:29.234422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_criterion_ce(params):\n",
    "    return nn.CrossEntropyLoss(label_smoothing=params.get(\"label_smoothing\", 0.0))\n",
    "\n",
    "def build_model_margin(params):\n",
    "    head = params.get(\"loss_name\", \"ce\")\n",
    "    m = params.get(\"m\", 0.0)\n",
    "    s = params.get(\"s\", 64)\n",
    "\n",
    "    if head == \"cosface\":\n",
    "        return ReIDNetCosFace(emb_dim=emb_dim, num_classes=num_classes, m=m, s=s)\n",
    "    elif head == \"arcface\":\n",
    "        return ReIDNetArcFace(emb_dim=emb_dim, num_classes=num_classes, m=m, s=s)\n",
    "    elif head == \"arcface_cx\":\n",
    "        return ReIDNetArcFaceConvNeXt(emb_dim=emb_dim, num_classes=num_classes, s=s, m=m, variant=\"tiny\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown head/loss_name: {head}\")\n",
    "\n",
    "base_config = {\n",
    "    \"seed\": seed,\n",
    "    \"dataset\": \"PRW\",\n",
    "    \"backbone\": \"resnet50\",\n",
    "    \"loss\": \"CE\",\n",
    "    \"resize\": \"(256,128)\",\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"warmup_epochs\": 1,\n",
    "    \"milestones\": [16],\n",
    "    \"gamma\": 0.1,\n",
    "}\n",
    "\n",
    "base_config_cx = {\n",
    "    \"seed\": seed,\n",
    "    \"dataset\": \"PRW\",\n",
    "    \"backbone\": \"ConvNeXt_Tiny\",\n",
    "    \"loss\": \"CE\",\n",
    "    \"resize\": \"(256,128)\",\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"warmup_epochs\": 1,\n",
    "    \"milestones\": [16],\n",
    "    \"gamma\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T11:59:50.815256Z",
     "iopub.status.busy": "2026-02-10T11:59:50.813945Z",
     "iopub.status.idle": "2026-02-10T11:59:50.863093Z",
     "shell.execute_reply": "2026-02-10T11:59:50.862115Z",
     "shell.execute_reply.started": "2026-02-10T11:59:50.815212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_classification(model, val_loader, criterion, device, use_amp: bool):\n",
    "    \"\"\"\n",
    "    Validation loop for classification-based ReIDNet with margin heads.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    tot_loss, tot_acc, n_batches = 0.0, 0.0, 0\n",
    "    tot_emb_norm, tot_maxprob = 0.0, 0.0\n",
    "\n",
    "    for crops, labels, pid, camid in val_loader:\n",
    "        crops = crops.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True).view(-1)\n",
    "\n",
    "        with autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "            logits, emb = model(crops, labels=labels)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "        pred = logits.argmax(dim=1)\n",
    "        acc1 = (pred == labels).float().mean().item()\n",
    "        max_prob = F.softmax(logits, dim=1).max(dim=1).values.mean().item()\n",
    "        emb_norm = emb.norm(dim=1).mean().item()\n",
    "\n",
    "        tot_loss += float(loss.item())\n",
    "        tot_acc += float(acc1)\n",
    "        tot_emb_norm += float(emb_norm)\n",
    "        tot_maxprob += float(max_prob)\n",
    "        n_batches += 1\n",
    "\n",
    "    if n_batches == 0:\n",
    "        return {}\n",
    "\n",
    "    return {\n",
    "        \"val/loss\": tot_loss / n_batches,\n",
    "        \"val/acc1\": tot_acc / n_batches,\n",
    "        \"val/emb_norm_mean\": tot_emb_norm / n_batches,\n",
    "        \"val/max_prob_mean\": tot_maxprob / n_batches,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_schedulers(optimizer, steps_per_epoch: int, warmup_epochs: int, milestones, gamma: float):\n",
    "    warmup_steps = warmup_epochs * steps_per_epoch\n",
    "\n",
    "    def warmup_lambda(step: int) -> float:\n",
    "        if step < warmup_steps:\n",
    "            return (step + 1) / max(1, warmup_steps)\n",
    "        return 1.0\n",
    "\n",
    "    warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_lambda)\n",
    "    step_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
    "\n",
    "    return warmup_scheduler, step_scheduler, warmup_steps\n",
    "\n",
    "\n",
    "def should_save_epoch(epoch_idx: int, save_every: int, extra_epochs: set):\n",
    "    # epoch_idx is 0-based for the epoch that just finished\n",
    "    if epoch_idx in extra_epochs:\n",
    "        return True\n",
    "    if save_every > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def save_ckpt(path, epoch_idx, global_step, model, optimizer, warmup_scheduler, step_scheduler, scaler, extra_state: dict):\n",
    "    ckpt = {\n",
    "        \"epoch\": epoch_idx,  # keep 0-based to be explicit\n",
    "        \"global_step\": global_step,\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"warmup_scheduler\": warmup_scheduler.state_dict() if warmup_scheduler is not None else None,\n",
    "        \"step_scheduler\": step_scheduler.state_dict() if step_scheduler is not None else None,\n",
    "        \"scaler\": scaler.state_dict() if scaler is not None else None,\n",
    "        **extra_state,\n",
    "    }\n",
    "    torch.save(ckpt, path)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main training function\n",
    "# -------------------------\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_reid_experiment(\n",
    "    *,\n",
    "    model: torch.nn.Module,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    device: str,\n",
    "    run_name: str,\n",
    "    wandb_project: str,\n",
    "    wandb_entity: str,\n",
    "    config: dict,\n",
    "    n_epochs: int = 20,\n",
    "    lr: float = 3e-4,\n",
    "    weight_decay: float = 1e-4,\n",
    "    warmup_epochs: int = 1,\n",
    "    milestones=(16,),\n",
    "    gamma: float = 0.1,\n",
    "    use_amp: bool = True,\n",
    "    save_every: int = 5,\n",
    "    always_save_epochs=(4, 5, 6),   # 1-based epoch numbers to always save\n",
    "    save_epoch0: bool = True,       # save before training starts\n",
    "    ckpt_dir: str = \".\",\n",
    "    extra_state: dict = None,       # e.g. pid2label, emb_dim, num_classes...\n",
    "    eval_metric_key: str = \"val/acc1\",  \n",
    "):\n",
    "    \"\"\"\n",
    "    Comprehensive training loop for ReIDNet with margin-based heads, integrated with Weights & Biases for logging and checkpointing.\n",
    "    \"\"\"\n",
    "\n",
    "    if extra_state is None:\n",
    "        extra_state = {}\n",
    "\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # AMP scaler\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=use_amp)\n",
    "\n",
    "    # schedulers\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    warmup_steps = max(1, warmup_epochs * steps_per_epoch)\n",
    "\n",
    "    def warmup_lambda(step: int) -> float:\n",
    "        # linearly ramp lr from 0 -> base lr over warmup_steps optimizer updates\n",
    "        if step < warmup_steps:\n",
    "            return (step + 1) / warmup_steps\n",
    "        return 1.0\n",
    "\n",
    "    warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_lambda)\n",
    "    step_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, milestones=list(milestones), gamma=gamma\n",
    "    )\n",
    "\n",
    "    # wandb init\n",
    "    run = wandb.init(\n",
    "        entity=wandb_entity,\n",
    "        project=wandb_project,\n",
    "        config={\n",
    "            **config,\n",
    "            \"epochs\": n_epochs,\n",
    "            \"learning_rate\": lr,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"scheduler\": f\"warmup({warmup_epochs} epoch, per-update) + MultiStepLR(milestones={list(milestones)}, gamma={gamma})\",\n",
    "            \"warmup_epochs\": warmup_epochs,\n",
    "            \"warmup_steps\": warmup_steps,\n",
    "            \"milestones\": list(milestones),\n",
    "            \"gamma\": gamma,\n",
    "            \"amp\": use_amp,\n",
    "            \"save_every_epochs\": save_every,\n",
    "            \"always_save_epochs\": list(always_save_epochs),\n",
    "            \"eval_metric_key\": eval_metric_key,\n",
    "        },\n",
    "        name=run_name,\n",
    "        reinit=True,\n",
    "    )\n",
    "\n",
    "    def save_ckpt(path: str, epoch: int, global_step: int):\n",
    "        ckpt = {\n",
    "            \"epoch\": epoch,  # 0 means untrained snapshot if save_epoch0=True\n",
    "            \"global_step\": global_step,\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"warmup_scheduler\": warmup_scheduler.state_dict(),\n",
    "            \"step_scheduler\": step_scheduler.state_dict(),\n",
    "            \"scaler\": scaler.state_dict() if use_amp else None,\n",
    "            **extra_state,\n",
    "        }\n",
    "        torch.save(ckpt, path)\n",
    "        artifact = wandb.Artifact(os.path.basename(path).replace(\".pth\", \"\"), type=\"model\")\n",
    "        artifact.add_file(path)\n",
    "        wandb.log_artifact(artifact)\n",
    "\n",
    "    def should_save(epoch_1based: int) -> bool:\n",
    "        if epoch_1based in set(always_save_epochs):\n",
    "            return True\n",
    "        if save_every > 0 and (epoch_1based % save_every == 0):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # ---- save epoch 0 (untrained) ----\n",
    "    global_step = 0\n",
    "    warmup_updates_done = 0  # counts optimizer updates that actually happened during warmup\n",
    "\n",
    "    if save_epoch0:\n",
    "        path0 = os.path.join(ckpt_dir, f\"{run_name}_epoch00.pth\")\n",
    "        save_ckpt(path0, epoch=0, global_step=global_step)\n",
    "\n",
    "    best_score = -math.inf\n",
    "    best_path = None\n",
    "\n",
    "    # ---- training loop (epoch is 1..n_epochs) ----\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss, running_acc1 = 0.0, 0.0\n",
    "\n",
    "        for crops, labels, pid, camid in train_loader:\n",
    "            crops = crops.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True).view(-1)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "                logits, emb = model(crops, labels=labels)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "            # AMP-safe step + detect overflow-skip\n",
    "            prev_scale = scaler.get_scale()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            skipped = scaler.get_scale() < prev_scale  # overflow => step skipped\n",
    "\n",
    "            # warmup step only if optimizer really stepped\n",
    "            if (not skipped) and (warmup_updates_done < warmup_steps):\n",
    "                warmup_scheduler.step()\n",
    "                warmup_updates_done += 1\n",
    "\n",
    "            with torch.no_grad():\n",
    "                loss_val = float(loss.item())\n",
    "                pred = logits.argmax(dim=1)\n",
    "                acc1 = (pred == labels).float().mean().item()\n",
    "                emb_norm = emb.norm(dim=1).mean().item()\n",
    "                max_prob = F.softmax(logits, dim=1).max(dim=1).values.mean().item()\n",
    "                lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            running_loss += loss_val\n",
    "            running_acc1 += acc1\n",
    "\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"train/loss\": loss_val,\n",
    "                    \"train/acc1\": acc1,\n",
    "                    \"train/emb_norm_mean\": emb_norm,\n",
    "                    \"train/max_prob_mean\": max_prob,\n",
    "                    \"train/lr\": lr_now,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"step\": global_step,\n",
    "                    \"train/amp_skipped_step\": int(skipped),\n",
    "                    \"train/warmup_updates_done\": warmup_updates_done,\n",
    "                },\n",
    "                step=global_step\n",
    "            )\n",
    "            global_step += 1\n",
    "\n",
    "        # epoch averages\n",
    "        epoch_loss = running_loss / max(1, len(train_loader))\n",
    "        epoch_acc1 = running_acc1 / max(1, len(train_loader))\n",
    "        wandb.log(\n",
    "            {\"train/epoch_loss_avg\": epoch_loss, \"train/epoch_acc1_avg\": epoch_acc1, \"epoch\": epoch},\n",
    "            step=global_step\n",
    "        )\n",
    "        print(f\"[Epoch {epoch:02d}] loss={epoch_loss:.4f} acc1={epoch_acc1:.4f}\")\n",
    "\n",
    "        # step multi-step scheduler at end of epoch (safe ordering)\n",
    "        step_scheduler.step()\n",
    "\n",
    "        # ---- validation ----\n",
    "        if val_loader is not None:\n",
    "            val_metrics = validate_classification(model, val_loader, criterion, device, use_amp)\n",
    "            if val_metrics:\n",
    "                val_metrics[\"epoch\"] = epoch\n",
    "                wandb.log(val_metrics, step=global_step)\n",
    "                print(f\"         val_loss={val_metrics['val/loss']:.4f} val_acc1={val_metrics['val/acc1']:.4f}\")\n",
    "\n",
    "                score = float(val_metrics.get(eval_metric_key, float(\"nan\")))\n",
    "                if math.isfinite(score) and score > best_score:\n",
    "                    best_score = score\n",
    "                    best_path = os.path.join(ckpt_dir, f\"{run_name}_best.pth\")\n",
    "                    save_ckpt(best_path, epoch=epoch, global_step=global_step)\n",
    "                    print(f\"[BEST] Updated best @ epoch {epoch} ({eval_metric_key}={best_score:.4f})\")\n",
    "\n",
    "        # ---- checkpoint saving ----\n",
    "        if should_save(epoch):\n",
    "            ckpt_path = os.path.join(ckpt_dir, f\"{run_name}_epoch{epoch:02d}.pth\")\n",
    "            save_ckpt(ckpt_path, epoch=epoch, global_step=global_step)\n",
    "            print(f\"[CKPT] Saved {ckpt_path}\")\n",
    "\n",
    "    run.finish()\n",
    "    return {\"best_score\": best_score, \"best_ckpt\": best_path}\n",
    "\n",
    "# -------------------------\n",
    "# Grid search runner\n",
    "# -------------------------\n",
    "\n",
    "def run_grid(\n",
    "    grid: list,\n",
    "    build_model_fn,     # returns a NEW model instance\n",
    "    build_criterion_fn, # returns criterion given params\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device: str,\n",
    "    wandb_entity: str,\n",
    "    wandb_project: str,\n",
    "    base_config: dict,\n",
    "    n_epochs: int = 20,\n",
    "    ckpt_dir: str = \"./ckpts\",\n",
    "    use_amp: bool = True,\n",
    "):\n",
    "    results = []\n",
    "    for i, params in enumerate(grid):\n",
    "        model = build_model_fn(params)\n",
    "        criterion = build_criterion_fn(params)\n",
    "\n",
    "        run_name = params.get(\"run_name\", f\"exp_{i:02d}\")\n",
    "\n",
    "        out = train_reid_experiment(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            run_name=run_name,\n",
    "            wandb_project=wandb_project,\n",
    "            wandb_entity=wandb_entity,\n",
    "            config={**base_config, **params},\n",
    "            n_epochs=n_epochs,\n",
    "            lr=params.get(\"lr\", base_config.get(\"lr\", 3e-4)),\n",
    "            weight_decay=params.get(\"weight_decay\", base_config.get(\"weight_decay\", 1e-4)),\n",
    "            warmup_epochs=params.get(\"warmup_epochs\", base_config.get(\"warmup_epochs\", 1)),\n",
    "            milestones=params.get(\"milestones\", base_config.get(\"milestones\", [16])),\n",
    "            gamma=params.get(\"gamma\", base_config.get(\"gamma\", 0.1)),\n",
    "            use_amp=use_amp,\n",
    "            save_every=params.get(\"save_every\", 5),\n",
    "            always_save_epochs=params.get(\"always_save_epochs\", (4,5,6)),\n",
    "            ckpt_dir=ckpt_dir,\n",
    "            extra_state=params.get(\"extra_state\", {}),\n",
    "        )\n",
    "        results.append({**params, **out})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.E. Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineClassifier(nn.Module):\n",
    "    def __init__(self, in_dim: int, num_classes: int, s: float = 30.0):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(num_classes, in_dim))\n",
    "        nn.init.normal_(self.weight, std=0.01)\n",
    "        self.s = s\n",
    "\n",
    "    def forward(self, x_normed: torch.Tensor, labels=None) -> torch.Tensor:\n",
    "        # x_normed: already L2-normalized features (B, D)\n",
    "        w = F.normalize(self.weight, dim=1)           # (C, D)\n",
    "        logits = x_normed @ w.t()                     # cosine similarity\n",
    "        return self.s * logits                        # scale for CE stability\n",
    "    \n",
    "class ReIDNet(nn.Module):\n",
    "    def __init__(self, emb_dim: int, num_classes: int, s: float = 30.0):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-2])  # conv until layer4\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(2048, emb_dim)\n",
    "        self.cls = CosineClassifier(emb_dim, num_classes, s=s)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        f = self.backbone(x)                   # (B,2048,H',W')\n",
    "        f = self.pool(f).flatten(1)            # (B,2048)\n",
    "        z = self.fc(f)                         # (B,emb_dim)\n",
    "        z = F.normalize(z, dim=1)              # normalized embeddings\n",
    "        logits = self.cls(z, labels=labels)    # scaled cosine logits\n",
    "        return logits, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T19:17:01.427677Z",
     "iopub.status.busy": "2026-02-04T19:17:01.427326Z",
     "iopub.status.idle": "2026-02-04T19:43:05.815430Z",
     "shell.execute_reply": "2026-02-04T19:43:05.814298Z",
     "shell.execute_reply.started": "2026-02-04T19:17:01.427648Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_ce_valsplit</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/8c0f1og0' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/8c0f1og0</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260204_191146-8c0f1og0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260204_191701-ikh2nuur</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/ikh2nuur' target=\"_blank\">reid_r50_ce_valsplit</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/ikh2nuur' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/ikh2nuur</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=4.5272 acc1=0.1899\n",
      "         val_loss=8.8417 val_acc1=0.0000\n",
      "[BEST] Updated best @ epoch 1 (val/acc1=0.0000)\n",
      "[Epoch 02] loss=0.7688 acc1=0.8122\n",
      "         val_loss=10.4154 val_acc1=0.0029\n",
      "[BEST] Updated best @ epoch 2 (val/acc1=0.0029)\n",
      "[Epoch 03] loss=0.1697 acc1=0.9616\n",
      "         val_loss=10.5539 val_acc1=0.0000\n",
      "[Epoch 04] loss=0.0740 acc1=0.9859\n",
      "         val_loss=10.6039 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/reid_r50_ce_valsplit_epoch04.pth\n",
      "[Epoch 05] loss=0.0347 acc1=0.9944\n",
      "         val_loss=10.8112 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/reid_r50_ce_valsplit_epoch05.pth\n",
      "[Epoch 06] loss=0.0211 acc1=0.9977\n",
      "         val_loss=10.6559 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/reid_r50_ce_valsplit_epoch06.pth\n",
      "[Epoch 07] loss=0.0206 acc1=0.9967\n",
      "         val_loss=10.7116 val_acc1=0.0006\n",
      "[Epoch 08] loss=0.0317 acc1=0.9941\n",
      "         val_loss=10.8552 val_acc1=0.0000\n",
      "[Epoch 09] loss=0.0315 acc1=0.9947\n",
      "         val_loss=10.7031 val_acc1=0.0000\n",
      "[Epoch 10] loss=0.0353 acc1=0.9927\n",
      "         val_loss=10.9017 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/reid_r50_ce_valsplit_epoch10.pth\n",
      "[Epoch 11] loss=0.0740 acc1=0.9823\n",
      "         val_loss=11.1080 val_acc1=0.0012\n",
      "[Epoch 12] loss=0.0904 acc1=0.9802\n",
      "         val_loss=11.4428 val_acc1=0.0012\n",
      "[Epoch 13] loss=0.0705 acc1=0.9825\n",
      "         val_loss=11.6281 val_acc1=0.0006\n",
      "[Epoch 14] loss=0.0511 acc1=0.9874\n",
      "         val_loss=11.6628 val_acc1=0.0006\n",
      "[Epoch 15] loss=0.0342 acc1=0.9923\n",
      "         val_loss=11.6475 val_acc1=0.0006\n",
      "[CKPT] Saved ./ckpts/reid_r50_ce_valsplit_epoch15.pth\n",
      "[Epoch 16] loss=0.0347 acc1=0.9937\n",
      "         val_loss=11.9267 val_acc1=0.0006\n",
      "[Epoch 17] loss=0.0131 acc1=0.9977\n",
      "         val_loss=11.8407 val_acc1=0.0012\n",
      "[Epoch 18] loss=0.0055 acc1=0.9989\n",
      "         val_loss=11.9357 val_acc1=0.0006\n",
      "[Epoch 19] loss=0.0049 acc1=0.9993\n",
      "         val_loss=11.9270 val_acc1=0.0006\n",
      "[Epoch 20] loss=0.0036 acc1=0.9996\n",
      "         val_loss=11.9621 val_acc1=0.0006\n",
      "[CKPT] Saved ./ckpts/reid_r50_ce_valsplit_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/acc1</td><td></td></tr><tr><td>train/amp_skipped_step</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/epoch_acc1_avg</td><td></td></tr><tr><td>train/epoch_loss_avg</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/max_prob_mean</td><td></td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>step</td><td>3119</td></tr><tr><td>train/acc1</td><td>1</td></tr><tr><td>train/amp_skipped_step</td><td>0</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/epoch_acc1_avg</td><td>0.9996</td></tr><tr><td>train/epoch_loss_avg</td><td>0.00356</td></tr><tr><td>train/loss</td><td>0.00257</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/max_prob_mean</td><td>0.99756</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_ce_valsplit</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/ikh2nuur' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/ikh2nuur</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260204_191701-ikh2nuur/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/3402330671.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mextra_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"num_classes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"emb_dim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pid2label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_reid_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid2label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     )\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "def build_model_ce(params):\n",
    "    return ReIDNet(emb_dim=emb_dim, num_classes=num_classes)\n",
    "\n",
    "out_ce = train_reid_experiment(\n",
    "        model=build_model_ce({}),\n",
    "        train_loader=train_reid_loader,\n",
    "        val_loader=val_reid_loader, \n",
    "        criterion=build_criterion_ce({\"label_smoothing\": 0.0}),\n",
    "        device=device,\n",
    "        run_name=\"reid_r50_ce_valsplit\",\n",
    "        wandb_project=\"person re-id valsplit\",\n",
    "        wandb_entity=\"unibo-ai\",\n",
    "        config=base_config,\n",
    "        n_epochs=20,\n",
    "        lr=3e-4,\n",
    "        weight_decay=1e-4,\n",
    "        warmup_epochs=1,\n",
    "        milestones=[16],\n",
    "        gamma=0.1,\n",
    "        use_amp=use_amp,\n",
    "        save_every=5,\n",
    "        always_save_epochs=(4,5,6),\n",
    "        ckpt_dir=\"./ckpts\",\n",
    "        extra_state={\"num_classes\": num_classes, \"emb_dim\": emb_dim, \"pid2label\": train_reid_ds.pid2label},\n",
    "    )\n",
    "print(out_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T18:30:30.346355Z",
     "iopub.status.busy": "2026-02-05T18:30:30.345636Z",
     "iopub.status.idle": "2026-02-05T18:45:35.808021Z",
     "shell.execute_reply": "2026-02-05T18:45:35.807283Z",
     "shell.execute_reply.started": "2026-02-05T18:30:30.346320Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search ranking:\n",
      "  mAP = 44.55%\n",
      "  top- 1 = 91.38%\n",
      "search ranking:\n",
      "  mAP = 47.72%\n",
      "  top- 1 = 89.66%\n",
      "search ranking:\n",
      "  mAP = 45.95%\n",
      "  top- 1 = 89.66%\n",
      "search ranking:\n",
      "  mAP = 44.92%\n",
      "  top- 1 = 89.66%\n"
     ]
    }
   ],
   "source": [
    "# Load ckpts\n",
    "ckpt_epochs = [5, 20, 4, 6]\n",
    "ckpt_paths  = [f\"/kaggle/input/ce-weights-vs/reid_r50_ce_valsplit_epoch{e:02d}.pth\" for e in ckpt_epochs]\n",
    "\n",
    "# Instantiate model\n",
    "emb_dim = 512\n",
    "num_classes = len(train_reid_ds.pids)\n",
    "model_reid_ce = ReIDNet( \n",
    "            emb_dim=emb_dim,\n",
    "            num_classes=num_classes,\n",
    "        ).to(device)\n",
    "\n",
    "# Eval\n",
    "results = {}\n",
    "for epoch, ckpt_path in zip(ckpt_epochs, ckpt_paths):\n",
    "    ret = eval_prw_validation_person_search(\n",
    "        ckpt_path=ckpt_path,\n",
    "        model=model_reid_ce,\n",
    "        val_view=val_view,\n",
    "        val_ds=det_train_ds,                 \n",
    "        val_detections=train_detections,\n",
    "        transform=test_reid_tf,\n",
    "        device=device,\n",
    "        det_thresh=0.3,\n",
    "        ignore_cam_id=True,\n",
    "    )\n",
    "    results[epoch] = ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model selection is performed on a validation split using a PRW-style person search protocol. Query identities are drawn from a validation subset disjoint from the training identities, while the gallery consists of all training images. Although the detector is trained on the gallery split, it is kept fixed across all evaluations, making the validation scores suitable for relative model comparison despite being slightly optimistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CosFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T14:59:13.048375Z",
     "iopub.status.busy": "2026-02-05T14:59:13.048049Z",
     "iopub.status.idle": "2026-02-05T15:48:48.788352Z",
     "shell.execute_reply": "2026-02-05T15:48:48.787605Z",
     "shell.execute_reply.started": "2026-02-05T14:59:13.048351Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">r50_cosface_m10_s64</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/uoi4pl9s' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/uoi4pl9s</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260205_145454-uoi4pl9s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260205_145913-71ito1mp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/71ito1mp' target=\"_blank\">r50_cosface_m10_s64</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/71ito1mp' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/71ito1mp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=7.2941 acc1=0.0680\n",
      "         val_loss=12.2908 val_acc1=0.0000\n",
      "[BEST] Updated best @ epoch 1 (val/acc1=0.0000)\n",
      "[Epoch 02] loss=1.8289 acc1=0.6039\n",
      "         val_loss=14.4597 val_acc1=0.0000\n",
      "[Epoch 03] loss=0.4974 acc1=0.8805\n",
      "         val_loss=14.7214 val_acc1=0.0000\n",
      "[Epoch 04] loss=0.1925 acc1=0.9506\n",
      "         val_loss=14.9596 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m10_s64_epoch04.pth\n",
      "[Epoch 05] loss=0.1205 acc1=0.9735\n",
      "         val_loss=14.7351 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m10_s64_epoch05.pth\n",
      "[Epoch 06] loss=0.0917 acc1=0.9791\n",
      "         val_loss=15.2182 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m10_s64_epoch06.pth\n",
      "[Epoch 07] loss=0.0611 acc1=0.9864\n",
      "         val_loss=15.0505 val_acc1=0.0000\n",
      "[Epoch 08] loss=0.0566 acc1=0.9879\n",
      "         val_loss=15.1442 val_acc1=0.0000\n",
      "[Epoch 09] loss=0.0714 acc1=0.9850\n",
      "         val_loss=15.2722 val_acc1=0.0000\n",
      "[Epoch 10] loss=0.0673 acc1=0.9857\n",
      "         val_loss=15.0646 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m10_s64_epoch10.pth\n",
      "[Epoch 11] loss=0.0581 acc1=0.9866\n",
      "         val_loss=14.9942 val_acc1=0.0000\n",
      "[Epoch 12] loss=0.0888 acc1=0.9796\n",
      "         val_loss=15.0210 val_acc1=0.0000\n",
      "[Epoch 13] loss=0.0805 acc1=0.9788\n",
      "         val_loss=14.9446 val_acc1=0.0000\n",
      "[Epoch 14] loss=0.0801 acc1=0.9799\n",
      "         val_loss=15.5104 val_acc1=0.0000\n",
      "[Epoch 15] loss=0.0881 acc1=0.9804\n",
      "         val_loss=15.1760 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m10_s64_epoch15.pth\n",
      "[Epoch 16] loss=0.0827 acc1=0.9802\n",
      "         val_loss=15.5099 val_acc1=0.0000\n",
      "[Epoch 17] loss=0.0324 acc1=0.9926\n",
      "         val_loss=15.8332 val_acc1=0.0000\n",
      "[Epoch 18] loss=0.0139 acc1=0.9969\n",
      "         val_loss=15.8006 val_acc1=0.0000\n",
      "[Epoch 19] loss=0.0076 acc1=0.9989\n",
      "         val_loss=15.9586 val_acc1=0.0000\n",
      "[Epoch 20] loss=0.0070 acc1=0.9991\n",
      "         val_loss=16.0020 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m10_s64_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/acc1</td><td></td></tr><tr><td>train/amp_skipped_step</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/epoch_acc1_avg</td><td></td></tr><tr><td>train/epoch_loss_avg</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/max_prob_mean</td><td></td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>step</td><td>3119</td></tr><tr><td>train/acc1</td><td>1</td></tr><tr><td>train/amp_skipped_step</td><td>0</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/epoch_acc1_avg</td><td>0.9991</td></tr><tr><td>train/epoch_loss_avg</td><td>0.00695</td></tr><tr><td>train/loss</td><td>0.00207</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/max_prob_mean</td><td>0.99805</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">r50_cosface_m10_s64</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/71ito1mp' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/71ito1mp</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260205_145913-71ito1mp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260205_152405-izucikmo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/izucikmo' target=\"_blank\">r50_cosface_m20_s64</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/izucikmo' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/izucikmo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=10.1797 acc1=0.0288\n",
      "         val_loss=15.7337 val_acc1=0.0000\n",
      "[BEST] Updated best @ epoch 1 (val/acc1=0.0000)\n",
      "[Epoch 02] loss=3.2940 acc1=0.4468\n",
      "         val_loss=17.7301 val_acc1=0.0000\n",
      "[Epoch 03] loss=1.0554 acc1=0.7754\n",
      "         val_loss=18.1513 val_acc1=0.0000\n",
      "[Epoch 04] loss=0.4620 acc1=0.8937\n",
      "         val_loss=18.4555 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m20_s64_epoch04.pth\n",
      "[Epoch 05] loss=0.2359 acc1=0.9439\n",
      "         val_loss=18.7480 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m20_s64_epoch05.pth\n",
      "[Epoch 06] loss=0.1699 acc1=0.9626\n",
      "         val_loss=18.6238 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m20_s64_epoch06.pth\n",
      "[Epoch 07] loss=0.1572 acc1=0.9656\n",
      "         val_loss=18.9611 val_acc1=0.0000\n",
      "[Epoch 08] loss=0.1150 acc1=0.9724\n",
      "         val_loss=19.1750 val_acc1=0.0000\n",
      "[Epoch 09] loss=0.1136 acc1=0.9750\n",
      "         val_loss=18.8917 val_acc1=0.0000\n",
      "[Epoch 10] loss=0.1015 acc1=0.9748\n",
      "         val_loss=19.0974 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m20_s64_epoch10.pth\n",
      "[Epoch 11] loss=0.1341 acc1=0.9687\n",
      "         val_loss=19.1861 val_acc1=0.0000\n",
      "[Epoch 12] loss=0.1206 acc1=0.9732\n",
      "         val_loss=18.7492 val_acc1=0.0000\n",
      "[Epoch 13] loss=0.1442 acc1=0.9649\n",
      "         val_loss=18.7654 val_acc1=0.0000\n",
      "[Epoch 14] loss=0.1028 acc1=0.9774\n",
      "         val_loss=19.2388 val_acc1=0.0000\n",
      "[Epoch 15] loss=0.1008 acc1=0.9783\n",
      "         val_loss=18.8086 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m20_s64_epoch15.pth\n",
      "[Epoch 16] loss=0.1002 acc1=0.9756\n",
      "         val_loss=18.8468 val_acc1=0.0000\n",
      "[Epoch 17] loss=0.0442 acc1=0.9899\n",
      "         val_loss=19.2169 val_acc1=0.0000\n",
      "[Epoch 18] loss=0.0177 acc1=0.9966\n",
      "         val_loss=19.2342 val_acc1=0.0000\n",
      "[Epoch 19] loss=0.0136 acc1=0.9974\n",
      "         val_loss=19.1520 val_acc1=0.0000\n",
      "[Epoch 20] loss=0.0109 acc1=0.9979\n",
      "         val_loss=19.3272 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_cosface_m20_s64_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/acc1</td><td></td></tr><tr><td>train/amp_skipped_step</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/epoch_acc1_avg</td><td></td></tr><tr><td>train/epoch_loss_avg</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/max_prob_mean</td><td></td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>step</td><td>3119</td></tr><tr><td>train/acc1</td><td>1</td></tr><tr><td>train/amp_skipped_step</td><td>0</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/epoch_acc1_avg</td><td>0.9979</td></tr><tr><td>train/epoch_loss_avg</td><td>0.01087</td></tr><tr><td>train/loss</td><td>0.00176</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/max_prob_mean</td><td>0.99805</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">r50_cosface_m20_s64</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/izucikmo' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/izucikmo</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260205_152405-izucikmo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'run_name': 'r50_cosface_m10_s64', 'loss_name': 'cosface', 'm': 0.1, 's': 30, 'weight_decay': 0.0001, 'best_score': 0.0, 'best_ckpt': './ckpts/r50_cosface_m10_s64_best.pth'}, {'run_name': 'r50_cosface_m20_s64', 'loss_name': 'cosface', 'm': 0.2, 's': 30, 'weight_decay': 0.0001, 'best_score': 0.0, 'best_ckpt': './ckpts/r50_cosface_m20_s64_best.pth'}]\n"
     ]
    }
   ],
   "source": [
    "grid = [\n",
    "    {\"run_name\": \"r50_cosface_m10_s30\", \"loss_name\": \"cosface\", \"m\": 0.10, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "    {\"run_name\": \"r50_cosface_m20_s30\", \"loss_name\": \"cosface\", \"m\": 0.20, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "results_cf = run_grid(\n",
    "    grid=grid,\n",
    "    build_model_fn=build_model_margin,\n",
    "    build_criterion_fn=build_criterion_ce,\n",
    "    train_loader=train_reid_loader,\n",
    "    val_loader=val_reid_loader,\n",
    "    device=device,\n",
    "    wandb_entity=\"unibo-ai\",\n",
    "    wandb_project=\"person re-id valsplit\",\n",
    "    base_config=base_config,\n",
    "    n_epochs=20,\n",
    "    ckpt_dir=\"./ckpts\",\n",
    "    use_amp=use_amp,\n",
    ")\n",
    "print(results_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T19:07:54.949062Z",
     "iopub.status.busy": "2026-02-05T19:07:54.948266Z",
     "iopub.status.idle": "2026-02-05T19:22:49.961719Z",
     "shell.execute_reply": "2026-02-05T19:22:49.961031Z",
     "shell.execute_reply.started": "2026-02-05T19:07:54.949031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will evaluate:\n",
      "  m=0.1 | s=30 | epoch=5 -> /kaggle/working/ckpts/r50_cosface_m10_s64_epoch05.pth\n",
      "  m=0.1 | s=30 | epoch=20 -> /kaggle/working/ckpts/r50_cosface_m10_s64_epoch20.pth\n",
      "  m=0.2 | s=30 | epoch=5 -> /kaggle/working/ckpts/r50_cosface_m20_s64_epoch05.pth\n",
      "  m=0.2 | s=30 | epoch=20 -> /kaggle/working/ckpts/r50_cosface_m20_s64_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 49.69%\n",
      "  top- 1 = 91.38%\n",
      "search ranking:\n",
      "  mAP = 51.03%\n",
      "  top- 1 = 91.38%\n",
      "search ranking:\n",
      "  mAP = 49.45%\n",
      "  top- 1 = 91.38%\n",
      "search ranking:\n",
      "  mAP = 50.25%\n",
      "  top- 1 = 89.66%\n",
      "\n",
      "Summary (mAP/top-1):\n",
      "m= 0.1 | epoch= 5 | mAP=0.4969 | top1=0.9138\n",
      "m= 0.1 | epoch=20 | mAP=0.5103 | top1=0.9138\n",
      "m= 0.2 | epoch= 5 | mAP=0.4945 | top1=0.9138\n",
      "m= 0.2 | epoch=20 | mAP=0.5025 | top1=0.8966\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Config: choose checkpoints\n",
    "# ==========================\n",
    "ckpt_epochs = [5, 20]\n",
    "\n",
    "# grid is a LIST of dicts\n",
    "m_list = [g[\"m\"] for g in grid]      # [0.10, 0.20]\n",
    "s = grid[0][\"s\"]                     # 30 (equal for evryone)\n",
    "\n",
    "# Build list of (m, epoch, path)\n",
    "ckpt_items = []\n",
    "for g in grid:\n",
    "    m = g[\"m\"]\n",
    "    s = g[\"s\"]\n",
    "    for e in ckpt_epochs:\n",
    "        ckpt_path = f\"/kaggle/working/ckpts/r50_cosface_m{int(m*100)}_s64_epoch{e:02d}.pth\"\n",
    "        ckpt_items.append((m, s, e, ckpt_path))\n",
    "\n",
    "print(\"Will evaluate:\")\n",
    "for m, s, e, p in ckpt_items:\n",
    "    print(f\"  m={m} | s={s} | epoch={e} -> {p}\")\n",
    "\n",
    "# ==============\n",
    "# Model builder \n",
    "# ==============\n",
    "def build_model_cosface(emb_dim: int, num_classes: int, m: float, s: float = 30):\n",
    "    return ReIDNetCosFace(emb_dim=emb_dim, num_classes=num_classes, m=m, s=s)\n",
    "\n",
    "# ========================\n",
    "# Instantiate + Eval loop\n",
    "# ========================\n",
    "emb_dim = 512\n",
    "num_classes = len(train_reid_ds.pids)\n",
    "\n",
    "results = {}  # key: (m, epoch)\n",
    "for m, s, epoch, ckpt_path in ckpt_items:\n",
    "\n",
    "    # Build a fresh model with the correct margin 'm'\n",
    "    model_reid_cf = build_model_cosface(\n",
    "        emb_dim=emb_dim,\n",
    "        num_classes=num_classes,\n",
    "        m=m,\n",
    "        s=s\n",
    "    ).to(device)\n",
    "\n",
    "    ret = eval_prw_validation_person_search(\n",
    "        ckpt_path=ckpt_path,\n",
    "        model=model_reid_cf,\n",
    "        val_view=val_view,\n",
    "        val_ds=det_train_ds,                 # gallery dataset (train split)\n",
    "        val_detections=train_detections,     # detections computed on det_train_ds IN THE SAME ORDER\n",
    "        transform=test_reid_tf,\n",
    "        device=device,\n",
    "        det_thresh=0.3,\n",
    "        ignore_cam_id=True,\n",
    "    )\n",
    "\n",
    "    results[(m, epoch)] = ret\n",
    "\n",
    "print(\"\\nSummary (mAP/top-1):\")\n",
    "for (m, epoch), ret in results.items():\n",
    "    print(f\"m={m:>4} | epoch={epoch:>2} | mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Best parameters: m = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T19:31:57.282592Z",
     "iopub.status.busy": "2026-02-05T19:31:57.281937Z",
     "iopub.status.idle": "2026-02-05T20:46:02.119321Z",
     "shell.execute_reply": "2026-02-05T20:46:02.118540Z",
     "shell.execute_reply.started": "2026-02-05T19:31:57.282562Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260205_193157-uno5ig87</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/uno5ig87' target=\"_blank\">r50_arcface_m15_s30</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/uno5ig87' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/uno5ig87</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=8.7263 acc1=0.0447\n",
      "         val_loss=13.8625 val_acc1=0.0000\n",
      "[BEST] Updated best @ epoch 1 (val/acc1=0.0000)\n",
      "[Epoch 02] loss=2.4163 acc1=0.5376\n",
      "         val_loss=15.9663 val_acc1=0.0000\n",
      "[Epoch 03] loss=0.6749 acc1=0.8421\n",
      "         val_loss=16.6071 val_acc1=0.0000\n",
      "[Epoch 04] loss=0.2599 acc1=0.9372\n",
      "         val_loss=16.8345 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m15_s30_epoch04.pth\n",
      "[Epoch 05] loss=0.1578 acc1=0.9615\n",
      "         val_loss=16.7625 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m15_s30_epoch05.pth\n",
      "[Epoch 06] loss=0.1078 acc1=0.9740\n",
      "         val_loss=16.8648 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m15_s30_epoch06.pth\n",
      "[Epoch 07] loss=0.0946 acc1=0.9796\n",
      "         val_loss=17.0357 val_acc1=0.0000\n",
      "[Epoch 08] loss=0.0742 acc1=0.9823\n",
      "         val_loss=16.8560 val_acc1=0.0000\n",
      "[Epoch 09] loss=0.0827 acc1=0.9815\n",
      "         val_loss=16.9248 val_acc1=0.0000\n",
      "[Epoch 10] loss=0.0754 acc1=0.9804\n",
      "         val_loss=17.2018 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m15_s30_epoch10.pth\n",
      "[Epoch 11] loss=0.0689 acc1=0.9835\n",
      "         val_loss=17.0460 val_acc1=0.0000\n",
      "[Epoch 12] loss=0.0890 acc1=0.9793\n",
      "         val_loss=16.9320 val_acc1=0.0000\n",
      "[Epoch 13] loss=0.0862 acc1=0.9796\n",
      "         val_loss=17.3703 val_acc1=0.0000\n",
      "[Epoch 14] loss=0.0751 acc1=0.9816\n",
      "         val_loss=17.7847 val_acc1=0.0000\n",
      "[Epoch 15] loss=0.0869 acc1=0.9803\n",
      "         val_loss=17.3708 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m15_s30_epoch15.pth\n",
      "[Epoch 16] loss=0.1099 acc1=0.9710\n",
      "         val_loss=18.0542 val_acc1=0.0000\n",
      "[Epoch 17] loss=0.0398 acc1=0.9904\n",
      "         val_loss=18.1145 val_acc1=0.0000\n",
      "[Epoch 18] loss=0.0200 acc1=0.9959\n",
      "         val_loss=18.0758 val_acc1=0.0000\n",
      "[Epoch 19] loss=0.0127 acc1=0.9978\n",
      "         val_loss=18.0108 val_acc1=0.0006\n",
      "[BEST] Updated best @ epoch 19 (val/acc1=0.0006)\n",
      "[Epoch 20] loss=0.0126 acc1=0.9981\n",
      "         val_loss=18.0725 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m15_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/acc1</td><td></td></tr><tr><td>train/amp_skipped_step</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/epoch_acc1_avg</td><td></td></tr><tr><td>train/epoch_loss_avg</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/max_prob_mean</td><td></td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>step</td><td>3119</td></tr><tr><td>train/acc1</td><td>1</td></tr><tr><td>train/amp_skipped_step</td><td>0</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/epoch_acc1_avg</td><td>0.9981</td></tr><tr><td>train/epoch_loss_avg</td><td>0.01263</td></tr><tr><td>train/loss</td><td>0.00587</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/max_prob_mean</td><td>0.99439</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">r50_arcface_m15_s30</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/uno5ig87' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/uno5ig87</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260205_193157-uno5ig87/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260205_195641-74j1f5og</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/74j1f5og' target=\"_blank\">r50_arcface_m25_s30</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/74j1f5og' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/74j1f5og</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=11.5534 acc1=0.0246\n",
      "         val_loss=16.9705 val_acc1=0.0000\n",
      "[BEST] Updated best @ epoch 1 (val/acc1=0.0000)\n",
      "[Epoch 02] loss=3.9489 acc1=0.4211\n",
      "         val_loss=19.8601 val_acc1=0.0000\n",
      "[Epoch 03] loss=1.2967 acc1=0.7569\n",
      "         val_loss=20.6129 val_acc1=0.0000\n",
      "[Epoch 04] loss=0.6011 acc1=0.8696\n",
      "         val_loss=21.0672 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m25_s30_epoch04.pth\n",
      "[Epoch 05] loss=0.3287 acc1=0.9246\n",
      "         val_loss=20.8346 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m25_s30_epoch05.pth\n",
      "[Epoch 06] loss=0.2405 acc1=0.9417\n",
      "         val_loss=21.0524 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m25_s30_epoch06.pth\n",
      "[Epoch 07] loss=0.1603 acc1=0.9629\n",
      "         val_loss=20.9591 val_acc1=0.0000\n",
      "[Epoch 08] loss=0.1342 acc1=0.9679\n",
      "         val_loss=21.2703 val_acc1=0.0000\n",
      "[Epoch 09] loss=0.1122 acc1=0.9755\n",
      "         val_loss=21.2566 val_acc1=0.0000\n",
      "[Epoch 10] loss=0.1236 acc1=0.9729\n",
      "         val_loss=21.2874 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m25_s30_epoch10.pth\n",
      "[Epoch 11] loss=0.1229 acc1=0.9701\n",
      "         val_loss=21.5438 val_acc1=0.0000\n",
      "[Epoch 12] loss=0.1295 acc1=0.9686\n",
      "         val_loss=21.6038 val_acc1=0.0000\n",
      "[Epoch 13] loss=0.1380 acc1=0.9693\n",
      "         val_loss=21.5164 val_acc1=0.0000\n",
      "[Epoch 14] loss=0.1656 acc1=0.9633\n",
      "         val_loss=21.8003 val_acc1=0.0000\n",
      "[Epoch 15] loss=0.1634 acc1=0.9615\n",
      "         val_loss=21.4407 val_acc1=0.0012\n",
      "[BEST] Updated best @ epoch 15 (val/acc1=0.0012)\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m25_s30_epoch15.pth\n",
      "[Epoch 16] loss=0.1187 acc1=0.9739\n",
      "         val_loss=21.8856 val_acc1=0.0000\n",
      "[Epoch 17] loss=0.0562 acc1=0.9859\n",
      "         val_loss=21.9812 val_acc1=0.0000\n",
      "[Epoch 18] loss=0.0202 acc1=0.9956\n",
      "         val_loss=21.8871 val_acc1=0.0000\n",
      "[Epoch 19] loss=0.0143 acc1=0.9971\n",
      "         val_loss=21.9394 val_acc1=0.0000\n",
      "[Epoch 20] loss=0.0097 acc1=0.9984\n",
      "         val_loss=21.8192 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m25_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/acc1</td><td></td></tr><tr><td>train/amp_skipped_step</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/epoch_acc1_avg</td><td></td></tr><tr><td>train/epoch_loss_avg</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/max_prob_mean</td><td></td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>step</td><td>3119</td></tr><tr><td>train/acc1</td><td>1</td></tr><tr><td>train/amp_skipped_step</td><td>0</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/epoch_acc1_avg</td><td>0.9984</td></tr><tr><td>train/epoch_loss_avg</td><td>0.00967</td></tr><tr><td>train/loss</td><td>0.00201</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/max_prob_mean</td><td>0.99801</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">r50_arcface_m25_s30</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/74j1f5og' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/74j1f5og</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260205_195641-74j1f5og/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260205_202120-2kjj94dc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/2kjj94dc' target=\"_blank\">r50_arcface_m35_s30</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/2kjj94dc' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/2kjj94dc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=14.2864 acc1=0.0194\n",
      "         val_loss=19.8587 val_acc1=0.0000\n",
      "[BEST] Updated best @ epoch 1 (val/acc1=0.0000)\n",
      "[Epoch 02] loss=5.6422 acc1=0.3491\n",
      "         val_loss=23.0986 val_acc1=0.0000\n",
      "[Epoch 03] loss=2.0914 acc1=0.6803\n",
      "         val_loss=24.1234 val_acc1=0.0000\n",
      "[Epoch 04] loss=1.0001 acc1=0.8231\n",
      "         val_loss=25.1027 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m35_s30_epoch04.pth\n",
      "[Epoch 05] loss=0.6299 acc1=0.8783\n",
      "         val_loss=24.7160 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m35_s30_epoch05.pth\n",
      "[Epoch 06] loss=0.4001 acc1=0.9214\n",
      "         val_loss=24.1981 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m35_s30_epoch06.pth\n",
      "[Epoch 07] loss=0.2622 acc1=0.9427\n",
      "         val_loss=24.9654 val_acc1=0.0000\n",
      "[Epoch 08] loss=0.2432 acc1=0.9492\n",
      "         val_loss=25.0552 val_acc1=0.0000\n",
      "[Epoch 09] loss=0.2541 acc1=0.9472\n",
      "         val_loss=24.8562 val_acc1=0.0000\n",
      "[Epoch 10] loss=0.2351 acc1=0.9506\n",
      "         val_loss=25.1614 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m35_s30_epoch10.pth\n",
      "[Epoch 11] loss=0.2753 acc1=0.9436\n",
      "         val_loss=25.2410 val_acc1=0.0000\n",
      "[Epoch 12] loss=0.2238 acc1=0.9516\n",
      "         val_loss=25.1596 val_acc1=0.0000\n",
      "[Epoch 13] loss=0.1718 acc1=0.9604\n",
      "         val_loss=25.2223 val_acc1=0.0000\n",
      "[Epoch 14] loss=0.1432 acc1=0.9689\n",
      "         val_loss=25.7008 val_acc1=0.0000\n",
      "[Epoch 15] loss=0.1659 acc1=0.9654\n",
      "         val_loss=25.7840 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m35_s30_epoch15.pth\n",
      "[Epoch 16] loss=0.1731 acc1=0.9658\n",
      "         val_loss=25.2078 val_acc1=0.0000\n",
      "[Epoch 17] loss=0.0801 acc1=0.9840\n",
      "         val_loss=25.5594 val_acc1=0.0000\n",
      "[Epoch 18] loss=0.0289 acc1=0.9935\n",
      "         val_loss=25.5969 val_acc1=0.0000\n",
      "[Epoch 19] loss=0.0212 acc1=0.9960\n",
      "         val_loss=25.5605 val_acc1=0.0000\n",
      "[Epoch 20] loss=0.0166 acc1=0.9970\n",
      "         val_loss=25.8576 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_m35_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/acc1</td><td></td></tr><tr><td>train/amp_skipped_step</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/epoch_acc1_avg</td><td></td></tr><tr><td>train/epoch_loss_avg</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/max_prob_mean</td><td></td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>step</td><td>3119</td></tr><tr><td>train/acc1</td><td>1</td></tr><tr><td>train/amp_skipped_step</td><td>0</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/epoch_acc1_avg</td><td>0.997</td></tr><tr><td>train/epoch_loss_avg</td><td>0.01658</td></tr><tr><td>train/loss</td><td>0.00145</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/max_prob_mean</td><td>0.99856</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">r50_arcface_m35_s30</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/2kjj94dc' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/2kjj94dc</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260205_202120-2kjj94dc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'run_name': 'r50_arcface_m15_s30', 'loss_name': 'arcface', 'm': 0.15, 's': 30, 'weight_decay': 0.0001, 'best_score': 0.0005787037037037037, 'best_ckpt': './ckpts/r50_arcface_m15_s30_best.pth'}, {'run_name': 'r50_arcface_m25_s30', 'loss_name': 'arcface', 'm': 0.25, 's': 30, 'weight_decay': 0.0001, 'best_score': 0.0011574074074074073, 'best_ckpt': './ckpts/r50_arcface_m25_s30_best.pth'}, {'run_name': 'r50_arcface_m35_s30', 'loss_name': 'arcface', 'm': 0.35, 's': 30, 'weight_decay': 0.0001, 'best_score': 0.0, 'best_ckpt': './ckpts/r50_arcface_m35_s30_best.pth'}]\n"
     ]
    }
   ],
   "source": [
    "grid = [\n",
    "    {\"run_name\": \"r50_arcface_m15_s30\", \"loss_name\": \"arcface\", \"m\": 0.15, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "    {\"run_name\": \"r50_arcface_m25_s30\", \"loss_name\": \"arcface\", \"m\": 0.25, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "    {\"run_name\": \"r50_arcface_m35_s30\", \"loss_name\": \"arcface\", \"m\": 0.35, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "results_af = run_grid(\n",
    "    grid=grid,\n",
    "    build_model_fn=build_model_margin,\n",
    "    build_criterion_fn=build_criterion_ce,\n",
    "    train_loader=train_reid_loader,\n",
    "    val_loader=val_reid_loader,\n",
    "    device=device,\n",
    "    wandb_entity=\"unibo-ai\",\n",
    "    wandb_project=\"person re-id valsplit\",\n",
    "    base_config=base_config,\n",
    "    n_epochs=20,\n",
    "    ckpt_dir=\"./ckpts\",\n",
    "    use_amp=use_amp,\n",
    ")\n",
    "print(results_af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T20:55:56.193364Z",
     "iopub.status.busy": "2026-02-05T20:55:56.192690Z",
     "iopub.status.idle": "2026-02-05T21:18:28.118248Z",
     "shell.execute_reply": "2026-02-05T21:18:28.117463Z",
     "shell.execute_reply.started": "2026-02-05T20:55:56.193336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will evaluate:\n",
      "  m=0.15 | s=30 | epoch=5 -> /kaggle/working/ckpts/r50_arcface_m15_s30_epoch05.pth\n",
      "  m=0.15 | s=30 | epoch=20 -> /kaggle/working/ckpts/r50_arcface_m15_s30_epoch20.pth\n",
      "  m=0.25 | s=30 | epoch=5 -> /kaggle/working/ckpts/r50_arcface_m25_s30_epoch05.pth\n",
      "  m=0.25 | s=30 | epoch=20 -> /kaggle/working/ckpts/r50_arcface_m25_s30_epoch20.pth\n",
      "  m=0.35 | s=30 | epoch=5 -> /kaggle/working/ckpts/r50_arcface_m35_s30_epoch05.pth\n",
      "  m=0.35 | s=30 | epoch=20 -> /kaggle/working/ckpts/r50_arcface_m35_s30_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 49.73%\n",
      "  top- 1 = 91.38%\n",
      "search ranking:\n",
      "  mAP = 49.59%\n",
      "  top- 1 = 91.38%\n",
      "search ranking:\n",
      "  mAP = 50.26%\n",
      "  top- 1 = 91.38%\n",
      "search ranking:\n",
      "  mAP = 53.14%\n",
      "  top- 1 = 87.93%\n",
      "search ranking:\n",
      "  mAP = 45.72%\n",
      "  top- 1 = 87.93%\n",
      "search ranking:\n",
      "  mAP = 50.34%\n",
      "  top- 1 = 91.38%\n",
      "\n",
      "Summary (mAP/top-1):\n",
      "m=0.15 | epoch= 5 | mAP=0.4973 | top1=0.9138\n",
      "m=0.15 | epoch=20 | mAP=0.4959 | top1=0.9138\n",
      "m=0.25 | epoch= 5 | mAP=0.5026 | top1=0.9138\n",
      "m=0.25 | epoch=20 | mAP=0.5314 | top1=0.8793\n",
      "m=0.35 | epoch= 5 | mAP=0.4572 | top1=0.8793\n",
      "m=0.35 | epoch=20 | mAP=0.5034 | top1=0.9138\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Config: choose checkpoints\n",
    "# ==========================\n",
    "ckpt_epochs = [5, 20]\n",
    "\n",
    "# grid is a LIST of dicts\n",
    "m_list = [g[\"m\"] for g in grid]      # [0.10, 0.20]\n",
    "s = grid[0][\"s\"]                     # 30 (uguale per tutti)\n",
    "\n",
    "# Build list of (m, epoch, path)\n",
    "ckpt_items = []\n",
    "for g in grid:\n",
    "    m = g[\"m\"]\n",
    "    s = g[\"s\"]\n",
    "    for e in ckpt_epochs:\n",
    "        ckpt_path = f\"/kaggle/working/ckpts/r50_arcface_m{int(m*100)}_s{s}_epoch{e:02d}.pth\"\n",
    "        ckpt_items.append((m, s, e, ckpt_path))\n",
    "\n",
    "print(\"Will evaluate:\")\n",
    "for m, s, e, p in ckpt_items:\n",
    "    print(f\"  m={m} | s={s} | epoch={e} -> {p}\")\n",
    "\n",
    "# ==============\n",
    "# Model builder \n",
    "# ==============\n",
    "def build_model_arcface(emb_dim: int, num_classes: int, m: float, s: float = 30):\n",
    "    return ReIDNetArcFace(emb_dim=emb_dim, num_classes=num_classes, m=m, s=s)\n",
    "\n",
    "# ========================\n",
    "# Instantiate + Eval loop\n",
    "# ========================\n",
    "emb_dim = 512\n",
    "num_classes = len(train_reid_ds.pids)\n",
    "\n",
    "results = {}  # key: (m, epoch)\n",
    "for m, s, epoch, ckpt_path in ckpt_items:\n",
    "\n",
    "    # Build a fresh model with the correct margin 'm'\n",
    "    model_reid_af = build_model_arcface(\n",
    "        emb_dim=emb_dim,\n",
    "        num_classes=num_classes,\n",
    "        m=m,\n",
    "        s=s\n",
    "    ).to(device)\n",
    "\n",
    "    ret = eval_prw_validation_person_search(\n",
    "        ckpt_path=ckpt_path,\n",
    "        model=model_reid_af,\n",
    "        val_view=val_view,\n",
    "        val_ds=det_train_ds,                 # gallery dataset (train split)\n",
    "        val_detections=train_detections,     # detections computed on det_train_ds IN THE SAME ORDER\n",
    "        transform=test_reid_tf,\n",
    "        device=device,\n",
    "        det_thresh=0.3,\n",
    "        ignore_cam_id=True,\n",
    "    )\n",
    "\n",
    "    results[(m, epoch)] = ret\n",
    "\n",
    "print(\"\\nSummary (mAP/top-1):\")\n",
    "for (m, epoch), ret in results.items():\n",
    "    print(f\"m={m:>4} | epoch={epoch:>2} | mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T11:30:24.719768Z",
     "iopub.status.busy": "2026-02-06T11:30:24.719190Z",
     "iopub.status.idle": "2026-02-06T11:44:58.888461Z",
     "shell.execute_reply": "2026-02-06T11:44:58.887667Z",
     "shell.execute_reply.started": "2026-02-06T11:30:24.719742Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will evaluate:\n",
      "  m=0.25 | s=30 | epoch=10 -> /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch10.pth\n",
      "  m=0.25 | s=30 | epoch=15 -> /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch15.pth\n",
      "  m=0.35 | s=30 | epoch=10 -> /kaggle/input/arcface-weights-vs/r50_arcface_m35_s30_epoch10.pth\n",
      "  m=0.35 | s=30 | epoch=15 -> /kaggle/input/arcface-weights-vs/r50_arcface_m35_s30_epoch15.pth\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch10.pth\n",
      "search ranking:\n",
      "  mAP = 52.85%\n",
      "  top- 1 = 86.21%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch15.pth\n",
      "search ranking:\n",
      "  mAP = 48.31%\n",
      "  top- 1 = 89.66%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-weights-vs/r50_arcface_m35_s30_epoch10.pth\n",
      "search ranking:\n",
      "  mAP = 46.48%\n",
      "  top- 1 = 89.66%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-weights-vs/r50_arcface_m35_s30_epoch15.pth\n",
      "search ranking:\n",
      "  mAP = 43.16%\n",
      "  top- 1 = 86.21%\n",
      "\n",
      "Summary (mAP/top-1):\n",
      "m=0.25 | epoch=10 | mAP=0.5285 | top1=0.8621\n",
      "m=0.25 | epoch=15 | mAP=0.4831 | top1=0.8966\n",
      "m=0.35 | epoch=10 | mAP=0.4648 | top1=0.8966\n",
      "m=0.35 | epoch=15 | mAP=0.4316 | top1=0.8621\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Config: choose checkpoints\n",
    "# ==========================\n",
    "ckpt_epochs = [10, 15]\n",
    "\n",
    "# grid is a LIST of dicts\n",
    "m_list = [g[\"m\"] for g in grid]      # [0.15, 0.25, 0.35]\n",
    "s = grid[0][\"s\"]                     # 30 \n",
    "\n",
    "# Build list of (m, epoch, path)\n",
    "ckpt_items = []\n",
    "for g in grid:\n",
    "    m = g[\"m\"]\n",
    "    s = g[\"s\"]\n",
    "    for e in ckpt_epochs:\n",
    "        ckpt_path = f\"/kaggle/input/arcface-weights-vs/r50_arcface_m{int(m*100)}_s{s}_epoch{e:02d}.pth\"\n",
    "        ckpt_items.append((m, s, e, ckpt_path))\n",
    "\n",
    "print(\"Will evaluate:\")\n",
    "for m, s, e, p in ckpt_items:\n",
    "    print(f\"  m={m} | s={s} | epoch={e} -> {p}\")\n",
    "\n",
    "# ==============\n",
    "# Model builder \n",
    "# ==============\n",
    "def build_model_arcface(emb_dim: int, num_classes: int, m: float, s: float = 30):\n",
    "    return ReIDNetArcFace(emb_dim=emb_dim, num_classes=num_classes, m=m, s=s)\n",
    "\n",
    "# ========================\n",
    "# Instantiate + Eval loop\n",
    "# ========================\n",
    "emb_dim = 512\n",
    "num_classes = len(train_reid_ds.pids)\n",
    "\n",
    "results = {}  # key: (m, epoch)\n",
    "for m, s, epoch, ckpt_path in ckpt_items:\n",
    "\n",
    "    # Build a fresh model with the correct margin 'm'\n",
    "    model_reid_af = build_model_arcface(\n",
    "        emb_dim=emb_dim,\n",
    "        num_classes=num_classes,\n",
    "        m=m,\n",
    "        s=s\n",
    "    ).to(device)\n",
    "\n",
    "    ret = eval_prw_validation_person_search(\n",
    "        ckpt_path=ckpt_path,\n",
    "        model=model_reid_af,\n",
    "        val_view=val_view,\n",
    "        val_ds=det_train_ds,                 # gallery dataset (train split)\n",
    "        val_detections=train_detections,     # detections computed on det_train_ds\n",
    "        transform=test_reid_tf,\n",
    "        device=device,\n",
    "        det_thresh=0.3,\n",
    "        ignore_cam_id=True,\n",
    "    )\n",
    "\n",
    "    results[(m, epoch)] = ret\n",
    "\n",
    "print(\"\\nSummary (mAP/top-1):\")\n",
    "for (m, epoch), ret in results.items():\n",
    "    print(f\"m={m:>4} | epoch={epoch:>2} | mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ArcFace was evaluated using a PRW-style validation protocol by varying the angular margin \\( m \\) and training epochs. The best configuration was obtained with \\( m = 0.25 \\) at epoch 20, achieving the highest mAP on the validation set.\n",
    "> \n",
    "> While this setting exhibits a slight decrease in Top-1 accuracy compared to earlier epochs, it provides a significantly better overall ranking performance, as reflected by the mAP metric, which is more indicative of retrieval quality in person search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ArcFace with ConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-02-06T12:15:29.028780Z",
     "iopub.status.busy": "2026-02-06T12:15:29.028269Z",
     "iopub.status.idle": "2026-02-06T13:31:23.450517Z",
     "shell.execute_reply": "2026-02-06T13:31:23.449523Z",
     "shell.execute_reply.started": "2026-02-06T12:15:29.028755Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 109M/109M [00:00<00:00, 188MB/s]  \n",
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtommaso-perniola\u001b[0m (\u001b[33munibo-ai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260206_121538-m9t4fa6c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/m9t4fa6c' target=\"_blank\">r50_arcface_cx_m15_s30</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/m9t4fa6c' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/m9t4fa6c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=7.9739 acc1=0.0851\n",
      "         val_loss=14.2004 val_acc1=0.0000\n",
      "[BEST] Updated best @ epoch 1 (val/acc1=0.0000)\n",
      "[Epoch 02] loss=1.8829 acc1=0.6282\n",
      "         val_loss=16.3302 val_acc1=0.0000\n",
      "[Epoch 03] loss=0.5904 acc1=0.8633\n",
      "         val_loss=16.8853 val_acc1=0.0000\n",
      "[Epoch 04] loss=0.2577 acc1=0.9379\n",
      "         val_loss=17.0712 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m15_s30_epoch04.pth\n",
      "[Epoch 05] loss=0.1505 acc1=0.9655\n",
      "         val_loss=17.4490 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m15_s30_epoch05.pth\n",
      "[Epoch 06] loss=0.1101 acc1=0.9757\n",
      "         val_loss=17.1325 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m15_s30_epoch06.pth\n",
      "[Epoch 07] loss=0.1142 acc1=0.9725\n",
      "         val_loss=18.0704 val_acc1=0.0000\n",
      "[Epoch 08] loss=0.0699 acc1=0.9845\n",
      "         val_loss=17.8111 val_acc1=0.0000\n",
      "[Epoch 09] loss=0.0738 acc1=0.9843\n",
      "         val_loss=18.5941 val_acc1=0.0000\n",
      "[Epoch 10] loss=0.0822 acc1=0.9783\n",
      "         val_loss=17.7873 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m15_s30_epoch10.pth\n",
      "[Epoch 11] loss=0.1211 acc1=0.9721\n",
      "         val_loss=18.2136 val_acc1=0.0000\n",
      "[Epoch 12] loss=0.1221 acc1=0.9699\n",
      "         val_loss=18.0477 val_acc1=0.0000\n",
      "[Epoch 13] loss=0.1149 acc1=0.9748\n",
      "         val_loss=18.6893 val_acc1=0.0000\n",
      "[Epoch 14] loss=0.1042 acc1=0.9743\n",
      "         val_loss=18.4800 val_acc1=0.0000\n",
      "[Epoch 15] loss=0.1162 acc1=0.9715\n",
      "         val_loss=19.1380 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m15_s30_epoch15.pth\n",
      "[Epoch 16] loss=0.0671 acc1=0.9821\n",
      "         val_loss=19.0264 val_acc1=0.0000\n",
      "[Epoch 17] loss=0.0354 acc1=0.9926\n",
      "         val_loss=19.1342 val_acc1=0.0000\n",
      "[Epoch 18] loss=0.0165 acc1=0.9973\n",
      "         val_loss=19.1355 val_acc1=0.0000\n",
      "[Epoch 19] loss=0.0160 acc1=0.9966\n",
      "         val_loss=19.0096 val_acc1=0.0000\n",
      "[Epoch 20] loss=0.0101 acc1=0.9981\n",
      "         val_loss=19.3959 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m15_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/acc1</td><td></td></tr><tr><td>train/amp_skipped_step</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/epoch_acc1_avg</td><td></td></tr><tr><td>train/epoch_loss_avg</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/max_prob_mean</td><td></td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>step</td><td>3119</td></tr><tr><td>train/acc1</td><td>1</td></tr><tr><td>train/amp_skipped_step</td><td>0</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/epoch_acc1_avg</td><td>0.9981</td></tr><tr><td>train/epoch_loss_avg</td><td>0.01005</td></tr><tr><td>train/loss</td><td>0.00296</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/max_prob_mean</td><td>0.99709</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">r50_arcface_cx_m15_s30</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/m9t4fa6c' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/m9t4fa6c</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260206_121538-m9t4fa6c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260206_124114-h4si5u93</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/h4si5u93' target=\"_blank\">r50_arcface_cx_m25_s30</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/h4si5u93' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/h4si5u93</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=10.9721 acc1=0.0420\n",
      "         val_loss=17.0537 val_acc1=0.0000\n",
      "[BEST] Updated best @ epoch 1 (val/acc1=0.0000)\n",
      "[Epoch 02] loss=3.2649 acc1=0.4897\n",
      "         val_loss=20.3256 val_acc1=0.0000\n",
      "[Epoch 03] loss=1.0703 acc1=0.7919\n",
      "         val_loss=20.3203 val_acc1=0.0000\n",
      "[Epoch 04] loss=0.5063 acc1=0.8883\n",
      "         val_loss=21.0719 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m25_s30_epoch04.pth\n",
      "[Epoch 05] loss=0.2969 acc1=0.9348\n",
      "         val_loss=20.9047 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m25_s30_epoch05.pth\n",
      "[Epoch 06] loss=0.2065 acc1=0.9534\n",
      "         val_loss=21.2208 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m25_s30_epoch06.pth\n",
      "[Epoch 07] loss=0.1724 acc1=0.9625\n",
      "         val_loss=21.3911 val_acc1=0.0000\n",
      "[Epoch 08] loss=0.1419 acc1=0.9659\n",
      "         val_loss=21.9920 val_acc1=0.0000\n",
      "[Epoch 09] loss=0.1594 acc1=0.9641\n",
      "         val_loss=22.2231 val_acc1=0.0000\n",
      "[Epoch 10] loss=0.1484 acc1=0.9679\n",
      "         val_loss=22.0017 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m25_s30_epoch10.pth\n",
      "[Epoch 11] loss=0.1587 acc1=0.9640\n",
      "         val_loss=22.1716 val_acc1=0.0000\n",
      "[Epoch 12] loss=0.1403 acc1=0.9674\n",
      "         val_loss=22.3146 val_acc1=0.0000\n",
      "[Epoch 13] loss=0.1111 acc1=0.9737\n",
      "         val_loss=22.2473 val_acc1=0.0000\n",
      "[Epoch 14] loss=0.1033 acc1=0.9761\n",
      "         val_loss=22.5421 val_acc1=0.0000\n",
      "[Epoch 15] loss=0.1426 acc1=0.9671\n",
      "         val_loss=22.8585 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m25_s30_epoch15.pth\n",
      "[Epoch 16] loss=0.1897 acc1=0.9578\n",
      "         val_loss=22.5413 val_acc1=0.0000\n",
      "[Epoch 17] loss=0.0590 acc1=0.9867\n",
      "         val_loss=22.9077 val_acc1=0.0000\n",
      "[Epoch 18] loss=0.0252 acc1=0.9939\n",
      "         val_loss=23.0432 val_acc1=0.0000\n",
      "[Epoch 19] loss=0.0242 acc1=0.9945\n",
      "         val_loss=23.0211 val_acc1=0.0000\n",
      "[Epoch 20] loss=0.0183 acc1=0.9962\n",
      "         val_loss=23.0795 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m25_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/acc1</td><td></td></tr><tr><td>train/amp_skipped_step</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/epoch_acc1_avg</td><td></td></tr><tr><td>train/epoch_loss_avg</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/max_prob_mean</td><td></td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>step</td><td>3119</td></tr><tr><td>train/acc1</td><td>1</td></tr><tr><td>train/amp_skipped_step</td><td>0</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/epoch_acc1_avg</td><td>0.99619</td></tr><tr><td>train/epoch_loss_avg</td><td>0.01829</td></tr><tr><td>train/loss</td><td>0.01211</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/max_prob_mean</td><td>0.9898</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">r50_arcface_cx_m25_s30</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/h4si5u93' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/h4si5u93</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260206_124114-h4si5u93/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260206_130610-o27fzb2l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/o27fzb2l' target=\"_blank\">r50_arcface_cx_m35_s30</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/o27fzb2l' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/o27fzb2l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=13.7599 acc1=0.0258\n",
      "         val_loss=20.4873 val_acc1=0.0000\n",
      "[BEST] Updated best @ epoch 1 (val/acc1=0.0000)\n",
      "[Epoch 02] loss=4.7452 acc1=0.4105\n",
      "         val_loss=23.4765 val_acc1=0.0000\n",
      "[Epoch 03] loss=1.7453 acc1=0.7173\n",
      "         val_loss=24.3141 val_acc1=0.0000\n",
      "[Epoch 04] loss=0.8285 acc1=0.8464\n",
      "         val_loss=24.5983 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m35_s30_epoch04.pth\n",
      "[Epoch 05] loss=0.5001 acc1=0.9018\n",
      "         val_loss=24.9620 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m35_s30_epoch05.pth\n",
      "[Epoch 06] loss=0.3350 acc1=0.9318\n",
      "         val_loss=24.8624 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m35_s30_epoch06.pth\n",
      "[Epoch 07] loss=0.3044 acc1=0.9376\n",
      "         val_loss=25.0709 val_acc1=0.0000\n",
      "[Epoch 08] loss=0.2379 acc1=0.9521\n",
      "         val_loss=25.0735 val_acc1=0.0000\n",
      "[Epoch 09] loss=0.2012 acc1=0.9578\n",
      "         val_loss=25.1220 val_acc1=0.0000\n",
      "[Epoch 10] loss=0.2273 acc1=0.9518\n",
      "         val_loss=25.7093 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m35_s30_epoch10.pth\n",
      "[Epoch 11] loss=0.2246 acc1=0.9552\n",
      "         val_loss=24.9730 val_acc1=0.0000\n",
      "[Epoch 12] loss=0.1999 acc1=0.9577\n",
      "         val_loss=25.5639 val_acc1=0.0000\n",
      "[Epoch 13] loss=0.2070 acc1=0.9598\n",
      "         val_loss=25.2601 val_acc1=0.0000\n",
      "[Epoch 14] loss=0.1663 acc1=0.9655\n",
      "         val_loss=25.6775 val_acc1=0.0006\n",
      "[BEST] Updated best @ epoch 14 (val/acc1=0.0006)\n",
      "[Epoch 15] loss=0.2023 acc1=0.9594\n",
      "         val_loss=25.8470 val_acc1=0.0006\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m35_s30_epoch15.pth\n",
      "[Epoch 16] loss=0.2042 acc1=0.9582\n",
      "         val_loss=25.7987 val_acc1=0.0000\n",
      "[Epoch 17] loss=0.0983 acc1=0.9807\n",
      "         val_loss=26.2340 val_acc1=0.0000\n",
      "[Epoch 18] loss=0.0418 acc1=0.9920\n",
      "         val_loss=26.2927 val_acc1=0.0000\n",
      "[Epoch 19] loss=0.0354 acc1=0.9933\n",
      "         val_loss=26.4826 val_acc1=0.0000\n",
      "[Epoch 20] loss=0.0365 acc1=0.9928\n",
      "         val_loss=26.2644 val_acc1=0.0000\n",
      "[CKPT] Saved ./ckpts/r50_arcface_cx_m35_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/acc1</td><td></td></tr><tr><td>train/amp_skipped_step</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/epoch_acc1_avg</td><td></td></tr><tr><td>train/epoch_loss_avg</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/max_prob_mean</td><td></td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>step</td><td>3119</td></tr><tr><td>train/acc1</td><td>1</td></tr><tr><td>train/amp_skipped_step</td><td>0</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/epoch_acc1_avg</td><td>0.99279</td></tr><tr><td>train/epoch_loss_avg</td><td>0.03653</td></tr><tr><td>train/loss</td><td>0.0172</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/max_prob_mean</td><td>0.98492</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">r50_arcface_cx_m35_s30</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/o27fzb2l' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/o27fzb2l</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260206_130610-o27fzb2l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'run_name': 'r50_arcface_cx_m15_s30', 'loss_name': 'arcface_cx', 'm': 0.15, 's': 30, 'weight_decay': 0.0001, 'best_score': 0.0, 'best_ckpt': './ckpts/r50_arcface_cx_m15_s30_best.pth'}, {'run_name': 'r50_arcface_cx_m25_s30', 'loss_name': 'arcface_cx', 'm': 0.25, 's': 30, 'weight_decay': 0.0001, 'best_score': 0.0, 'best_ckpt': './ckpts/r50_arcface_cx_m25_s30_best.pth'}, {'run_name': 'r50_arcface_cx_m35_s30', 'loss_name': 'arcface_cx', 'm': 0.35, 's': 30, 'weight_decay': 0.0001, 'best_score': 0.0005787037037037037, 'best_ckpt': './ckpts/r50_arcface_cx_m35_s30_best.pth'}]\n"
     ]
    }
   ],
   "source": [
    "grid = [\n",
    "    {\"run_name\": \"r50_arcface_cx_m15_s30\", \"loss_name\": \"arcface_cx\", \"m\": 0.15, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "    {\"run_name\": \"r50_arcface_cx_m25_s30\", \"loss_name\": \"arcface_cx\", \"m\": 0.25, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "    {\"run_name\": \"r50_arcface_cx_m35_s30\", \"loss_name\": \"arcface_cx\", \"m\": 0.35, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "results_af = run_grid(\n",
    "    grid=grid,\n",
    "    build_model_fn=build_model_margin,\n",
    "    build_criterion_fn=build_criterion_ce,\n",
    "    train_loader=train_reid_loader,\n",
    "    val_loader=val_reid_loader,\n",
    "    device=device,\n",
    "    wandb_entity=\"unibo-ai\",\n",
    "    wandb_project=\"person re-id valsplit\",\n",
    "    base_config=base_config_cx,\n",
    "    n_epochs=20,\n",
    "    ckpt_dir=\"./ckpts\",\n",
    "    use_amp=use_amp,\n",
    ")\n",
    "print(results_af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-02-06T15:12:14.347474Z",
     "iopub.status.busy": "2026-02-06T15:12:14.347084Z",
     "iopub.status.idle": "2026-02-06T15:55:09.165881Z",
     "shell.execute_reply": "2026-02-06T15:55:09.165044Z",
     "shell.execute_reply.started": "2026-02-06T15:12:14.347427Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will evaluate:\n",
      "  m=0.15 | s=30 | epoch=20 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m15_s30_epoch20.pth\n",
      "  m=0.15 | s=30 | epoch=15 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m15_s30_epoch15.pth\n",
      "  m=0.15 | s=30 | epoch=10 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m15_s30_epoch10.pth\n",
      "  m=0.15 | s=30 | epoch=5 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m15_s30_epoch05.pth\n",
      "  m=0.25 | s=30 | epoch=20 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch20.pth\n",
      "  m=0.25 | s=30 | epoch=15 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch15.pth\n",
      "  m=0.25 | s=30 | epoch=10 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch10.pth\n",
      "  m=0.25 | s=30 | epoch=5 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch05.pth\n",
      "  m=0.35 | s=30 | epoch=20 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m35_s30_epoch20.pth\n",
      "  m=0.35 | s=30 | epoch=15 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m35_s30_epoch15.pth\n",
      "  m=0.35 | s=30 | epoch=10 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m35_s30_epoch10.pth\n",
      "  m=0.35 | s=30 | epoch=5 -> /kaggle/input/arcface-cx-weights/r50_arcface_cx_m35_s30_epoch05.pth\n",
      "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 109M/109M [00:00<00:00, 191MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m15_s30_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 56.24%\n",
      "  top- 1 = 96.55%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m15_s30_epoch15.pth\n",
      "search ranking:\n",
      "  mAP = 53.98%\n",
      "  top- 1 = 89.66%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m15_s30_epoch10.pth\n",
      "search ranking:\n",
      "  mAP = 56.97%\n",
      "  top- 1 = 89.66%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m15_s30_epoch05.pth\n",
      "search ranking:\n",
      "  mAP = 59.54%\n",
      "  top- 1 = 91.38%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 56.85%\n",
      "  top- 1 = 89.66%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch15.pth\n",
      "search ranking:\n",
      "  mAP = 53.48%\n",
      "  top- 1 = 91.38%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch10.pth\n",
      "search ranking:\n",
      "  mAP = 57.68%\n",
      "  top- 1 = 86.21%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch05.pth\n",
      "search ranking:\n",
      "  mAP = 60.71%\n",
      "  top- 1 = 89.66%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m35_s30_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 54.35%\n",
      "  top- 1 = 87.93%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m35_s30_epoch15.pth\n",
      "search ranking:\n",
      "  mAP = 51.81%\n",
      "  top- 1 = 87.93%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m35_s30_epoch10.pth\n",
      "search ranking:\n",
      "  mAP = 54.81%\n",
      "  top- 1 = 93.10%\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/input/arcface-cx-weights/r50_arcface_cx_m35_s30_epoch05.pth\n",
      "search ranking:\n",
      "  mAP = 55.78%\n",
      "  top- 1 = 91.38%\n",
      "\n",
      "Summary (mAP/top-1):\n",
      "m=0.15 | epoch=20 | mAP=0.5624 | top1=0.9655\n",
      "m=0.15 | epoch=15 | mAP=0.5398 | top1=0.8966\n",
      "m=0.15 | epoch=10 | mAP=0.5697 | top1=0.8966\n",
      "m=0.15 | epoch= 5 | mAP=0.5954 | top1=0.9138\n",
      "m=0.25 | epoch=20 | mAP=0.5685 | top1=0.8966\n",
      "m=0.25 | epoch=15 | mAP=0.5348 | top1=0.9138\n",
      "m=0.25 | epoch=10 | mAP=0.5768 | top1=0.8621\n",
      "m=0.25 | epoch= 5 | mAP=0.6071 | top1=0.8966\n",
      "m=0.35 | epoch=20 | mAP=0.5435 | top1=0.8793\n",
      "m=0.35 | epoch=15 | mAP=0.5181 | top1=0.8793\n",
      "m=0.35 | epoch=10 | mAP=0.5481 | top1=0.9310\n",
      "m=0.35 | epoch= 5 | mAP=0.5578 | top1=0.9138\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Config: choose checkpoints\n",
    "# ==========================\n",
    "ckpt_epochs = [20, 15, 10, 5]\n",
    "grid = [\n",
    "    {\"run_name\": \"r50_arcface_cx_m15_s30\", \"loss_name\": \"arcface_cx\", \"m\": 0.15, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "    {\"run_name\": \"r50_arcface_cx_m25_s30\", \"loss_name\": \"arcface_cx\", \"m\": 0.25, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "    {\"run_name\": \"r50_arcface_cx_m35_s30\", \"loss_name\": \"arcface_cx\", \"m\": 0.35, \"s\": 30, \"weight_decay\": 1e-4},\n",
    "]\n",
    "\n",
    "# grid is a LIST of dicts\n",
    "m_list = [g[\"m\"] for g in grid]      # [0.15, 0.25, 0.35]\n",
    "s = grid[0][\"s\"]                     # 30 \n",
    "\n",
    "# Build list of (m, epoch, path)\n",
    "ckpt_items = []\n",
    "for g in grid:\n",
    "    m = g[\"m\"]\n",
    "    s = g[\"s\"]\n",
    "    for e in ckpt_epochs:\n",
    "        ckpt_path = f\"/kaggle/input/arcface-cx-weights/r50_arcface_cx_m{int(m*100)}_s{s}_epoch{e:02d}.pth\"\n",
    "        ckpt_items.append((m, s, e, ckpt_path))\n",
    "\n",
    "print(\"Will evaluate:\")\n",
    "for m, s, e, p in ckpt_items:\n",
    "    print(f\"  m={m} | s={s} | epoch={e} -> {p}\")\n",
    "\n",
    "# ==============\n",
    "# Model builder \n",
    "# ==============\n",
    "def build_model_arcface_cx(emb_dim: int, num_classes: int, m: float, s: float = 30):\n",
    "    return ReIDNetArcFaceConvNeXt(emb_dim=emb_dim, num_classes=num_classes, m=m, s=s)\n",
    "\n",
    "# ========================\n",
    "# Instantiate + Eval loop\n",
    "# ========================\n",
    "emb_dim = 512\n",
    "num_classes = len(train_reid_ds.pids)\n",
    "\n",
    "results = {}  # key: (m, epoch)\n",
    "for m, s, epoch, ckpt_path in ckpt_items:\n",
    "\n",
    "    # Build a fresh model with the correct margin 'm'\n",
    "    model_reid_af_cx = build_model_arcface_cx(\n",
    "        emb_dim=emb_dim,\n",
    "        num_classes=num_classes,\n",
    "        m=m,\n",
    "        s=s\n",
    "    ).to(device)\n",
    "\n",
    "    ret = eval_prw_validation_person_search(\n",
    "        ckpt_path=ckpt_path,\n",
    "        model=model_reid_af_cx,\n",
    "        val_view=val_view,\n",
    "        val_ds=det_train_ds,                 # gallery dataset (train split)\n",
    "        val_detections=train_detections,     # detections computed on det_train_ds\n",
    "        transform=test_reid_tf,\n",
    "        device=device,\n",
    "        det_thresh=0.3,\n",
    "        ignore_cam_id=True,\n",
    "    )\n",
    "\n",
    "    results[(m, epoch)] = ret\n",
    "\n",
    "print(\"\\nSummary (mAP/top-1):\")\n",
    "for (m, epoch), ret in results.items():\n",
    "    print(f\"m={m:>4} | epoch={epoch:>2} | mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ArcFace with ConvNeXt exhibits a clear early-peak behavior, with the highest mAP values achieved at early epochs (epoch 5) for all margins. The configuration m=0.25, epoch 5 yields the best overall retrieval performance in terms of mAP.\n",
    "> \n",
    "> Interestingly, a higher margin (m=0.35) achieves the best Top-1 accuracy, suggesting a stronger emphasis on the most confident match, at the cost of a less optimal global ranking. This highlights a trade-off between global retrieval quality (mAP) and rank-1 precision, with larger margins favoring sharper decision boundaries but reduced ranking stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Angular) Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T10:24:14.190632Z",
     "iopub.status.busy": "2026-02-10T10:24:14.189971Z",
     "iopub.status.idle": "2026-02-10T10:24:14.250885Z",
     "shell.execute_reply": "2026-02-10T10:24:14.250294Z",
     "shell.execute_reply.started": "2026-02-10T10:24:14.190590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import Dict, Any, Optional, List\n",
    "\n",
    "# =========================\n",
    "# PK sampler (epoch-dependent) \n",
    "# =========================\n",
    "class RandomIdentitySampler(Sampler):\n",
    "    \"\"\"\n",
    "    Samples P identities, and for each identity samples K instances.\n",
    "    Changes each epoch via set_epoch to avoid repeating identical batches.\n",
    "\n",
    "    - We set __len__ so that the number of batches per epoch is (approximately) constant\n",
    "      across different (P,K), when batch_size = P*K.\n",
    "    - This avoids 8x8 having ~2x steps vs 16x4 just because K is larger.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, num_identities: int, num_instances: int, seed: int = 42):\n",
    "        self.dataset = dataset\n",
    "        self.P = int(num_identities)\n",
    "        self.K = int(num_instances)\n",
    "        self.seed = int(seed)\n",
    "        self.epoch = 0\n",
    "\n",
    "        # label -> indices\n",
    "        self.index_dict = {}\n",
    "        for idx in range(len(dataset)):\n",
    "            _, label, _, _ = dataset[idx]  # (crop, label, pid, camid)\n",
    "            lab = int(label)\n",
    "            self.index_dict.setdefault(lab, []).append(idx)\n",
    "\n",
    "        self.labels = list(self.index_dict.keys())\n",
    "        self.num_samples_per_batch = self.P * self.K\n",
    "\n",
    "        # Set epoch length to ensure a fixed number of batches per epoch, regardless of P and K.\n",
    "        target_batches_per_epoch = max(1, len(self.labels) // self.P)\n",
    "        self.length = target_batches_per_epoch * self.num_samples_per_batch\n",
    "        # ----------------------------\n",
    "\n",
    "    def set_epoch(self, epoch: int):\n",
    "        self.epoch = int(epoch)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __iter__(self):\n",
    "        g = np.random.RandomState(self.seed + self.epoch)\n",
    "\n",
    "        labels = self.labels.copy()\n",
    "        g.shuffle(labels)\n",
    "\n",
    "        batch = []\n",
    "        n_yielded = 0\n",
    "        for lab in labels:\n",
    "            idxs = self.index_dict.get(lab, [])\n",
    "            if not idxs:\n",
    "                continue\n",
    "\n",
    "            # sample K instances (with replacement if not enough)\n",
    "            if len(idxs) >= self.K:\n",
    "                chosen = g.choice(idxs, size=self.K, replace=False)\n",
    "            else:\n",
    "                chosen = g.choice(idxs, size=self.K, replace=True)\n",
    "\n",
    "            batch.extend(chosen.tolist())\n",
    "\n",
    "            if len(batch) == self.num_samples_per_batch:\n",
    "                yield from batch\n",
    "                n_yielded += len(batch)\n",
    "                batch = []\n",
    "\n",
    "                # stop once we hit the fixed epoch length\n",
    "                if n_yielded >= self.length:\n",
    "                    return\n",
    "\n",
    "        # If we didn't reach self.length due to too few labels, pad by resampling.\n",
    "        # This keeps batches/epoch constant.\n",
    "        while n_yielded < self.length:\n",
    "            # resample P identities\n",
    "            if len(self.labels) == 0:\n",
    "                return\n",
    "            chosen_labs = g.choice(self.labels, size=self.P, replace=(len(self.labels) < self.P))\n",
    "            batch = []\n",
    "            for lab in chosen_labs:\n",
    "                idxs = self.index_dict.get(int(lab), [])\n",
    "                if not idxs:\n",
    "                    continue\n",
    "                if len(idxs) >= self.K:\n",
    "                    chosen = g.choice(idxs, size=self.K, replace=False)\n",
    "                else:\n",
    "                    chosen = g.choice(idxs, size=self.K, replace=True)\n",
    "                batch.extend(chosen.tolist())\n",
    "\n",
    "            if len(batch) == self.num_samples_per_batch:\n",
    "                yield from batch\n",
    "                n_yielded += len(batch)\n",
    "\n",
    "# =========================\n",
    "# ArcFace init loader\n",
    "# =========================\n",
    "def load_arcface_init(model: nn.Module, arc_ckpt_path: str, verbose: bool = True) -> int:\n",
    "    ckpt = torch.load(arc_ckpt_path, map_location=\"cpu\")\n",
    "    arc_state = ckpt[\"model\"] if isinstance(ckpt, dict) and \"model\" in ckpt else ckpt\n",
    "\n",
    "    model_state = model.state_dict()\n",
    "    filtered = {k: v for k, v in arc_state.items() if k in model_state and v.shape == model_state[k].shape}\n",
    "\n",
    "    model_state.update(filtered)\n",
    "    model.load_state_dict(model_state)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[INIT] Loaded {len(filtered)}/{len(model_state)} params from {arc_ckpt_path}\")\n",
    "    return len(filtered)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Angular Triplet Loss (Batch-Hard)\n",
    "# =========================\n",
    "class AngularTripletLoss(nn.Module):\n",
    "    def __init__(self, margin_rad: float = 0.20, eps: float = 1e-7):\n",
    "        super().__init__()\n",
    "        self.margin = float(margin_rad)\n",
    "        self.eps = float(eps)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, labels: torch.Tensor):\n",
    "        B = emb.size(0)\n",
    "        if B < 2:\n",
    "            return emb.new_tensor(0.0)\n",
    "\n",
    "        labels = labels.view(-1)\n",
    "        cos = (emb @ emb.t()).clamp(-1.0 + self.eps, 1.0 - self.eps)\n",
    "        theta = torch.acos(cos)\n",
    "\n",
    "        same = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "        eye = torch.eye(B, dtype=torch.bool, device=emb.device)\n",
    "\n",
    "        pos_mask = same & ~eye\n",
    "        neg_mask = ~same\n",
    "\n",
    "        theta_pos = theta.masked_fill(~pos_mask, float(\"-inf\"))\n",
    "        theta_neg = theta.masked_fill(~neg_mask, float(\"inf\"))\n",
    "\n",
    "        hardest_pos = theta_pos.max(dim=1).values\n",
    "        hardest_neg = theta_neg.min(dim=1).values\n",
    "\n",
    "        valid = (hardest_pos > float(\"-inf\")) & (hardest_neg < float(\"inf\"))\n",
    "        if valid.sum().item() == 0:\n",
    "            return emb.new_tensor(0.0)\n",
    "\n",
    "        diff = hardest_pos[valid] - hardest_neg[valid] + self.margin\n",
    "        return F.softplus(diff).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def angular_batch_stats(emb: torch.Tensor, labels: torch.Tensor, eps: float = 1e-7):\n",
    "    \"\"\"\n",
    "    Computes the mean positive angle, mean negative angle, and fraction of valid anchors in the batch.\n",
    "    \"\"\"\n",
    "    B = emb.size(0)\n",
    "    if B < 2:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    cos = (emb @ emb.t()).clamp(-1.0 + eps, 1.0 - eps)\n",
    "    theta = torch.acos(cos)\n",
    "\n",
    "    same = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "    eye = torch.eye(B, dtype=torch.bool, device=emb.device)\n",
    "    pos_mask = same & ~eye\n",
    "    neg_mask = ~same\n",
    "\n",
    "    theta_pos = theta.masked_select(pos_mask)\n",
    "    theta_neg = theta.masked_select(neg_mask)\n",
    "\n",
    "    theta_pos_mat = theta.masked_fill(~pos_mask, float(\"-inf\"))\n",
    "    theta_neg_mat = theta.masked_fill(~neg_mask, float(\"inf\"))\n",
    "    hardest_pos = theta_pos_mat.max(dim=1).values\n",
    "    hardest_neg = theta_neg_mat.min(dim=1).values\n",
    "    valid = (hardest_pos > float(\"-inf\")) & (hardest_neg < float(\"inf\"))\n",
    "    valid_frac = valid.float().mean().item()\n",
    "\n",
    "    pos_mean = theta_pos.mean().item() if theta_pos.numel() else 0.0\n",
    "    neg_mean = theta_neg.mean().item() if theta_neg.numel() else 0.0\n",
    "    return pos_mean, neg_mean, valid_frac\n",
    "\n",
    "@torch.no_grad()\n",
    "def angular_hard_stats(emb: torch.Tensor, labels: torch.Tensor, eps: float = 1e-7):\n",
    "    \"\"\"\n",
    "    Computes the mean hardest positive angle, mean hardest negative angle, and their difference for valid anchors in the batch.\n",
    "    Returns:\n",
    "      hard_pos_mean, hard_neg_mean, diff_mean, valid_frac\n",
    "    \"\"\"\n",
    "    B = emb.size(0)\n",
    "    if B < 2:\n",
    "        return 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    labels = labels.view(-1)\n",
    "    cos = (emb @ emb.t()).clamp(-1.0 + eps, 1.0 - eps)\n",
    "    theta = torch.acos(cos)\n",
    "\n",
    "    same = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "    eye = torch.eye(B, dtype=torch.bool, device=emb.device)\n",
    "\n",
    "    pos_mask = same & ~eye\n",
    "    neg_mask = ~same\n",
    "\n",
    "    theta_pos = theta.masked_fill(~pos_mask, float(\"-inf\"))\n",
    "    theta_neg = theta.masked_fill(~neg_mask, float(\"inf\"))\n",
    "\n",
    "    hardest_pos = theta_pos.max(dim=1).values\n",
    "    hardest_neg = theta_neg.min(dim=1).values\n",
    "\n",
    "    valid = (hardest_pos > float(\"-inf\")) & (hardest_neg < float(\"inf\"))\n",
    "    if valid.sum().item() == 0:\n",
    "        return 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    hp = hardest_pos[valid]\n",
    "    hn = hardest_neg[valid]\n",
    "    diff = hp - hn\n",
    "\n",
    "    return hp.mean().item(), hn.mean().item(), diff.mean().item(), valid.float().mean().item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_triplet_val_epoch(\n",
    "    model: nn.Module,\n",
    "    criterion: nn.Module,\n",
    "    val_loader: DataLoader,\n",
    "    device: str,\n",
    "    use_amp: bool = True,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluates a single epoch on the validation set for a model trained with Angular Triplet Loss.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    loss_sum = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    acc_sum = 0.0\n",
    "    n_acc_batches = 0\n",
    "\n",
    "    pos_sum, neg_sum, valid_sum = 0.0, 0.0, 0.0\n",
    "    hardpos_sum, hardneg_sum, diff_sum = 0.0, 0.0, 0.0\n",
    "    n_stat_batches = 0\n",
    "\n",
    "    for crops, labels, pid, camid in val_loader:\n",
    "        crops = crops.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True).view(-1)\n",
    "\n",
    "        with autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "            emb = model(crops)\n",
    "            loss = criterion(emb, labels)\n",
    "\n",
    "        loss_sum += float(loss.item())\n",
    "        n_batches += 1\n",
    "\n",
    "        # 1-NN batch acc proxy\n",
    "        sim = emb @ emb.t()\n",
    "        B = sim.size(0)\n",
    "        if B >= 2:\n",
    "            sim.fill_diagonal_(-1e9)\n",
    "            nn_idx = sim.argmax(dim=1)\n",
    "            nn_labels = labels[nn_idx]\n",
    "            acc_sum += (nn_labels == labels).float().mean().item()\n",
    "            n_acc_batches += 1\n",
    "\n",
    "        # angle stats\n",
    "        pos_m, neg_m, valid_frac = angular_batch_stats(emb, labels)\n",
    "        hp_m, hn_m, d_m, v2 = angular_hard_stats(emb, labels)\n",
    "\n",
    "        pos_sum += pos_m\n",
    "        neg_sum += neg_m\n",
    "        valid_sum += valid_frac\n",
    "\n",
    "        hardpos_sum += hp_m\n",
    "        hardneg_sum += hn_m\n",
    "        diff_sum += d_m\n",
    "\n",
    "        n_stat_batches += 1\n",
    "\n",
    "    out = {}\n",
    "    out[\"loss\"] = loss_sum / max(1, n_batches)\n",
    "    out[\"1nn_acc\"] = acc_sum / max(1, n_acc_batches)\n",
    "\n",
    "    out[\"pos_angle_mean\"] = pos_sum / max(1, n_stat_batches)\n",
    "    out[\"neg_angle_mean\"] = neg_sum / max(1, n_stat_batches)\n",
    "    out[\"valid_anchor_frac\"] = valid_sum / max(1, n_stat_batches)\n",
    "\n",
    "    out[\"hard_pos_mean\"] = hardpos_sum / max(1, n_stat_batches)\n",
    "    out[\"hard_neg_mean\"] = hardneg_sum / max(1, n_stat_batches)\n",
    "    out[\"diff_mean\"] = diff_sum / max(1, n_stat_batches)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "# ===============\n",
    "# Train ONE run\n",
    "# ===============\n",
    "def train_one_angtriplet(\n",
    "    cfg: Dict[str, Any],\n",
    "    train_reid_ds,\n",
    "    val_reid_ds,\n",
    "    device: str,\n",
    "    num_workers: int = 2,\n",
    "    use_amp: bool = True,\n",
    "    wandb_project: str = \"person re-id valsplit\",\n",
    "    wandb_entity: str = \"unibo-ai\",\n",
    "    run_name_prefix: str = \"reid_r50_angtriplet\",\n",
    "    save_dir: str = \"./ckpts_angtriplet\",\n",
    "    save_every: int = 5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a ReID model with Angular Triplet Loss and PK sampling.\n",
    "      - LambdaLR warmup (stepped per-iteration)\n",
    "      - MultiStepLR (stepped per-epoch)\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------- SEED --------------------\n",
    "    seed = int(cfg[\"seed\"])\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # -------------------- LOADERS --------------------\n",
    "    P, K = int(cfg[\"P\"]), int(cfg[\"K\"])\n",
    "\n",
    "    train_sampler = RandomIdentitySampler(train_reid_ds, P, K, seed)\n",
    "    val_sampler   = RandomIdentitySampler(val_reid_ds,   P, K, seed + 999)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_reid_ds,\n",
    "        batch_size=P * K,\n",
    "        sampler=train_sampler,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_reid_ds,\n",
    "        batch_size=P * K,\n",
    "        sampler=val_sampler,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    # -------------------- MODEL --------------------\n",
    "    name_run = f\"{run_name_prefix}_P{P}K{K}_m{int(cfg['margin_rad']*100)}\"\n",
    "    model = ReIDNetEmbed(emb_dim=int(cfg[\"emb_dim\"])).to(device)\n",
    "\n",
    "    if cfg.get(\"init_from_arcface\", False):\n",
    "        load_arcface_init(model, cfg[\"arc_ckpt_path\"])\n",
    "        name_run = f\"{run_name_prefix}_af_P{P}K{K}_m{int(cfg['margin_rad']*100)}\"\n",
    "\n",
    "    # -------------------- OPT / LOSS --------------------\n",
    "    criterion = AngularTripletLoss(cfg[\"margin_rad\"])\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=float(cfg[\"lr\"]),\n",
    "        weight_decay=float(cfg[\"weight_decay\"]),\n",
    "    )\n",
    "\n",
    "    # -------------------- SCHEDULERS (same as before) --------------------\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    warmup_steps = max(1, int(cfg[\"warmup_epochs\"]) * steps_per_epoch)\n",
    "\n",
    "    def warmup_lambda(step: int) -> float:\n",
    "        if step < warmup_steps:\n",
    "            return (step + 1) / warmup_steps\n",
    "        return 1.0\n",
    "\n",
    "    warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "        optimizer, lr_lambda=warmup_lambda\n",
    "    )\n",
    "\n",
    "    step_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=list(cfg[\"milestones\"]),\n",
    "        gamma=float(cfg[\"gamma\"]),\n",
    "    )\n",
    "\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=use_amp)\n",
    "\n",
    "    # -------------------- WANDB --------------------\n",
    "    wandb.init(\n",
    "        entity=wandb_entity,\n",
    "        project=wandb_project,\n",
    "        config=cfg,\n",
    "        name=name_run,\n",
    "        reinit=True,\n",
    "    )\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    global_step = 0\n",
    "\n",
    "    # ==================== TRAIN LOOP ====================\n",
    "    for epoch in range(int(cfg[\"epochs\"])):\n",
    "        model.train()\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        val_sampler.set_epoch(epoch)\n",
    "\n",
    "        # epoch accumulators\n",
    "        train_loss_sum = 0.0\n",
    "        n_train_batches = 0\n",
    "\n",
    "        pos_sum, neg_sum, valid_sum = 0.0, 0.0, 0.0\n",
    "        hardpos_sum, hardneg_sum, diff_sum = 0.0, 0.0, 0.0\n",
    "        acc_sum = 0.0\n",
    "        n_stat_batches = 0\n",
    "\n",
    "        for crops, labels, _, _ in train_loader:\n",
    "            crops  = crops.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True).view(-1)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "                emb  = model(crops)\n",
    "                loss = criterion(emb, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # warmup per-iter\n",
    "            if global_step < warmup_steps:\n",
    "                warmup_scheduler.step()\n",
    "\n",
    "            # ---- stats (no_grad) ----\n",
    "            with torch.no_grad():\n",
    "                loss_val = float(loss.item())\n",
    "                emb_norm = emb.norm(dim=1).mean().item()\n",
    "\n",
    "                # 1-NN proxy\n",
    "                sim = emb @ emb.t()\n",
    "                B = sim.size(0)\n",
    "                if B >= 2:\n",
    "                    sim.fill_diagonal_(-1e9)\n",
    "                    nn_idx = sim.argmax(dim=1)\n",
    "                    nn_labels = labels[nn_idx]\n",
    "                    acc_batch = (nn_labels == labels).float().mean().item()\n",
    "                else:\n",
    "                    acc_batch = 0.0\n",
    "\n",
    "                pos_m, neg_m, valid_frac = angular_batch_stats(emb, labels)\n",
    "                hp_m, hn_m, d_m, _ = angular_hard_stats(emb, labels)\n",
    "\n",
    "                lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            # accumulators\n",
    "            train_loss_sum += loss_val\n",
    "            n_train_batches += 1\n",
    "\n",
    "            pos_sum += pos_m\n",
    "            neg_sum += neg_m\n",
    "            valid_sum += valid_frac\n",
    "\n",
    "            hardpos_sum += hp_m\n",
    "            hardneg_sum += hn_m\n",
    "            diff_sum += d_m\n",
    "\n",
    "            acc_sum += acc_batch\n",
    "            n_stat_batches += 1\n",
    "\n",
    "            # per-step wandb\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"step\": global_step,\n",
    "                    \"train/loss_step\": loss_val,\n",
    "                    \"train/lr\": lr_now,\n",
    "                    \"train/emb_norm_mean\": emb_norm,\n",
    "\n",
    "                    \"train/pos_angle_mean\": pos_m,\n",
    "                    \"train/neg_angle_mean\": neg_m,\n",
    "                    \"train/valid_anchor_frac\": valid_frac,\n",
    "\n",
    "                    \"train/hard_pos_mean\": hp_m,\n",
    "                    \"train/hard_neg_mean\": hn_m,\n",
    "                    \"train/diff_mean\": d_m,\n",
    "\n",
    "                    \"train/1nn_acc_batch\": acc_batch,\n",
    "                },\n",
    "                step=global_step,\n",
    "            )\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        # epoch means\n",
    "        train_loss = train_loss_sum / max(1, n_train_batches)\n",
    "        train_pos = pos_sum / max(1, n_stat_batches)\n",
    "        train_neg = neg_sum / max(1, n_stat_batches)\n",
    "        train_valid = valid_sum / max(1, n_stat_batches)\n",
    "        train_hp = hardpos_sum / max(1, n_stat_batches)\n",
    "        train_hn = hardneg_sum / max(1, n_stat_batches)\n",
    "        train_diff = diff_sum / max(1, n_stat_batches)\n",
    "        train_acc = acc_sum / max(1, n_stat_batches)\n",
    "\n",
    "        # multistep per-epoch\n",
    "        step_scheduler.step()\n",
    "\n",
    "        # validation\n",
    "        val_stats = eval_triplet_val_epoch(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            val_loader=val_loader,\n",
    "            device=device,\n",
    "            use_amp=use_amp,\n",
    "        )\n",
    "\n",
    "        # per-epoch wandb\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"train/loss_epoch\": train_loss,\n",
    "                \"train/pos_angle_mean_epoch\": train_pos,\n",
    "                \"train/neg_angle_mean_epoch\": train_neg,\n",
    "                \"train/valid_anchor_frac_epoch\": train_valid,\n",
    "                \"train/hard_pos_mean_epoch\": train_hp,\n",
    "                \"train/hard_neg_mean_epoch\": train_hn,\n",
    "                \"train/diff_mean_epoch\": train_diff,\n",
    "                \"train/1nn_acc_epoch\": train_acc,\n",
    "\n",
    "                \"val/loss\": val_stats[\"loss\"],\n",
    "                \"val/1nn_acc\": val_stats[\"1nn_acc\"],\n",
    "                \"val/pos_angle_mean\": val_stats[\"pos_angle_mean\"],\n",
    "                \"val/neg_angle_mean\": val_stats[\"neg_angle_mean\"],\n",
    "                \"val/valid_anchor_frac\": val_stats[\"valid_anchor_frac\"],\n",
    "                \"val/hard_pos_mean\": val_stats[\"hard_pos_mean\"],\n",
    "                \"val/hard_neg_mean\": val_stats[\"hard_neg_mean\"],\n",
    "                \"val/diff_mean\": val_stats[\"diff_mean\"],\n",
    "\n",
    "                \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                \"train/warmup_steps\": warmup_steps,\n",
    "                \"train/global_step\": global_step,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {epoch:02d}] \"\n",
    "            f\"train_loss={train_loss:.4f} | \"\n",
    "            f\"pos={train_pos:.3f} rad | neg={train_neg:.3f} rad | \"\n",
    "            f\"hard_diff={train_diff:.3f} rad | \"\n",
    "            f\"val_loss={val_stats['loss']:.4f} | \"\n",
    "            f\"val_1NN={val_stats['1nn_acc']:.4f} | \"\n",
    "            f\"lr={optimizer.param_groups[0]['lr']:.2e}\"\n",
    "        )\n",
    "\n",
    "        # -------------------- CKPT --------------------\n",
    "        if (epoch + 1) % int(save_every) == 0:\n",
    "            tag = \"af\" if cfg.get(\"init_from_arcface\", False) else \"scratch\"\n",
    "            ckpt_path = os.path.join(\n",
    "                save_dir,\n",
    "                f\"{run_name_prefix}_{tag}_P{P}K{K}_m{int(cfg['margin_rad']*100)}_epoch{epoch+1:02d}.pth\"\n",
    "            )\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"global_step\": global_step,\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"warmup_scheduler\": warmup_scheduler.state_dict(),\n",
    "                    \"step_scheduler\": step_scheduler.state_dict(),\n",
    "                    \"scaler\": scaler.state_dict() if use_amp else None,\n",
    "                    \"config\": cfg,\n",
    "                    \"P\": P,\n",
    "                    \"K\": K,\n",
    "                },\n",
    "                ckpt_path,\n",
    "            )\n",
    "            print(f\"[CKPT] Saved {ckpt_path}\")\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "# ============\n",
    "# Grid runner \n",
    "# ============\n",
    "def run_grid_angtriplet(\n",
    "    train_reid_ds,\n",
    "    val_reid_ds,\n",
    "    device: str,\n",
    "    grid: List[Dict[str, Any]],\n",
    "    arc_ckpt_path: Optional[str] = None,\n",
    "    num_workers: int = 2,\n",
    "    use_amp: bool = True,\n",
    "    wandb_project: str = \"person re-id valsplit\",\n",
    "    wandb_entity: str = \"unibo-ai\",\n",
    "    save_dir: str = \"./ckpts_angtriplet\",\n",
    "    save_every: int = 5,\n",
    ") -> List[Dict[str, Any]]:\n",
    "\n",
    "    results = []\n",
    "    print(f\"[RUNS] Total runs: {len(grid)}\")\n",
    "\n",
    "    for i, cfg in enumerate(grid, 1):\n",
    "        cfg = copy.deepcopy(cfg)\n",
    "\n",
    "        # inject global arc path if provided\n",
    "        if arc_ckpt_path is not None:\n",
    "            cfg[\"arc_ckpt_path\"] = arc_ckpt_path\n",
    "\n",
    "        # safety\n",
    "        if int(cfg[\"P\"]) * int(cfg[\"K\"]) <= 1:\n",
    "            raise ValueError(f\"Bad P,K: {cfg['P']} {cfg['K']}\")\n",
    "\n",
    "        if bool(cfg.get(\"init_from_arcface\", False)) and not cfg.get(\"arc_ckpt_path\", None):\n",
    "            raise ValueError(\"init_from_arcface=True but arc_ckpt_path is missing.\")\n",
    "\n",
    "        print(f\"\\n[RUN {i}/{len(grid)}] {cfg}\")\n",
    "\n",
    "        out = train_one_angtriplet(\n",
    "            cfg=cfg,\n",
    "            train_reid_ds=train_reid_ds,\n",
    "            val_reid_ds=val_reid_ds,\n",
    "            device=device,\n",
    "            num_workers=num_workers,\n",
    "            use_amp=use_amp,\n",
    "            wandb_project=wandb_project,\n",
    "            wandb_entity=wandb_entity,\n",
    "            save_dir=save_dir,\n",
    "            save_every=save_every,\n",
    "        )\n",
    "        results.append(out)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ================\n",
    "# Hyperparams grid\n",
    "# ================\n",
    "def angtriplet_grid(try_arc_init: bool = False) -> List[Dict[str, Any]]:\n",
    "    base = dict(\n",
    "        lr=3e-4,\n",
    "        weight_decay=1e-4,\n",
    "        epochs=20,\n",
    "        warmup_epochs=1,\n",
    "        milestones=[16],  \n",
    "        gamma=0.1,\n",
    "        init_from_arcface=try_arc_init,\n",
    "        arc_ckpt_path=None,  \n",
    "        seed=42,\n",
    "        emb_dim=512,\n",
    "    )\n",
    "\n",
    "    pk_pairs = [(16, 4), (8, 8)]\n",
    "    margins = [0.20, 0.25]\n",
    "\n",
    "    runs = []\n",
    "    for (P, K) in pk_pairs:\n",
    "        for m in margins:\n",
    "            cfg = dict(base)\n",
    "            cfg.update(P=P, K=K, margin_rad=m)\n",
    "            runs.append(cfg)\n",
    "\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-02-08T10:25:20.670325Z",
     "iopub.status.busy": "2026-02-08T10:25:20.669527Z",
     "iopub.status.idle": "2026-02-08T11:14:52.583932Z",
     "shell.execute_reply": "2026-02-08T11:14:52.583083Z",
     "shell.execute_reply.started": "2026-02-08T10:25:20.670297Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUNS] Total runs: 6\n",
      "\n",
      "[RUN 1/6] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'milestones': [16], 'gamma': 0.1, 'init_from_arcface': False, 'arc_ckpt_path': '', 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'margin_rad': 0.15}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>val/1nn_acc</td><td></td></tr><tr><td>val/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>6</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.91941</td></tr><tr><td>val/1nn_acc</td><td>0.5625</td></tr><tr><td>val/loss</td><td>0.93053</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_P8K8_m0.15</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/jkdqks05' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/jkdqks05</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_101656-jkdqks05/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_102814-o7xmptty</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/o7xmptty' target=\"_blank\">reid_r50_angtriplet_P16K4_m0.15</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/o7xmptty' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/o7xmptty</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train=0.8967 | val=0.9292 | 1NN=0.4010 | lr=1.50e-05\n",
      "[Epoch 01] train=0.8948 | val=0.9160 | 1NN=0.3802 | lr=1.50e-05\n",
      "[Epoch 02] train=0.8922 | val=0.9037 | 1NN=0.3229 | lr=1.50e-05\n",
      "[Epoch 03] train=0.8988 | val=0.9131 | 1NN=0.3646 | lr=1.50e-05\n",
      "[Epoch 04] train=0.8910 | val=0.9046 | 1NN=0.3125 | lr=1.50e-05\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch05.pth\n",
      "[Epoch 05] train=0.8981 | val=0.9147 | 1NN=0.2708 | lr=1.50e-05\n",
      "[Epoch 06] train=0.8995 | val=0.9154 | 1NN=0.3281 | lr=1.50e-05\n",
      "[Epoch 07] train=0.8899 | val=0.9052 | 1NN=0.3750 | lr=1.50e-05\n",
      "[Epoch 08] train=0.8965 | val=0.8909 | 1NN=0.4531 | lr=2.25e-04\n",
      "[Epoch 09] train=0.8948 | val=0.8960 | 1NN=0.4688 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch10.pth\n",
      "[Epoch 10] train=0.8992 | val=0.8973 | 1NN=0.3021 | lr=3.00e-04\n",
      "[Epoch 11] train=0.8972 | val=0.9054 | 1NN=0.3906 | lr=3.00e-04\n",
      "[Epoch 12] train=0.8958 | val=0.8968 | 1NN=0.4219 | lr=3.00e-04\n",
      "[Epoch 13] train=0.8962 | val=0.9077 | 1NN=0.3073 | lr=3.00e-04\n",
      "[Epoch 14] train=0.8969 | val=0.9038 | 1NN=0.3594 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch15.pth\n",
      "[Epoch 15] train=0.8953 | val=0.8976 | 1NN=0.3854 | lr=3.00e-04\n",
      "[Epoch 16] train=0.8896 | val=0.9101 | 1NN=0.3646 | lr=3.00e-04\n",
      "[Epoch 17] train=0.8918 | val=0.9057 | 1NN=0.3073 | lr=3.00e-04\n",
      "[Epoch 18] train=0.8973 | val=0.9096 | 1NN=0.3854 | lr=3.00e-04\n",
      "[Epoch 19] train=0.9009 | val=0.8979 | 1NN=0.3698 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/warmup_updates_done</td><td></td></tr><tr><td>val/1nn_acc</td><td></td></tr><tr><td>val/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>0.0003</td></tr><tr><td>train/loss</td><td>0.90087</td></tr><tr><td>train/warmup_updates_done</td><td>20</td></tr><tr><td>val/1nn_acc</td><td>0.36979</td></tr><tr><td>val/loss</td><td>0.89785</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_P16K4_m0.15</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/o7xmptty' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/o7xmptty</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_102814-o7xmptty/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 2/6] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'milestones': [16], 'gamma': 0.1, 'init_from_arcface': False, 'arc_ckpt_path': '', 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'margin_rad': 0.2}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_103452-we2uflda</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/we2uflda' target=\"_blank\">reid_r50_angtriplet_P16K4_m0.2</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/we2uflda' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/we2uflda</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train=0.9266 | val=0.9596 | 1NN=0.4010 | lr=1.50e-05\n",
      "[Epoch 01] train=0.9246 | val=0.9462 | 1NN=0.3802 | lr=1.50e-05\n",
      "[Epoch 02] train=0.9219 | val=0.9337 | 1NN=0.3229 | lr=1.50e-05\n",
      "[Epoch 03] train=0.9287 | val=0.9433 | 1NN=0.3646 | lr=1.50e-05\n",
      "[Epoch 04] train=0.9208 | val=0.9346 | 1NN=0.3125 | lr=1.50e-05\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch05.pth\n",
      "[Epoch 05] train=0.9280 | val=0.9449 | 1NN=0.2708 | lr=1.50e-05\n",
      "[Epoch 06] train=0.9294 | val=0.9456 | 1NN=0.3281 | lr=1.50e-05\n",
      "[Epoch 07] train=0.9196 | val=0.9352 | 1NN=0.3750 | lr=1.50e-05\n",
      "[Epoch 08] train=0.9263 | val=0.9206 | 1NN=0.4531 | lr=2.25e-04\n",
      "[Epoch 09] train=0.9246 | val=0.9258 | 1NN=0.4688 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch10.pth\n",
      "[Epoch 10] train=0.9291 | val=0.9272 | 1NN=0.3021 | lr=3.00e-04\n",
      "[Epoch 11] train=0.9271 | val=0.9355 | 1NN=0.3906 | lr=3.00e-04\n",
      "[Epoch 12] train=0.9257 | val=0.9266 | 1NN=0.4219 | lr=3.00e-04\n",
      "[Epoch 13] train=0.9260 | val=0.9378 | 1NN=0.3073 | lr=3.00e-04\n",
      "[Epoch 14] train=0.9268 | val=0.9338 | 1NN=0.3594 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch15.pth\n",
      "[Epoch 15] train=0.9251 | val=0.9274 | 1NN=0.3854 | lr=3.00e-04\n",
      "[Epoch 16] train=0.9193 | val=0.9402 | 1NN=0.3646 | lr=3.00e-04\n",
      "[Epoch 17] train=0.9216 | val=0.9358 | 1NN=0.3073 | lr=3.00e-04\n",
      "[Epoch 18] train=0.9272 | val=0.9397 | 1NN=0.3854 | lr=3.00e-04\n",
      "[Epoch 19] train=0.9308 | val=0.9277 | 1NN=0.3698 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/warmup_updates_done</td><td></td></tr><tr><td>val/1nn_acc</td><td></td></tr><tr><td>val/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>0.0003</td></tr><tr><td>train/loss</td><td>0.93082</td></tr><tr><td>train/warmup_updates_done</td><td>20</td></tr><tr><td>val/1nn_acc</td><td>0.36979</td></tr><tr><td>val/loss</td><td>0.92771</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_P16K4_m0.2</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/we2uflda' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/we2uflda</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_103452-we2uflda/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 3/6] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'milestones': [16], 'gamma': 0.1, 'init_from_arcface': False, 'arc_ckpt_path': '', 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'margin_rad': 0.25}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_104126-kt5ammrd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/kt5ammrd' target=\"_blank\">reid_r50_angtriplet_P16K4_m0.25</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/kt5ammrd' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/kt5ammrd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train=0.9570 | val=0.9907 | 1NN=0.4010 | lr=1.50e-05\n",
      "[Epoch 01] train=0.9550 | val=0.9770 | 1NN=0.3802 | lr=1.50e-05\n",
      "[Epoch 02] train=0.9523 | val=0.9643 | 1NN=0.3229 | lr=1.50e-05\n",
      "[Epoch 03] train=0.9592 | val=0.9741 | 1NN=0.3646 | lr=1.50e-05\n",
      "[Epoch 04] train=0.9511 | val=0.9652 | 1NN=0.3125 | lr=1.50e-05\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch05.pth\n",
      "[Epoch 05] train=0.9585 | val=0.9757 | 1NN=0.2708 | lr=1.50e-05\n",
      "[Epoch 06] train=0.9599 | val=0.9764 | 1NN=0.3281 | lr=1.50e-05\n",
      "[Epoch 07] train=0.9499 | val=0.9658 | 1NN=0.3750 | lr=1.50e-05\n",
      "[Epoch 08] train=0.9568 | val=0.9509 | 1NN=0.4531 | lr=2.25e-04\n",
      "[Epoch 09] train=0.9550 | val=0.9563 | 1NN=0.4688 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch10.pth\n",
      "[Epoch 10] train=0.9596 | val=0.9577 | 1NN=0.3021 | lr=3.00e-04\n",
      "[Epoch 11] train=0.9576 | val=0.9661 | 1NN=0.3906 | lr=3.00e-04\n",
      "[Epoch 12] train=0.9561 | val=0.9571 | 1NN=0.4219 | lr=3.00e-04\n",
      "[Epoch 13] train=0.9565 | val=0.9684 | 1NN=0.3073 | lr=3.00e-04\n",
      "[Epoch 14] train=0.9573 | val=0.9644 | 1NN=0.3594 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch15.pth\n",
      "[Epoch 15] train=0.9556 | val=0.9579 | 1NN=0.3854 | lr=3.00e-04\n",
      "[Epoch 16] train=0.9496 | val=0.9709 | 1NN=0.3646 | lr=3.00e-04\n",
      "[Epoch 17] train=0.9520 | val=0.9664 | 1NN=0.3073 | lr=3.00e-04\n",
      "[Epoch 18] train=0.9577 | val=0.9704 | 1NN=0.3854 | lr=3.00e-04\n",
      "[Epoch 19] train=0.9614 | val=0.9582 | 1NN=0.3698 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/warmup_updates_done</td><td></td></tr><tr><td>val/1nn_acc</td><td></td></tr><tr><td>val/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>0.0003</td></tr><tr><td>train/loss</td><td>0.96136</td></tr><tr><td>train/warmup_updates_done</td><td>20</td></tr><tr><td>val/1nn_acc</td><td>0.36979</td></tr><tr><td>val/loss</td><td>0.95817</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_P16K4_m0.25</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/kt5ammrd' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/kt5ammrd</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_104126-kt5ammrd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 4/6] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'milestones': [16], 'gamma': 0.1, 'init_from_arcface': False, 'arc_ckpt_path': '', 'seed': 42, 'emb_dim': 512, 'P': 8, 'K': 8, 'margin_rad': 0.15}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_104750-4w8yh0sz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/4w8yh0sz' target=\"_blank\">reid_r50_angtriplet_P8K8_m0.15</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/4w8yh0sz' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/4w8yh0sz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train=0.9167 | val=0.9329 | 1NN=0.5938 | lr=7.32e-06\n",
      "[Epoch 01] train=0.9147 | val=0.9245 | 1NN=0.6049 | lr=7.32e-06\n",
      "[Epoch 02] train=0.9169 | val=0.9238 | 1NN=0.6116 | lr=7.32e-06\n",
      "[Epoch 03] train=0.9160 | val=0.9326 | 1NN=0.6116 | lr=7.32e-06\n",
      "[Epoch 04] train=0.9151 | val=0.9255 | 1NN=0.5536 | lr=2.93e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch05.pth\n",
      "[Epoch 05] train=0.9129 | val=0.9254 | 1NN=0.5469 | lr=3.00e-04\n",
      "[Epoch 06] train=0.9194 | val=0.9305 | 1NN=0.5625 | lr=3.00e-04\n",
      "[Epoch 07] train=0.9138 | val=0.9304 | 1NN=0.6161 | lr=3.00e-04\n",
      "[Epoch 08] train=0.9172 | val=0.9269 | 1NN=0.5781 | lr=3.00e-04\n",
      "[Epoch 09] train=0.9167 | val=0.9203 | 1NN=0.6228 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch10.pth\n",
      "[Epoch 10] train=0.9142 | val=0.9252 | 1NN=0.5603 | lr=3.00e-04\n",
      "[Epoch 11] train=0.9164 | val=0.9318 | 1NN=0.5826 | lr=3.00e-04\n",
      "[Epoch 12] train=0.9166 | val=0.9318 | 1NN=0.5960 | lr=3.00e-04\n",
      "[Epoch 13] train=0.9158 | val=0.9282 | 1NN=0.5982 | lr=3.00e-04\n",
      "[Epoch 14] train=0.9152 | val=0.9293 | 1NN=0.6004 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch15.pth\n",
      "[Epoch 15] train=0.9162 | val=0.9257 | 1NN=0.5804 | lr=3.00e-04\n",
      "[Epoch 16] train=0.9148 | val=0.9241 | 1NN=0.5714 | lr=3.00e-04\n",
      "[Epoch 17] train=0.9164 | val=0.9210 | 1NN=0.6205 | lr=3.00e-04\n",
      "[Epoch 18] train=0.9140 | val=0.9291 | 1NN=0.5871 | lr=3.00e-04\n",
      "[Epoch 19] train=0.9149 | val=0.9240 | 1NN=0.5982 | lr=3.00e-05\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/warmup_updates_done</td><td></td></tr><tr><td>val/1nn_acc</td><td></td></tr><tr><td>val/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.91491</td></tr><tr><td>train/warmup_updates_done</td><td>41</td></tr><tr><td>val/1nn_acc</td><td>0.59821</td></tr><tr><td>val/loss</td><td>0.92402</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_P8K8_m0.15</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/4w8yh0sz' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/4w8yh0sz</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_104750-4w8yh0sz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 5/6] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'milestones': [16], 'gamma': 0.1, 'init_from_arcface': False, 'arc_ckpt_path': '', 'seed': 42, 'emb_dim': 512, 'P': 8, 'K': 8, 'margin_rad': 0.2}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_105745-g3p5i13w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/g3p5i13w' target=\"_blank\">reid_r50_angtriplet_P8K8_m0.2</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/g3p5i13w' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/g3p5i13w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train=0.9470 | val=0.9635 | 1NN=0.5938 | lr=7.32e-06\n",
      "[Epoch 01] train=0.9450 | val=0.9549 | 1NN=0.6049 | lr=7.32e-06\n",
      "[Epoch 02] train=0.9472 | val=0.9542 | 1NN=0.6116 | lr=7.32e-06\n",
      "[Epoch 03] train=0.9463 | val=0.9631 | 1NN=0.6116 | lr=7.32e-06\n",
      "[Epoch 04] train=0.9453 | val=0.9559 | 1NN=0.5536 | lr=2.93e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch05.pth\n",
      "[Epoch 05] train=0.9431 | val=0.9559 | 1NN=0.5469 | lr=3.00e-04\n",
      "[Epoch 06] train=0.9497 | val=0.9610 | 1NN=0.5625 | lr=3.00e-04\n",
      "[Epoch 07] train=0.9440 | val=0.9609 | 1NN=0.6161 | lr=3.00e-04\n",
      "[Epoch 08] train=0.9475 | val=0.9574 | 1NN=0.5781 | lr=3.00e-04\n",
      "[Epoch 09] train=0.9470 | val=0.9507 | 1NN=0.6228 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch10.pth\n",
      "[Epoch 10] train=0.9444 | val=0.9557 | 1NN=0.5603 | lr=3.00e-04\n",
      "[Epoch 11] train=0.9467 | val=0.9624 | 1NN=0.5826 | lr=3.00e-04\n",
      "[Epoch 12] train=0.9468 | val=0.9623 | 1NN=0.5960 | lr=3.00e-04\n",
      "[Epoch 13] train=0.9461 | val=0.9587 | 1NN=0.5982 | lr=3.00e-04\n",
      "[Epoch 14] train=0.9454 | val=0.9598 | 1NN=0.6004 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch15.pth\n",
      "[Epoch 15] train=0.9464 | val=0.9561 | 1NN=0.5804 | lr=3.00e-04\n",
      "[Epoch 16] train=0.9450 | val=0.9545 | 1NN=0.5714 | lr=3.00e-04\n",
      "[Epoch 17] train=0.9466 | val=0.9513 | 1NN=0.6205 | lr=3.00e-04\n",
      "[Epoch 18] train=0.9442 | val=0.9595 | 1NN=0.5871 | lr=3.00e-04\n",
      "[Epoch 19] train=0.9451 | val=0.9544 | 1NN=0.5982 | lr=3.00e-05\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/warmup_updates_done</td><td></td></tr><tr><td>val/1nn_acc</td><td></td></tr><tr><td>val/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.94515</td></tr><tr><td>train/warmup_updates_done</td><td>41</td></tr><tr><td>val/1nn_acc</td><td>0.59821</td></tr><tr><td>val/loss</td><td>0.95441</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_P8K8_m0.2</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/g3p5i13w' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/g3p5i13w</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_105745-g3p5i13w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 6/6] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'milestones': [16], 'gamma': 0.1, 'init_from_arcface': False, 'arc_ckpt_path': '', 'seed': 42, 'emb_dim': 512, 'P': 8, 'K': 8, 'margin_rad': 0.25}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_110738-s9u4dk5z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/s9u4dk5z' target=\"_blank\">reid_r50_angtriplet_P8K8_m0.25</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/s9u4dk5z' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/s9u4dk5z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train=0.9779 | val=0.9946 | 1NN=0.5938 | lr=7.32e-06\n",
      "[Epoch 01] train=0.9758 | val=0.9859 | 1NN=0.6049 | lr=7.32e-06\n",
      "[Epoch 02] train=0.9781 | val=0.9852 | 1NN=0.6116 | lr=7.32e-06\n",
      "[Epoch 03] train=0.9771 | val=0.9942 | 1NN=0.6116 | lr=7.32e-06\n",
      "[Epoch 04] train=0.9762 | val=0.9869 | 1NN=0.5536 | lr=2.93e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch05.pth\n",
      "[Epoch 05] train=0.9739 | val=0.9869 | 1NN=0.5469 | lr=3.00e-04\n",
      "[Epoch 06] train=0.9806 | val=0.9922 | 1NN=0.5625 | lr=3.00e-04\n",
      "[Epoch 07] train=0.9749 | val=0.9920 | 1NN=0.6161 | lr=3.00e-04\n",
      "[Epoch 08] train=0.9784 | val=0.9884 | 1NN=0.5781 | lr=3.00e-04\n",
      "[Epoch 09] train=0.9779 | val=0.9816 | 1NN=0.6228 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch10.pth\n",
      "[Epoch 10] train=0.9752 | val=0.9867 | 1NN=0.5603 | lr=3.00e-04\n",
      "[Epoch 11] train=0.9775 | val=0.9935 | 1NN=0.5826 | lr=3.00e-04\n",
      "[Epoch 12] train=0.9777 | val=0.9935 | 1NN=0.5960 | lr=3.00e-04\n",
      "[Epoch 13] train=0.9769 | val=0.9897 | 1NN=0.5982 | lr=3.00e-04\n",
      "[Epoch 14] train=0.9763 | val=0.9909 | 1NN=0.6004 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch15.pth\n",
      "[Epoch 15] train=0.9773 | val=0.9871 | 1NN=0.5804 | lr=3.00e-04\n",
      "[Epoch 16] train=0.9758 | val=0.9855 | 1NN=0.5714 | lr=3.00e-04\n",
      "[Epoch 17] train=0.9775 | val=0.9822 | 1NN=0.6205 | lr=3.00e-04\n",
      "[Epoch 18] train=0.9750 | val=0.9906 | 1NN=0.5871 | lr=3.00e-04\n",
      "[Epoch 19] train=0.9760 | val=0.9854 | 1NN=0.5982 | lr=3.00e-05\n",
      "[CKPT] Saved ./ckpts_angtriplet/reid_angtriplet_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/warmup_updates_done</td><td></td></tr><tr><td>val/1nn_acc</td><td></td></tr><tr><td>val/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.97597</td></tr><tr><td>train/warmup_updates_done</td><td>41</td></tr><tr><td>val/1nn_acc</td><td>0.59821</td></tr><tr><td>val/loss</td><td>0.9854</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_P8K8_m0.25</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/s9u4dk5z' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/s9u4dk5z</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_110738-s9u4dk5z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Angular triplet loss standalone\n",
    "grid = angtriplet_grid(try_arc_init=False)\n",
    "\n",
    "results = run_grid_angtriplet(\n",
    "    train_reid_ds=train_reid_ds,   \n",
    "    val_reid_ds = val_reid_ds,\n",
    "    device=device,\n",
    "    grid=grid,\n",
    "    arc_ckpt_path=\"\",  # optional, used only if init_from_arcface=True\n",
    "    num_workers=4,\n",
    "    use_amp=True,\n",
    "    save_dir=\"./ckpts_angtriplet\",\n",
    "    save_every=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:03:28.558789Z",
     "iopub.status.busy": "2026-02-08T16:03:28.557927Z",
     "iopub.status.idle": "2026-02-08T16:07:13.982818Z",
     "shell.execute_reply": "2026-02-08T16:07:13.981883Z",
     "shell.execute_reply.started": "2026-02-08T16:03:28.558756Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Eval] Loading checkpoint: /kaggle/working/ckpts_angtriplet/reid_angtriplet_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 3.59%\n",
      "  top- 1 = 25.86%\n",
      "[DONE] m25 epoch=20 -> mAP=0.0359 top1=0.2586\n",
      "\n",
      "Summary (mAP/top-1):\n",
      "m25 | epoch=20 | mAP=0.0359 | top1=0.2586\n"
     ]
    }
   ],
   "source": [
    "# ==============\n",
    "# Model builder\n",
    "# ==============\n",
    "def build_model_trip(emb_dim: int):\n",
    "    return ReIDNetEmbed(emb_dim=emb_dim)\n",
    "\n",
    "# ==========================\n",
    "emb_dim = 512\n",
    "epochs_to_eval = [20]   \n",
    "m_tags = [\"m25\"]            # filename tags\n",
    "\n",
    "results_trip = {}  # key: (m_tag, epoch)\n",
    "\n",
    "for m_tag in m_tags:\n",
    "    for e in epochs_to_eval:\n",
    "        ckpt_path = f\"/kaggle/working/ckpts_angtriplet/reid_angtriplet_epoch{e:02d}.pth\"\n",
    "\n",
    "        model_reid_trip = build_model_trip(emb_dim=emb_dim).to(device)\n",
    "\n",
    "        ret = eval_prw_validation_person_search(\n",
    "            ckpt_path=ckpt_path,\n",
    "            model=model_reid_trip,\n",
    "            val_view=val_view,\n",
    "            val_ds=det_train_ds,\n",
    "            val_detections=train_detections,\n",
    "            transform=test_reid_tf,\n",
    "            device=device,\n",
    "            det_thresh=0.3,\n",
    "            ignore_cam_id=True,\n",
    "        )\n",
    "\n",
    "        results_trip[(m_tag, e)] = ret\n",
    "        print(f\"[DONE] {m_tag} epoch={e:02d} -> mAP={ret['mAP']:.4f} top1={ret['accs'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nSummary (mAP/top-1):\")\n",
    "for (m_tag, e), ret in sorted(results_trip.items(), key=lambda x: (x[0][0], x[0][1])):\n",
    "    print(f\"{m_tag:>3} | epoch={e:>2} | mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Very bad results, since **angular triplet loss** used as a standalone objective leads to unstable training and poor retrieval performance on the PRW dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try adding arcface weights: we have to use triplet loss as fine-tuning loss, instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-02-08T13:27:27.915065Z",
     "iopub.status.busy": "2026-02-08T13:27:27.914455Z",
     "iopub.status.idle": "2026-02-08T14:00:07.068999Z",
     "shell.execute_reply": "2026-02-08T14:00:07.068329Z",
     "shell.execute_reply.started": "2026-02-08T13:27:27.915037Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUNS] Total runs: 4\n",
      "\n",
      "[RUN 1/4] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'milestones': [16], 'gamma': 0.1, 'init_from_arcface': True, 'arc_ckpt_path': '/kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth', 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'margin_rad': 0.2}\n",
      "[INIT] Loaded 320/320 params from /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_133017-comkyj04</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/comkyj04' target=\"_blank\">reid_r50_angtriplet_af_P16K4_m20</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/comkyj04' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/comkyj04</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train_loss=0.5672 | pos=0.788 rad | neg=1.590 rad | hard_diff=-0.476 rad | val_loss=0.7942 | val_1NN=0.9062 | lr=3.00e-04\n",
      "[Epoch 01] train_loss=0.5686 | pos=0.790 rad | neg=1.590 rad | hard_diff=-0.474 rad | val_loss=0.7792 | val_1NN=0.9479 | lr=3.00e-04\n",
      "[Epoch 02] train_loss=0.5665 | pos=0.783 rad | neg=1.591 rad | hard_diff=-0.478 rad | val_loss=0.7706 | val_1NN=0.9479 | lr=3.00e-04\n",
      "[Epoch 03] train_loss=0.5644 | pos=0.784 rad | neg=1.590 rad | hard_diff=-0.483 rad | val_loss=0.7518 | val_1NN=0.9531 | lr=3.00e-04\n",
      "[Epoch 04] train_loss=0.5633 | pos=0.785 rad | neg=1.591 rad | hard_diff=-0.486 rad | val_loss=0.7661 | val_1NN=0.9427 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m20_epoch05.pth\n",
      "[Epoch 05] train_loss=0.5673 | pos=0.782 rad | neg=1.591 rad | hard_diff=-0.477 rad | val_loss=0.7740 | val_1NN=0.9635 | lr=3.00e-04\n",
      "[Epoch 06] train_loss=0.5647 | pos=0.788 rad | neg=1.591 rad | hard_diff=-0.482 rad | val_loss=0.7761 | val_1NN=0.9688 | lr=3.00e-04\n",
      "[Epoch 07] train_loss=0.5670 | pos=0.782 rad | neg=1.590 rad | hard_diff=-0.478 rad | val_loss=0.7786 | val_1NN=0.9740 | lr=3.00e-04\n",
      "[Epoch 08] train_loss=0.5618 | pos=0.782 rad | neg=1.590 rad | hard_diff=-0.489 rad | val_loss=0.7691 | val_1NN=0.9479 | lr=3.00e-04\n",
      "[Epoch 09] train_loss=0.5608 | pos=0.779 rad | neg=1.591 rad | hard_diff=-0.491 rad | val_loss=0.7631 | val_1NN=0.9271 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m20_epoch10.pth\n",
      "[Epoch 10] train_loss=0.5665 | pos=0.792 rad | neg=1.591 rad | hard_diff=-0.478 rad | val_loss=0.7500 | val_1NN=0.9635 | lr=3.00e-04\n",
      "[Epoch 11] train_loss=0.5648 | pos=0.787 rad | neg=1.591 rad | hard_diff=-0.482 rad | val_loss=0.7705 | val_1NN=0.9635 | lr=3.00e-04\n",
      "[Epoch 12] train_loss=0.5615 | pos=0.780 rad | neg=1.590 rad | hard_diff=-0.490 rad | val_loss=0.7700 | val_1NN=0.9323 | lr=3.00e-04\n",
      "[Epoch 13] train_loss=0.5682 | pos=0.789 rad | neg=1.590 rad | hard_diff=-0.474 rad | val_loss=0.7775 | val_1NN=0.9115 | lr=3.00e-04\n",
      "[Epoch 14] train_loss=0.5611 | pos=0.780 rad | neg=1.591 rad | hard_diff=-0.491 rad | val_loss=0.7641 | val_1NN=0.9375 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m20_epoch15.pth\n",
      "[Epoch 15] train_loss=0.5648 | pos=0.784 rad | neg=1.590 rad | hard_diff=-0.482 rad | val_loss=0.7627 | val_1NN=0.9635 | lr=3.00e-05\n",
      "[Epoch 16] train_loss=0.5612 | pos=0.776 rad | neg=1.592 rad | hard_diff=-0.491 rad | val_loss=0.7643 | val_1NN=0.9531 | lr=3.00e-05\n",
      "[Epoch 17] train_loss=0.5670 | pos=0.784 rad | neg=1.591 rad | hard_diff=-0.478 rad | val_loss=0.7668 | val_1NN=0.9583 | lr=3.00e-05\n",
      "[Epoch 18] train_loss=0.5680 | pos=0.790 rad | neg=1.591 rad | hard_diff=-0.475 rad | val_loss=0.7589 | val_1NN=0.9427 | lr=3.00e-05\n",
      "[Epoch 19] train_loss=0.5639 | pos=0.784 rad | neg=1.591 rad | hard_diff=-0.484 rad | val_loss=0.7901 | val_1NN=0.9219 | lr=3.00e-05\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m20_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/1nn_acc_batch</td><td></td></tr><tr><td>train/1nn_acc_epoch</td><td></td></tr><tr><td>train/diff_mean</td><td></td></tr><tr><td>train/diff_mean_epoch</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/hard_neg_mean</td><td></td></tr><tr><td>+21</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>step</td><td>399</td></tr><tr><td>train/1nn_acc_batch</td><td>1</td></tr><tr><td>train/1nn_acc_epoch</td><td>1</td></tr><tr><td>train/diff_mean</td><td>-0.47506</td></tr><tr><td>train/diff_mean_epoch</td><td>-0.48428</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/global_step</td><td>400</td></tr><tr><td>train/hard_neg_mean</td><td>1.38351</td></tr><tr><td>+21</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_af_P16K4_m20</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/comkyj04' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/comkyj04</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_133017-comkyj04/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 2/4] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'milestones': [16], 'gamma': 0.1, 'init_from_arcface': True, 'arc_ckpt_path': '/kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth', 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'margin_rad': 0.25}\n",
      "[INIT] Loaded 320/320 params from /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_133643-gl5ul8nq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/gl5ul8nq' target=\"_blank\">reid_r50_angtriplet_af_P16K4_m25</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/gl5ul8nq' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/gl5ul8nq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train_loss=0.5890 | pos=0.788 rad | neg=1.590 rad | hard_diff=-0.476 rad | val_loss=0.8218 | val_1NN=0.9062 | lr=3.00e-04\n",
      "[Epoch 01] train_loss=0.5905 | pos=0.790 rad | neg=1.590 rad | hard_diff=-0.474 rad | val_loss=0.8065 | val_1NN=0.9479 | lr=3.00e-04\n",
      "[Epoch 02] train_loss=0.5884 | pos=0.783 rad | neg=1.591 rad | hard_diff=-0.478 rad | val_loss=0.7976 | val_1NN=0.9479 | lr=3.00e-04\n",
      "[Epoch 03] train_loss=0.5862 | pos=0.784 rad | neg=1.590 rad | hard_diff=-0.483 rad | val_loss=0.7784 | val_1NN=0.9531 | lr=3.00e-04\n",
      "[Epoch 04] train_loss=0.5851 | pos=0.785 rad | neg=1.591 rad | hard_diff=-0.486 rad | val_loss=0.7931 | val_1NN=0.9427 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m25_epoch05.pth\n",
      "[Epoch 05] train_loss=0.5892 | pos=0.782 rad | neg=1.591 rad | hard_diff=-0.477 rad | val_loss=0.8011 | val_1NN=0.9635 | lr=3.00e-04\n",
      "[Epoch 06] train_loss=0.5865 | pos=0.788 rad | neg=1.591 rad | hard_diff=-0.482 rad | val_loss=0.8033 | val_1NN=0.9688 | lr=3.00e-04\n",
      "[Epoch 07] train_loss=0.5889 | pos=0.782 rad | neg=1.590 rad | hard_diff=-0.478 rad | val_loss=0.8058 | val_1NN=0.9740 | lr=3.00e-04\n",
      "[Epoch 08] train_loss=0.5836 | pos=0.782 rad | neg=1.590 rad | hard_diff=-0.489 rad | val_loss=0.7962 | val_1NN=0.9479 | lr=3.00e-04\n",
      "[Epoch 09] train_loss=0.5825 | pos=0.779 rad | neg=1.591 rad | hard_diff=-0.491 rad | val_loss=0.7899 | val_1NN=0.9271 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m25_epoch10.pth\n",
      "[Epoch 10] train_loss=0.5884 | pos=0.792 rad | neg=1.591 rad | hard_diff=-0.478 rad | val_loss=0.7766 | val_1NN=0.9635 | lr=3.00e-04\n",
      "[Epoch 11] train_loss=0.5866 | pos=0.787 rad | neg=1.591 rad | hard_diff=-0.482 rad | val_loss=0.7976 | val_1NN=0.9635 | lr=3.00e-04\n",
      "[Epoch 12] train_loss=0.5832 | pos=0.780 rad | neg=1.590 rad | hard_diff=-0.490 rad | val_loss=0.7970 | val_1NN=0.9323 | lr=3.00e-04\n",
      "[Epoch 13] train_loss=0.5901 | pos=0.789 rad | neg=1.590 rad | hard_diff=-0.474 rad | val_loss=0.8046 | val_1NN=0.9115 | lr=3.00e-04\n",
      "[Epoch 14] train_loss=0.5828 | pos=0.780 rad | neg=1.591 rad | hard_diff=-0.491 rad | val_loss=0.7910 | val_1NN=0.9375 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m25_epoch15.pth\n",
      "[Epoch 15] train_loss=0.5866 | pos=0.784 rad | neg=1.590 rad | hard_diff=-0.482 rad | val_loss=0.7896 | val_1NN=0.9635 | lr=3.00e-05\n",
      "[Epoch 16] train_loss=0.5829 | pos=0.776 rad | neg=1.592 rad | hard_diff=-0.491 rad | val_loss=0.7912 | val_1NN=0.9531 | lr=3.00e-05\n",
      "[Epoch 17] train_loss=0.5889 | pos=0.784 rad | neg=1.591 rad | hard_diff=-0.478 rad | val_loss=0.7938 | val_1NN=0.9583 | lr=3.00e-05\n",
      "[Epoch 18] train_loss=0.5899 | pos=0.790 rad | neg=1.591 rad | hard_diff=-0.475 rad | val_loss=0.7856 | val_1NN=0.9427 | lr=3.00e-05\n",
      "[Epoch 19] train_loss=0.5857 | pos=0.784 rad | neg=1.591 rad | hard_diff=-0.484 rad | val_loss=0.8176 | val_1NN=0.9219 | lr=3.00e-05\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m25_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/1nn_acc_batch</td><td></td></tr><tr><td>train/1nn_acc_epoch</td><td></td></tr><tr><td>train/diff_mean</td><td></td></tr><tr><td>train/diff_mean_epoch</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/hard_neg_mean</td><td></td></tr><tr><td>+21</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>step</td><td>399</td></tr><tr><td>train/1nn_acc_batch</td><td>1</td></tr><tr><td>train/1nn_acc_epoch</td><td>1</td></tr><tr><td>train/diff_mean</td><td>-0.47506</td></tr><tr><td>train/diff_mean_epoch</td><td>-0.48428</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/global_step</td><td>400</td></tr><tr><td>train/hard_neg_mean</td><td>1.38351</td></tr><tr><td>+21</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_af_P16K4_m25</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/gl5ul8nq' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/gl5ul8nq</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_133643-gl5ul8nq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 3/4] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'milestones': [16], 'gamma': 0.1, 'init_from_arcface': True, 'arc_ckpt_path': '/kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth', 'seed': 42, 'emb_dim': 512, 'P': 8, 'K': 8, 'margin_rad': 0.2}\n",
      "[INIT] Loaded 320/320 params from /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_134311-km8ng4k7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/km8ng4k7' target=\"_blank\">reid_r50_angtriplet_af_P8K8_m20</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/km8ng4k7' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/km8ng4k7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train_loss=0.6098 | pos=0.861 rad | neg=1.612 rad | hard_diff=-0.379 rad | val_loss=0.7996 | val_1NN=0.9821 | lr=3.00e-04\n",
      "[Epoch 01] train_loss=0.6085 | pos=0.859 rad | neg=1.612 rad | hard_diff=-0.383 rad | val_loss=0.7787 | val_1NN=0.9844 | lr=3.00e-04\n",
      "[Epoch 02] train_loss=0.6094 | pos=0.858 rad | neg=1.613 rad | hard_diff=-0.381 rad | val_loss=0.7889 | val_1NN=0.9933 | lr=3.00e-04\n",
      "[Epoch 03] train_loss=0.6081 | pos=0.855 rad | neg=1.612 rad | hard_diff=-0.384 rad | val_loss=0.7808 | val_1NN=0.9933 | lr=3.00e-04\n",
      "[Epoch 04] train_loss=0.6047 | pos=0.857 rad | neg=1.613 rad | hard_diff=-0.391 rad | val_loss=0.7969 | val_1NN=0.9888 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P8K8_m20_epoch05.pth\n",
      "[Epoch 05] train_loss=0.6006 | pos=0.851 rad | neg=1.613 rad | hard_diff=-0.400 rad | val_loss=0.7835 | val_1NN=0.9888 | lr=3.00e-04\n",
      "[Epoch 06] train_loss=0.6080 | pos=0.856 rad | neg=1.611 rad | hard_diff=-0.384 rad | val_loss=0.7993 | val_1NN=0.9844 | lr=3.00e-04\n",
      "[Epoch 07] train_loss=0.6062 | pos=0.857 rad | neg=1.613 rad | hard_diff=-0.388 rad | val_loss=0.7997 | val_1NN=0.9911 | lr=3.00e-04\n",
      "[Epoch 08] train_loss=0.6117 | pos=0.863 rad | neg=1.610 rad | hard_diff=-0.376 rad | val_loss=0.7912 | val_1NN=0.9955 | lr=3.00e-04\n",
      "[Epoch 09] train_loss=0.6060 | pos=0.857 rad | neg=1.612 rad | hard_diff=-0.388 rad | val_loss=0.7963 | val_1NN=0.9844 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P8K8_m20_epoch10.pth\n",
      "[Epoch 10] train_loss=0.6045 | pos=0.855 rad | neg=1.612 rad | hard_diff=-0.391 rad | val_loss=0.7826 | val_1NN=0.9888 | lr=3.00e-04\n",
      "[Epoch 11] train_loss=0.6060 | pos=0.856 rad | neg=1.612 rad | hard_diff=-0.388 rad | val_loss=0.8009 | val_1NN=0.9866 | lr=3.00e-04\n",
      "[Epoch 12] train_loss=0.6049 | pos=0.859 rad | neg=1.613 rad | hard_diff=-0.390 rad | val_loss=0.8078 | val_1NN=0.9866 | lr=3.00e-04\n",
      "[Epoch 13] train_loss=0.6051 | pos=0.855 rad | neg=1.612 rad | hard_diff=-0.390 rad | val_loss=0.7899 | val_1NN=0.9799 | lr=3.00e-04\n",
      "[Epoch 14] train_loss=0.6054 | pos=0.859 rad | neg=1.611 rad | hard_diff=-0.389 rad | val_loss=0.8041 | val_1NN=0.9799 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P8K8_m20_epoch15.pth\n",
      "[Epoch 15] train_loss=0.6087 | pos=0.857 rad | neg=1.612 rad | hard_diff=-0.382 rad | val_loss=0.7910 | val_1NN=0.9821 | lr=3.00e-05\n",
      "[Epoch 16] train_loss=0.6003 | pos=0.849 rad | neg=1.613 rad | hard_diff=-0.401 rad | val_loss=0.7799 | val_1NN=0.9844 | lr=3.00e-05\n",
      "[Epoch 17] train_loss=0.6104 | pos=0.864 rad | neg=1.612 rad | hard_diff=-0.378 rad | val_loss=0.7715 | val_1NN=0.9888 | lr=3.00e-05\n",
      "[Epoch 18] train_loss=0.6084 | pos=0.859 rad | neg=1.613 rad | hard_diff=-0.383 rad | val_loss=0.7820 | val_1NN=0.9866 | lr=3.00e-05\n",
      "[Epoch 19] train_loss=0.6045 | pos=0.855 rad | neg=1.614 rad | hard_diff=-0.392 rad | val_loss=0.8034 | val_1NN=0.9866 | lr=3.00e-05\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P8K8_m20_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/1nn_acc_batch</td><td></td></tr><tr><td>train/1nn_acc_epoch</td><td></td></tr><tr><td>train/diff_mean</td><td></td></tr><tr><td>train/diff_mean_epoch</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/hard_neg_mean</td><td></td></tr><tr><td>+21</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>step</td><td>819</td></tr><tr><td>train/1nn_acc_batch</td><td>1</td></tr><tr><td>train/1nn_acc_epoch</td><td>1</td></tr><tr><td>train/diff_mean</td><td>-0.47793</td></tr><tr><td>train/diff_mean_epoch</td><td>-0.39186</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/global_step</td><td>820</td></tr><tr><td>train/hard_neg_mean</td><td>1.4505</td></tr><tr><td>+21</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_af_P8K8_m20</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/km8ng4k7' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/km8ng4k7</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_134311-km8ng4k7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 4/4] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'milestones': [16], 'gamma': 0.1, 'init_from_arcface': True, 'arc_ckpt_path': '/kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth', 'seed': 42, 'emb_dim': 512, 'P': 8, 'K': 8, 'margin_rad': 0.25}\n",
      "[INIT] Loaded 320/320 params from /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_135300-xr4jfn7o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/xr4jfn7o' target=\"_blank\">reid_r50_angtriplet_af_P8K8_m25</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/xr4jfn7o' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/xr4jfn7o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train_loss=0.6329 | pos=0.861 rad | neg=1.612 rad | hard_diff=-0.379 rad | val_loss=0.8273 | val_1NN=0.9821 | lr=3.00e-04\n",
      "[Epoch 01] train_loss=0.6315 | pos=0.859 rad | neg=1.612 rad | hard_diff=-0.383 rad | val_loss=0.8059 | val_1NN=0.9844 | lr=3.00e-04\n",
      "[Epoch 02] train_loss=0.6325 | pos=0.858 rad | neg=1.613 rad | hard_diff=-0.381 rad | val_loss=0.8164 | val_1NN=0.9933 | lr=3.00e-04\n",
      "[Epoch 03] train_loss=0.6312 | pos=0.855 rad | neg=1.612 rad | hard_diff=-0.384 rad | val_loss=0.8081 | val_1NN=0.9933 | lr=3.00e-04\n",
      "[Epoch 04] train_loss=0.6276 | pos=0.857 rad | neg=1.613 rad | hard_diff=-0.391 rad | val_loss=0.8246 | val_1NN=0.9888 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P8K8_m25_epoch05.pth\n",
      "[Epoch 05] train_loss=0.6234 | pos=0.851 rad | neg=1.613 rad | hard_diff=-0.400 rad | val_loss=0.8109 | val_1NN=0.9888 | lr=3.00e-04\n",
      "[Epoch 06] train_loss=0.6311 | pos=0.856 rad | neg=1.611 rad | hard_diff=-0.384 rad | val_loss=0.8270 | val_1NN=0.9844 | lr=3.00e-04\n",
      "[Epoch 07] train_loss=0.6292 | pos=0.857 rad | neg=1.613 rad | hard_diff=-0.388 rad | val_loss=0.8275 | val_1NN=0.9911 | lr=3.00e-04\n",
      "[Epoch 08] train_loss=0.6348 | pos=0.863 rad | neg=1.610 rad | hard_diff=-0.376 rad | val_loss=0.8187 | val_1NN=0.9955 | lr=3.00e-04\n",
      "[Epoch 09] train_loss=0.6290 | pos=0.857 rad | neg=1.612 rad | hard_diff=-0.388 rad | val_loss=0.8239 | val_1NN=0.9844 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P8K8_m25_epoch10.pth\n",
      "[Epoch 10] train_loss=0.6274 | pos=0.855 rad | neg=1.612 rad | hard_diff=-0.391 rad | val_loss=0.8099 | val_1NN=0.9888 | lr=3.00e-04\n",
      "[Epoch 11] train_loss=0.6290 | pos=0.856 rad | neg=1.612 rad | hard_diff=-0.388 rad | val_loss=0.8287 | val_1NN=0.9866 | lr=3.00e-04\n",
      "[Epoch 12] train_loss=0.6279 | pos=0.859 rad | neg=1.613 rad | hard_diff=-0.390 rad | val_loss=0.8357 | val_1NN=0.9866 | lr=3.00e-04\n",
      "[Epoch 13] train_loss=0.6280 | pos=0.855 rad | neg=1.612 rad | hard_diff=-0.390 rad | val_loss=0.8174 | val_1NN=0.9799 | lr=3.00e-04\n",
      "[Epoch 14] train_loss=0.6283 | pos=0.859 rad | neg=1.611 rad | hard_diff=-0.389 rad | val_loss=0.8319 | val_1NN=0.9799 | lr=3.00e-04\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P8K8_m25_epoch15.pth\n",
      "[Epoch 15] train_loss=0.6317 | pos=0.857 rad | neg=1.612 rad | hard_diff=-0.382 rad | val_loss=0.8185 | val_1NN=0.9821 | lr=3.00e-05\n",
      "[Epoch 16] train_loss=0.6231 | pos=0.849 rad | neg=1.613 rad | hard_diff=-0.401 rad | val_loss=0.8071 | val_1NN=0.9844 | lr=3.00e-05\n",
      "[Epoch 17] train_loss=0.6335 | pos=0.864 rad | neg=1.612 rad | hard_diff=-0.378 rad | val_loss=0.7986 | val_1NN=0.9888 | lr=3.00e-05\n",
      "[Epoch 18] train_loss=0.6315 | pos=0.859 rad | neg=1.613 rad | hard_diff=-0.383 rad | val_loss=0.8093 | val_1NN=0.9866 | lr=3.00e-05\n",
      "[Epoch 19] train_loss=0.6274 | pos=0.855 rad | neg=1.614 rad | hard_diff=-0.392 rad | val_loss=0.8311 | val_1NN=0.9866 | lr=3.00e-05\n",
      "[CKPT] Saved ./ckpts_angtriplet_af/reid_r50_angtriplet_af_P8K8_m25_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>train/1nn_acc_batch</td><td></td></tr><tr><td>train/1nn_acc_epoch</td><td></td></tr><tr><td>train/diff_mean</td><td></td></tr><tr><td>train/diff_mean_epoch</td><td></td></tr><tr><td>train/emb_norm_mean</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/hard_neg_mean</td><td></td></tr><tr><td>+21</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>step</td><td>819</td></tr><tr><td>train/1nn_acc_batch</td><td>1</td></tr><tr><td>train/1nn_acc_epoch</td><td>1</td></tr><tr><td>train/diff_mean</td><td>-0.47793</td></tr><tr><td>train/diff_mean_epoch</td><td>-0.39186</td></tr><tr><td>train/emb_norm_mean</td><td>1</td></tr><tr><td>train/global_step</td><td>820</td></tr><tr><td>train/hard_neg_mean</td><td>1.4505</td></tr><tr><td>+21</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_angtriplet_af_P8K8_m25</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/xr4jfn7o' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/xr4jfn7o</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_135300-xr4jfn7o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try adding arcface weights\n",
    "grid = angtriplet_grid(try_arc_init=True)\n",
    "\n",
    "results = run_grid_angtriplet(\n",
    "    train_reid_ds=train_reid_ds,   \n",
    "    val_reid_ds = val_reid_ds,\n",
    "    device=device,\n",
    "    grid=grid,\n",
    "    arc_ckpt_path=\"/kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth\",\n",
    "    num_workers=4,\n",
    "    use_amp=True,\n",
    "    save_dir=\"./ckpts_angtriplet_af\",\n",
    "    save_every=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-02-08T14:49:40.281349Z",
     "iopub.status.busy": "2026-02-08T14:49:40.280391Z",
     "iopub.status.idle": "2026-02-08T15:18:54.583908Z",
     "shell.execute_reply": "2026-02-08T15:18:54.583076Z",
     "shell.execute_reply.started": "2026-02-08T14:49:40.281310Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Eval] Loading checkpoint: /kaggle/working/ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m20_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 52.41%\n",
      "  top- 1 = 87.93%\n",
      "[DONE] m20 epoch=20 -> mAP=0.5241 top1=0.8793\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/working/ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m20_epoch15.pth\n",
      "search ranking:\n",
      "  mAP = 52.31%\n",
      "  top- 1 = 87.93%\n",
      "[DONE] m20 epoch=15 -> mAP=0.5231 top1=0.8793\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/working/ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m20_epoch10.pth\n",
      "search ranking:\n",
      "  mAP = 52.54%\n",
      "  top- 1 = 86.21%\n",
      "[DONE] m20 epoch=10 -> mAP=0.5254 top1=0.8621\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/working/ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m20_epoch05.pth\n",
      "search ranking:\n",
      "  mAP = 52.31%\n",
      "  top- 1 = 87.93%\n",
      "[DONE] m20 epoch=05 -> mAP=0.5231 top1=0.8793\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/working/ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m25_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 52.41%\n",
      "  top- 1 = 87.93%\n",
      "[DONE] m25 epoch=20 -> mAP=0.5241 top1=0.8793\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/working/ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m25_epoch15.pth\n",
      "search ranking:\n",
      "  mAP = 52.31%\n",
      "  top- 1 = 87.93%\n",
      "[DONE] m25 epoch=15 -> mAP=0.5231 top1=0.8793\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/working/ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m25_epoch10.pth\n",
      "search ranking:\n",
      "  mAP = 52.54%\n",
      "  top- 1 = 86.21%\n",
      "[DONE] m25 epoch=10 -> mAP=0.5254 top1=0.8621\n",
      "\n",
      "[Eval] Loading checkpoint: /kaggle/working/ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_m25_epoch05.pth\n",
      "search ranking:\n",
      "  mAP = 52.31%\n",
      "  top- 1 = 87.93%\n",
      "[DONE] m25 epoch=05 -> mAP=0.5231 top1=0.8793\n",
      "\n",
      "Summary (mAP/top-1):\n",
      "m20 | epoch= 5 | mAP=0.5231 | top1=0.8793\n",
      "m20 | epoch=10 | mAP=0.5254 | top1=0.8621\n",
      "m20 | epoch=15 | mAP=0.5231 | top1=0.8793\n",
      "m20 | epoch=20 | mAP=0.5241 | top1=0.8793\n",
      "m25 | epoch= 5 | mAP=0.5231 | top1=0.8793\n",
      "m25 | epoch=10 | mAP=0.5254 | top1=0.8621\n",
      "m25 | epoch=15 | mAP=0.5231 | top1=0.8793\n",
      "m25 | epoch=20 | mAP=0.5241 | top1=0.8793\n"
     ]
    }
   ],
   "source": [
    "# ==============\n",
    "# Model builder\n",
    "# ==============\n",
    "def build_model_trip(emb_dim: int):\n",
    "    return ReIDNetEmbed(emb_dim=emb_dim)\n",
    "\n",
    "# ==========================\n",
    "# Compare m20 vs m25 (Triplet)\n",
    "# ==========================\n",
    "emb_dim = 512\n",
    "epochs_to_eval = [20, 15, 10, 5]   \n",
    "m_tags = [\"m20\", \"m25\"]            # filename tags\n",
    "\n",
    "results_trip = {}  # key: (m_tag, epoch)\n",
    "\n",
    "for m_tag in m_tags:\n",
    "    for e in epochs_to_eval:\n",
    "        ckpt_path = f\"/kaggle/working/ckpts_angtriplet_af/reid_r50_angtriplet_af_P16K4_{m_tag}_epoch{e:02d}.pth\"\n",
    "\n",
    "        model_reid_trip = build_model_trip(emb_dim=emb_dim).to(device)\n",
    "\n",
    "        ret = eval_prw_validation_person_search(\n",
    "            ckpt_path=ckpt_path,\n",
    "            model=model_reid_trip,\n",
    "            val_view=val_view,\n",
    "            val_ds=det_train_ds,\n",
    "            val_detections=train_detections,\n",
    "            transform=test_reid_tf,\n",
    "            device=device,\n",
    "            det_thresh=0.3,\n",
    "            ignore_cam_id=True,\n",
    "        )\n",
    "\n",
    "        results_trip[(m_tag, e)] = ret\n",
    "        print(f\"[DONE] {m_tag} epoch={e:02d} -> mAP={ret['mAP']:.4f} top1={ret['accs'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nSummary (mAP/top-1):\")\n",
    "for (m_tag, e), ret in sorted(results_trip.items(), key=lambda x: (x[0][0], x[0][1])):\n",
    "    print(f\"{m_tag:>3} | epoch={e:>2} | mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We choose the m25 16x4 20epoch model. We can spot very similar performances with respect to our ArcFace best model (mAP=0.5314 | top1=0.8793). Indeed, we spot a low decrease in mAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ArcFace + NTXent Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:05:57.186387Z",
     "iopub.status.busy": "2026-02-10T12:05:57.185681Z",
     "iopub.status.idle": "2026-02-10T12:05:57.215942Z",
     "shell.execute_reply": "2026-02-10T12:05:57.215366Z",
     "shell.execute_reply.started": "2026-02-10T12:05:57.186357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_infonce_val_epoch(\n",
    "    model: nn.Module,\n",
    "    loss_fn: nn.Module,\n",
    "    val_loader: DataLoader,\n",
    "    device: str,\n",
    "    use_amp: bool = True,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "\n",
    "    loss_sum, n_batches = 0.0, 0\n",
    "    acc_sum, n_acc_batches = 0.0, 0\n",
    "    pos_sum, neg_sum, valid_sum = 0.0, 0.0, 0.0\n",
    "    n_stat_batches = 0\n",
    "\n",
    "    for crops, labels, _, _ in val_loader:\n",
    "        crops = crops.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True).view(-1).long()\n",
    "\n",
    "        with autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "            emb = model(crops)  # already normalized in ReIDNetEmbed\n",
    "        loss = loss_fn(emb.float(), labels)\n",
    "\n",
    "        loss_sum += float(loss.item())\n",
    "        n_batches += 1\n",
    "\n",
    "        # 1-NN proxy\n",
    "        sim = emb @ emb.t()\n",
    "        B = sim.size(0)\n",
    "        if B >= 2:\n",
    "            sim.fill_diagonal_(-1e9)\n",
    "            nn_idx = sim.argmax(dim=1)\n",
    "            nn_labels = labels[nn_idx]\n",
    "            acc_sum += (nn_labels == labels).float().mean().item()\n",
    "            n_acc_batches += 1\n",
    "\n",
    "        #  angle stats\n",
    "        pos_m, neg_m, valid_frac = angular_batch_stats(emb, labels)\n",
    "        pos_sum += pos_m\n",
    "        neg_sum += neg_m\n",
    "        valid_sum += valid_frac\n",
    "        n_stat_batches += 1\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss_sum / max(1, n_batches),\n",
    "        \"1nn_acc\": acc_sum / max(1, n_acc_batches),\n",
    "        \"pos_angle_mean\": pos_sum / max(1, n_stat_batches),\n",
    "        \"neg_angle_mean\": neg_sum / max(1, n_stat_batches),\n",
    "        \"valid_anchor_frac\": valid_sum / max(1, n_stat_batches),\n",
    "    }\n",
    "\n",
    "def train_one_supinfonce(\n",
    "    cfg: Dict[str, Any],\n",
    "    train_reid_ds,\n",
    "    val_reid_ds,\n",
    "    device: str,\n",
    "    num_workers: int = 2,\n",
    "    use_amp: bool = True,\n",
    "    wandb_project: str = \"person re-id valsplit\",\n",
    "    wandb_entity: str = \"unibo-ai\",\n",
    "    run_name_prefix: str = \"reid_r50_supinfonce\",\n",
    "    save_dir: str = \"./ckpts_supinfonce\",\n",
    "    save_every: int = 5,\n",
    "):\n",
    "    \"\"\"\n",
    "    ArcFace init (optional) + Supervised InfoNCE\n",
    "    - Warmup: per-iteration (manual LR ramp)\n",
    "    - MultiStepLR: per-epoch\n",
    "    - Validation each epoch (loss + 1NN proxy + angle stats)\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------- SEED --------------------\n",
    "    seed = int(cfg.get(\"seed\", 42))\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # -------------------- LOADERS --------------------\n",
    "    P, K = int(cfg[\"P\"]), int(cfg[\"K\"])\n",
    "    batch_size = P * K\n",
    "\n",
    "    train_sampler = RandomIdentitySampler(train_reid_ds, P, K, seed)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_reid_ds,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_sampler,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    if val_reid_ds is not None:\n",
    "        val_sampler = RandomIdentitySampler(val_reid_ds,   P, K, seed + 999)\n",
    "        val_loader = DataLoader(\n",
    "            val_reid_ds,\n",
    "            batch_size=batch_size,\n",
    "            sampler=val_sampler,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    warmup_steps = max(1, int(cfg[\"warmup_epochs\"]) * steps_per_epoch)\n",
    "\n",
    "    # -------------------- MODEL --------------------\n",
    "    emb_dim = int(cfg.get(\"emb_dim\", 512))\n",
    "    model = ReIDNetEmbed(emb_dim=emb_dim).to(device)\n",
    "\n",
    "    name_run = f\"{run_name_prefix}_P{P}K{K}_tau{int(cfg['temperature']*1000)}\"\n",
    "\n",
    "    # optional init from ArcFace checkpoint\n",
    "    if cfg.get(\"init_from_arcface\", False):\n",
    "        load_arcface_init(model, cfg[\"arc_ckpt_path\"])\n",
    "        name_run = f\"{run_name_prefix}_af_P{P}K{K}_tau{int(cfg['temperature']*1000)}\"\n",
    "\n",
    "    # -------------------- LOSS / OPT --------------------\n",
    "    loss_fn = SupInfoNCELoss(temperature=float(cfg[\"temperature\"])).to(device)\n",
    "\n",
    "    base_lr = float(cfg[\"lr\"])\n",
    "    eta_min = float(cfg.get(\"eta_min\", 1e-6))\n",
    "    weight_decay = float(cfg[\"weight_decay\"])\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=weight_decay)\n",
    "\n",
    "    # start from eta_min (warmup to base_lr)\n",
    "    for pg in optimizer.param_groups:\n",
    "        pg[\"lr\"] = eta_min\n",
    "\n",
    "    # MultiStepLR per-epoch\n",
    "    step_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=list(cfg[\"milestones\"]),\n",
    "        gamma=float(cfg[\"gamma\"]),\n",
    "    )\n",
    "\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=use_amp)\n",
    "\n",
    "    # -------------------- WANDB --------------------\n",
    "    wandb.init(\n",
    "        entity=wandb_entity,\n",
    "        project=wandb_project,\n",
    "        config=cfg,\n",
    "        name=name_run,\n",
    "        reinit=True,\n",
    "    )\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    # ==================== TRAIN LOOP ====================\n",
    "    for epoch in range(int(cfg[\"epochs\"])):\n",
    "        model.train()\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        if val_reid_ds is not None:\n",
    "            val_sampler.set_epoch(epoch)\n",
    "\n",
    "        epoch_loss_sum = 0.0\n",
    "        n_batches = 0\n",
    "        acc_sum, n_acc = 0.0, 0\n",
    "        pos_sum, neg_sum, valid_sum, n_stat = 0.0, 0.0, 0.0, 0\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        for crops, labels, _, _ in train_loader:\n",
    "            crops  = crops.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True).view(-1).long()\n",
    "\n",
    "            # warmup per-step (manual)\n",
    "            if global_step < warmup_steps:\n",
    "                warm = (global_step + 1) / warmup_steps\n",
    "                lr_now = eta_min + warm * (base_lr - eta_min)\n",
    "                for pg in optimizer.param_groups:\n",
    "                    pg[\"lr\"] = lr_now\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "                emb = model(crops)             # (B,D) normalized\n",
    "            loss = loss_fn(emb.float(), labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # stats\n",
    "            with torch.no_grad():\n",
    "                loss_val = float(loss.item())\n",
    "                lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "                sim = emb @ emb.t()\n",
    "                B = sim.size(0)\n",
    "                if B >= 2:\n",
    "                    sim.fill_diagonal_(-1e9)\n",
    "                    nn_idx = sim.argmax(dim=1)\n",
    "                    nn_labels = labels[nn_idx]\n",
    "                    acc_batch = (nn_labels == labels).float().mean().item()\n",
    "                else:\n",
    "                    acc_batch = 0.0\n",
    "\n",
    "                pos_m, neg_m, valid_frac = angular_batch_stats(emb, labels)\n",
    "\n",
    "            epoch_loss_sum += loss_val\n",
    "            n_batches += 1\n",
    "            acc_sum += acc_batch\n",
    "            n_acc += 1\n",
    "            pos_sum += pos_m\n",
    "            neg_sum += neg_m\n",
    "            valid_sum += valid_frac\n",
    "            n_stat += 1\n",
    "\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"step\": global_step,\n",
    "                    \"train/loss_step\": loss_val,\n",
    "                    \"train/lr\": lr_now,\n",
    "                    \"train/1nn_acc_batch\": acc_batch,\n",
    "                    \"train/pos_angle_mean\": pos_m,\n",
    "                    \"train/neg_angle_mean\": neg_m,\n",
    "                    \"train/valid_anchor_frac\": valid_frac,\n",
    "                },\n",
    "                step=global_step,\n",
    "            )\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        train_loss = epoch_loss_sum / max(1, n_batches)\n",
    "        train_acc  = acc_sum / max(1, n_acc)\n",
    "        train_pos  = pos_sum / max(1, n_stat)\n",
    "        train_neg  = neg_sum / max(1, n_stat)\n",
    "        train_valid = valid_sum / max(1, n_stat)\n",
    "\n",
    "        # MultiStepLR per-epoch (after warmup epoch(s)\n",
    "        if (epoch + 1) > int(cfg[\"warmup_epochs\"]):\n",
    "            step_scheduler.step()\n",
    "\n",
    "        # -------------------- VALIDATION --------------------\n",
    "        if val_reid_ds is not None:\n",
    "            val_stats = eval_infonce_val_epoch(\n",
    "                model=model,\n",
    "                loss_fn=loss_fn,\n",
    "                val_loader=val_loader,\n",
    "                device=device,\n",
    "                use_amp=use_amp,\n",
    "            )\n",
    "    \n",
    "            dt = time.time() - t0\n",
    "    \n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"train/loss_epoch\": train_loss,\n",
    "                    \"train/1nn_acc_epoch\": train_acc,\n",
    "                    \"train/pos_angle_mean_epoch\": train_pos,\n",
    "                    \"train/neg_angle_mean_epoch\": train_neg,\n",
    "                    \"train/valid_anchor_frac_epoch\": train_valid,\n",
    "                    \"val/loss\": val_stats[\"loss\"],\n",
    "                    \"val/1nn_acc\": val_stats[\"1nn_acc\"],\n",
    "                    \"val/pos_angle_mean\": val_stats[\"pos_angle_mean\"],\n",
    "                    \"val/neg_angle_mean\": val_stats[\"neg_angle_mean\"],\n",
    "                    \"val/valid_anchor_frac\": val_stats[\"valid_anchor_frac\"],\n",
    "                    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                    \"time/epoch_sec\": dt,\n",
    "                }\n",
    "            )\n",
    "    \n",
    "            print(\n",
    "                f\"[Epoch {epoch:02d}] \"\n",
    "                f\"train_loss={train_loss:.4f} | val_loss={val_stats['loss']:.4f} | \"\n",
    "                f\"val_1NN={val_stats['1nn_acc']:.4f} | lr={optimizer.param_groups[0]['lr']:.2e} | {dt:.1f}s\"\n",
    "            )\n",
    "\n",
    "        # -------------------- CKPT --------------------\n",
    "        if (epoch + 1) % int(save_every) == 0:\n",
    "            tag = \"af\" if cfg.get(\"init_from_arcface\", False) else \"scratch\"\n",
    "            ckpt_path = os.path.join(\n",
    "                save_dir,\n",
    "                f\"{run_name_prefix}_{tag}_P{P}K{K}_tau{int(cfg['temperature']*1000)}_epoch{epoch+1:02d}.pth\"\n",
    "            )\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"global_step\": global_step,\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"step_scheduler\": step_scheduler.state_dict(),\n",
    "                    \"scaler\": scaler.state_dict() if use_amp else None,\n",
    "                    \"config\": cfg,\n",
    "                    \"P\": P,\n",
    "                    \"K\": K,\n",
    "                },\n",
    "                ckpt_path,\n",
    "            )\n",
    "            print(f\"[CKPT] Saved {ckpt_path}\")\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "def run_grid_supinfonce(\n",
    "    train_reid_ds,\n",
    "    val_reid_ds,\n",
    "    device: str,\n",
    "    grid: List[Dict[str, Any]],\n",
    "    num_workers: int = 2,\n",
    "    use_amp: bool = True,\n",
    "    wandb_project: str = \"person re-id valsplit\",\n",
    "    wandb_entity: str = \"unibo-ai\",\n",
    "    save_dir: str = \"./ckpts_supinfonce\",\n",
    "    save_every: int = 5,\n",
    "):\n",
    "    results = []\n",
    "    print(f\"[RUNS] Total SupInfoNCE runs: {len(grid)}\")\n",
    "\n",
    "    for i, cfg in enumerate(grid, 1):\n",
    "        cfg = copy.deepcopy(cfg)\n",
    "\n",
    "        # safety\n",
    "        if int(cfg[\"P\"]) * int(cfg[\"K\"]) <= 1:\n",
    "            raise ValueError(f\"Bad P,K: {cfg['P']} {cfg['K']}\")\n",
    "\n",
    "        if bool(cfg.get(\"init_from_arcface\", False)) and not cfg.get(\"arc_ckpt_path\", None):\n",
    "            raise ValueError(\"init_from_arcface=True but arc_ckpt_path is missing.\")\n",
    "\n",
    "        print(f\"\\n[RUN {i}/{len(grid)}] {cfg}\")\n",
    "\n",
    "        out = train_one_supinfonce(\n",
    "            cfg=cfg,\n",
    "            train_reid_ds=train_reid_ds,\n",
    "            val_reid_ds=val_reid_ds,\n",
    "            device=device,\n",
    "            num_workers=num_workers,\n",
    "            use_amp=use_amp,\n",
    "            wandb_project=wandb_project,\n",
    "            wandb_entity=wandb_entity,\n",
    "            save_dir=save_dir,\n",
    "            save_every=save_every,\n",
    "        )\n",
    "\n",
    "        results.append(out)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def supinfonce_grid() -> List[Dict[str, Any]]:\n",
    "    base = dict(\n",
    "        lr=3e-4,\n",
    "        weight_decay=1e-4,\n",
    "        epochs=20,\n",
    "        warmup_epochs=1,\n",
    "        eta_min=1e-6,\n",
    "        milestones=[16],\n",
    "        gamma=0.1,\n",
    "        seed=42,\n",
    "        emb_dim=512,\n",
    "        P=16,\n",
    "        K=4,\n",
    "        init_from_arcface=True,\n",
    "        arc_ckpt_path=\"/kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch05.pth\",\n",
    "    )\n",
    "\n",
    "    temps = [0.05, 0.07, 0.1]\n",
    "    runs = []\n",
    "    for t in temps:\n",
    "        cfg = dict(base)\n",
    "        cfg.update(temperature=t)\n",
    "        runs.append(cfg)\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-02-08T16:16:36.692865Z",
     "iopub.status.busy": "2026-02-08T16:16:36.692332Z",
     "iopub.status.idle": "2026-02-08T16:36:22.553595Z",
     "shell.execute_reply": "2026-02-08T16:36:22.552862Z",
     "shell.execute_reply.started": "2026-02-08T16:16:36.692835Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUNS] Total SupInfoNCE runs: 3\n",
      "\n",
      "[RUN 1/3] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'eta_min': 1e-06, 'milestones': [16], 'gamma': 0.1, 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'init_from_arcface': True, 'arc_ckpt_path': '/kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth', 'temperature': 0.05}\n",
      "[INIT] Loaded 320/320 params from /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_161934-oqlzgexv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/oqlzgexv' target=\"_blank\">reid_r50_supinfonce_af_P16K4_tau50</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/oqlzgexv' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/oqlzgexv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train_loss=1.7250 | val_loss=2.6701 | val_1NN=0.9115 | lr=3.00e-04 | 11.3s\n",
      "[Epoch 01] train_loss=1.4106 | val_loss=1.9840 | val_1NN=0.9531 | lr=3.00e-04 | 11.0s\n",
      "[Epoch 02] train_loss=1.2883 | val_loss=1.8571 | val_1NN=0.9375 | lr=3.00e-04 | 11.0s\n",
      "[Epoch 03] train_loss=1.2480 | val_loss=1.7103 | val_1NN=0.9688 | lr=3.00e-04 | 11.3s\n",
      "[Epoch 04] train_loss=1.2157 | val_loss=1.7483 | val_1NN=0.9635 | lr=3.00e-04 | 11.0s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau50_epoch05.pth\n",
      "[Epoch 05] train_loss=1.2220 | val_loss=1.7293 | val_1NN=0.9583 | lr=3.00e-04 | 11.1s\n",
      "[Epoch 06] train_loss=1.2125 | val_loss=1.7706 | val_1NN=0.9479 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 07] train_loss=1.1906 | val_loss=1.7928 | val_1NN=0.9635 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 08] train_loss=1.1827 | val_loss=1.6944 | val_1NN=0.9583 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 09] train_loss=1.1820 | val_loss=1.7863 | val_1NN=0.9323 | lr=3.00e-04 | 10.7s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau50_epoch10.pth\n",
      "[Epoch 10] train_loss=1.1756 | val_loss=1.7232 | val_1NN=0.9635 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 11] train_loss=1.1786 | val_loss=1.8319 | val_1NN=0.9688 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 12] train_loss=1.1672 | val_loss=1.8168 | val_1NN=0.9635 | lr=3.00e-04 | 11.1s\n",
      "[Epoch 13] train_loss=1.1677 | val_loss=1.8122 | val_1NN=0.9427 | lr=3.00e-04 | 11.1s\n",
      "[Epoch 14] train_loss=1.1644 | val_loss=1.6873 | val_1NN=0.9479 | lr=3.00e-04 | 11.0s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau50_epoch15.pth\n",
      "[Epoch 15] train_loss=1.1612 | val_loss=1.8038 | val_1NN=0.9479 | lr=3.00e-04 | 11.0s\n",
      "[Epoch 16] train_loss=1.1594 | val_loss=1.6481 | val_1NN=0.9635 | lr=3.00e-05 | 11.0s\n",
      "[Epoch 17] train_loss=1.1600 | val_loss=1.7555 | val_1NN=0.9688 | lr=3.00e-05 | 10.7s\n",
      "[Epoch 18] train_loss=1.1539 | val_loss=1.6732 | val_1NN=0.9479 | lr=3.00e-05 | 10.7s\n",
      "[Epoch 19] train_loss=1.1567 | val_loss=1.8475 | val_1NN=0.9479 | lr=3.00e-05 | 10.7s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau50_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>time/epoch_sec</td><td></td></tr><tr><td>train/1nn_acc_batch</td><td></td></tr><tr><td>train/1nn_acc_epoch</td><td></td></tr><tr><td>train/loss_epoch</td><td></td></tr><tr><td>train/loss_step</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/neg_angle_mean</td><td></td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>step</td><td>399</td></tr><tr><td>time/epoch_sec</td><td>10.7344</td></tr><tr><td>train/1nn_acc_batch</td><td>1</td></tr><tr><td>train/1nn_acc_epoch</td><td>0.99922</td></tr><tr><td>train/loss_epoch</td><td>1.15671</td></tr><tr><td>train/loss_step</td><td>1.15743</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/neg_angle_mean</td><td>1.05881</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_supinfonce_af_P16K4_tau50</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/oqlzgexv' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/oqlzgexv</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_161934-oqlzgexv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 2/3] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'eta_min': 1e-06, 'milestones': [16], 'gamma': 0.1, 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'init_from_arcface': True, 'arc_ckpt_path': '/kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth', 'temperature': 0.07}\n",
      "[INIT] Loaded 320/320 params from /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_162606-facmqzqm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/facmqzqm' target=\"_blank\">reid_r50_supinfonce_af_P16K4_tau70</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/facmqzqm' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/facmqzqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train_loss=1.4617 | val_loss=2.2257 | val_1NN=0.9115 | lr=3.00e-04 | 11.1s\n",
      "[Epoch 01] train_loss=1.3236 | val_loss=1.9204 | val_1NN=0.9583 | lr=3.00e-04 | 10.6s\n",
      "[Epoch 02] train_loss=1.2658 | val_loss=1.8355 | val_1NN=0.9427 | lr=3.00e-04 | 10.6s\n",
      "[Epoch 03] train_loss=1.2364 | val_loss=1.7052 | val_1NN=0.9635 | lr=3.00e-04 | 10.8s\n",
      "[Epoch 04] train_loss=1.2111 | val_loss=1.7372 | val_1NN=0.9531 | lr=3.00e-04 | 10.8s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau70_epoch05.pth\n",
      "[Epoch 05] train_loss=1.2189 | val_loss=1.7286 | val_1NN=0.9635 | lr=3.00e-04 | 10.8s\n",
      "[Epoch 06] train_loss=1.2096 | val_loss=1.7368 | val_1NN=0.9375 | lr=3.00e-04 | 10.7s\n",
      "[Epoch 07] train_loss=1.1940 | val_loss=1.7683 | val_1NN=0.9531 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 08] train_loss=1.1851 | val_loss=1.7183 | val_1NN=0.9479 | lr=3.00e-04 | 10.8s\n",
      "[Epoch 09] train_loss=1.1869 | val_loss=1.8073 | val_1NN=0.9115 | lr=3.00e-04 | 10.6s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau70_epoch10.pth\n",
      "[Epoch 10] train_loss=1.1768 | val_loss=1.7389 | val_1NN=0.9635 | lr=3.00e-04 | 10.6s\n",
      "[Epoch 11] train_loss=1.1774 | val_loss=1.8552 | val_1NN=0.9583 | lr=3.00e-04 | 11.0s\n",
      "[Epoch 12] train_loss=1.1685 | val_loss=1.7965 | val_1NN=0.9427 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 13] train_loss=1.1708 | val_loss=1.8001 | val_1NN=0.9427 | lr=3.00e-04 | 10.8s\n",
      "[Epoch 14] train_loss=1.1724 | val_loss=1.6689 | val_1NN=0.9375 | lr=3.00e-04 | 10.9s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau70_epoch15.pth\n",
      "[Epoch 15] train_loss=1.1676 | val_loss=1.8110 | val_1NN=0.9323 | lr=3.00e-04 | 10.6s\n",
      "[Epoch 16] train_loss=1.1599 | val_loss=1.6689 | val_1NN=0.9531 | lr=3.00e-05 | 10.8s\n",
      "[Epoch 17] train_loss=1.1661 | val_loss=1.7521 | val_1NN=0.9583 | lr=3.00e-05 | 10.8s\n",
      "[Epoch 18] train_loss=1.1598 | val_loss=1.6963 | val_1NN=0.9479 | lr=3.00e-05 | 10.5s\n",
      "[Epoch 19] train_loss=1.1602 | val_loss=1.8584 | val_1NN=0.9531 | lr=3.00e-05 | 10.5s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau70_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>time/epoch_sec</td><td></td></tr><tr><td>train/1nn_acc_batch</td><td></td></tr><tr><td>train/1nn_acc_epoch</td><td></td></tr><tr><td>train/loss_epoch</td><td></td></tr><tr><td>train/loss_step</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/neg_angle_mean</td><td></td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>step</td><td>399</td></tr><tr><td>time/epoch_sec</td><td>10.53212</td></tr><tr><td>train/1nn_acc_batch</td><td>1</td></tr><tr><td>train/1nn_acc_epoch</td><td>0.99922</td></tr><tr><td>train/loss_epoch</td><td>1.1602</td></tr><tr><td>train/loss_step</td><td>1.15295</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/neg_angle_mean</td><td>1.27941</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_supinfonce_af_P16K4_tau70</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/facmqzqm' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/facmqzqm</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_162606-facmqzqm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 3/3] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'eta_min': 1e-06, 'milestones': [16], 'gamma': 0.1, 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'init_from_arcface': True, 'arc_ckpt_path': '/kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth', 'temperature': 0.1}\n",
      "[INIT] Loaded 320/320 params from /kaggle/input/arcface-weights-vs/r50_arcface_m25_s30_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260208_163232-jl3kbydl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/jl3kbydl' target=\"_blank\">reid_r50_supinfonce_af_P16K4_tau100</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/jl3kbydl' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/jl3kbydl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train_loss=1.3225 | val_loss=2.0418 | val_1NN=0.9062 | lr=3.00e-04 | 10.8s\n",
      "[Epoch 01] train_loss=1.2863 | val_loss=1.8623 | val_1NN=0.9479 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 02] train_loss=1.2539 | val_loss=1.8180 | val_1NN=0.9427 | lr=3.00e-04 | 11.2s\n",
      "[Epoch 03] train_loss=1.2362 | val_loss=1.6989 | val_1NN=0.9740 | lr=3.00e-04 | 11.2s\n",
      "[Epoch 04] train_loss=1.2132 | val_loss=1.7323 | val_1NN=0.9583 | lr=3.00e-04 | 11.1s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau100_epoch05.pth\n",
      "[Epoch 05] train_loss=1.2198 | val_loss=1.7354 | val_1NN=0.9635 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 06] train_loss=1.2120 | val_loss=1.7302 | val_1NN=0.9427 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 07] train_loss=1.2003 | val_loss=1.7632 | val_1NN=0.9583 | lr=3.00e-04 | 11.0s\n",
      "[Epoch 08] train_loss=1.1900 | val_loss=1.7130 | val_1NN=0.9427 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 09] train_loss=1.1910 | val_loss=1.7728 | val_1NN=0.9167 | lr=3.00e-04 | 11.1s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau100_epoch10.pth\n",
      "[Epoch 10] train_loss=1.1818 | val_loss=1.7436 | val_1NN=0.9583 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 11] train_loss=1.1886 | val_loss=1.8101 | val_1NN=0.9479 | lr=3.00e-04 | 11.1s\n",
      "[Epoch 12] train_loss=1.1759 | val_loss=1.7527 | val_1NN=0.9427 | lr=3.00e-04 | 10.9s\n",
      "[Epoch 13] train_loss=1.1786 | val_loss=1.7794 | val_1NN=0.9531 | lr=3.00e-04 | 11.1s\n",
      "[Epoch 14] train_loss=1.1772 | val_loss=1.6839 | val_1NN=0.9531 | lr=3.00e-04 | 11.2s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau100_epoch15.pth\n",
      "[Epoch 15] train_loss=1.1694 | val_loss=1.7930 | val_1NN=0.9323 | lr=3.00e-04 | 11.1s\n",
      "[Epoch 16] train_loss=1.1703 | val_loss=1.6779 | val_1NN=0.9531 | lr=3.00e-05 | 11.1s\n",
      "[Epoch 17] train_loss=1.1618 | val_loss=1.7473 | val_1NN=0.9531 | lr=3.00e-05 | 11.2s\n",
      "[Epoch 18] train_loss=1.1629 | val_loss=1.7097 | val_1NN=0.9479 | lr=3.00e-05 | 11.1s\n",
      "[Epoch 19] train_loss=1.1668 | val_loss=1.8557 | val_1NN=0.9219 | lr=3.00e-05 | 10.9s\n",
      "[CKPT] Saved ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau100_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>time/epoch_sec</td><td></td></tr><tr><td>train/1nn_acc_batch</td><td></td></tr><tr><td>train/1nn_acc_epoch</td><td></td></tr><tr><td>train/loss_epoch</td><td></td></tr><tr><td>train/loss_step</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/neg_angle_mean</td><td></td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>step</td><td>399</td></tr><tr><td>time/epoch_sec</td><td>10.85811</td></tr><tr><td>train/1nn_acc_batch</td><td>1</td></tr><tr><td>train/1nn_acc_epoch</td><td>0.99922</td></tr><tr><td>train/loss_epoch</td><td>1.16681</td></tr><tr><td>train/loss_step</td><td>1.16467</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/neg_angle_mean</td><td>1.54468</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_supinfonce_af_P16K4_tau100</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/jl3kbydl' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/jl3kbydl</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_163232-jl3kbydl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = supinfonce_grid()\n",
    "\n",
    "results = run_grid_supinfonce(\n",
    "    train_reid_ds=train_reid_ds,\n",
    "    val_reid_ds=val_reid_ds,\n",
    "    device=device,\n",
    "    grid=grid,\n",
    "    num_workers=4,      \n",
    "    use_amp=True,\n",
    "    wandb_project=\"person re-id valsplit\",\n",
    "    wandb_entity=\"unibo-ai\",\n",
    "    save_dir=\"./ckpts_supinfonce\",\n",
    "    save_every=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:42:17.866749Z",
     "iopub.status.busy": "2026-02-08T16:42:17.866367Z",
     "iopub.status.idle": "2026-02-08T16:53:24.754290Z",
     "shell.execute_reply": "2026-02-08T16:53:24.753491Z",
     "shell.execute_reply.started": "2026-02-08T16:42:17.866710Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will evaluate SupInfoNCE:\n",
      "  tau=0.05 | epoch=20 -> ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau50_epoch20.pth\n",
      "  tau=0.07 | epoch=20 -> ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau70_epoch20.pth\n",
      "  tau=0.1 | epoch=20 -> ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau100_epoch20.pth\n",
      "\n",
      "[Eval] Loading checkpoint: ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau50_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 54.31%\n",
      "  top- 1 = 84.48%\n",
      "[DONE] tau=0.05 | epoch=20 -> mAP=0.5431 | top1=0.8448\n",
      "\n",
      "[Eval] Loading checkpoint: ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau70_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 53.47%\n",
      "  top- 1 = 84.48%\n",
      "[DONE] tau=0.07 | epoch=20 -> mAP=0.5347 | top1=0.8448\n",
      "\n",
      "[Eval] Loading checkpoint: ./ckpts_supinfonce/reid_r50_supinfonce_af_P16K4_tau100_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 50.63%\n",
      "  top- 1 = 86.21%\n",
      "[DONE] tau=0.1 | epoch=20 -> mAP=0.5063 | top1=0.8621\n",
      "\n",
      "Summary (mAP/top-1):\n",
      "tau=0.05 | epoch=20 | mAP=0.5431 | top1=0.8448\n",
      "tau=0.07 | epoch=20 | mAP=0.5347 | top1=0.8448\n",
      "tau= 0.1 | epoch=20 | mAP=0.5063 | top1=0.8621\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Eval SupInfoNCE (ArcFace init + InfoNCE) @ epoch 20\n",
    "# taus: 0.05, 0.07, 0.10\n",
    "# ==========================\n",
    "taus = [0.05, 0.07, 0.10]\n",
    "epoch = 20\n",
    "\n",
    "run_name_prefix = \"reid_r50_supinfonce\"   \n",
    "save_dir = \"./ckpts_supinfonce\"          \n",
    "tag = \"af\"                               \n",
    "\n",
    "P, K = 16, 4\n",
    "emb_dim = 512\n",
    "\n",
    "def build_model_infonce(emb_dim: int):\n",
    "    # InfoNCE training uses embedding-only model for retrieval\n",
    "    return ReIDNetEmbed(emb_dim=emb_dim)\n",
    "\n",
    "# Build ckpt list\n",
    "ckpt_items = []\n",
    "for tau in taus:\n",
    "    tau_tag = int(tau * 1000)  # 0.07 -> 70\n",
    "    ckpt_path = f\"{save_dir}/{run_name_prefix}_{tag}_P{P}K{K}_tau{tau_tag}_epoch{epoch:02d}.pth\"\n",
    "    ckpt_items.append((tau, epoch, ckpt_path))\n",
    "\n",
    "print(\"Will evaluate SupInfoNCE:\")\n",
    "for tau, e, p in ckpt_items:\n",
    "    print(f\"  tau={tau} | epoch={e} -> {p}\")\n",
    "\n",
    "# Run eval\n",
    "results_infonce = {}  # key: (tau, epoch)\n",
    "for tau, e, ckpt_path in ckpt_items:\n",
    "    model = build_model_infonce(emb_dim=emb_dim).to(device)\n",
    "\n",
    "    ret = eval_prw_validation_person_search(\n",
    "        ckpt_path=ckpt_path,\n",
    "        model=model,\n",
    "        val_view=val_view,\n",
    "        val_ds=det_train_ds,                 # gallery dataset (train split)\n",
    "        val_detections=train_detections,     # detections computed on det_train_ds\n",
    "        transform=test_reid_tf,\n",
    "        device=device,\n",
    "        det_thresh=0.3,\n",
    "        ignore_cam_id=True,\n",
    "    )\n",
    "\n",
    "    results_infonce[(tau, e)] = ret\n",
    "    print(f\"[DONE] tau={tau} | epoch={e:02d} -> mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nSummary (mAP/top-1):\")\n",
    "for (tau, e), ret in sorted(results_infonce.items(), key=lambda x: (x[0][0], x[0][1])):\n",
    "    print(f\"tau={tau:>4} | epoch={e:>2} | mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The best param for tau is 0.05!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InfoNCE + ArcFace + ConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:06:27.539733Z",
     "iopub.status.busy": "2026-02-10T12:06:27.539132Z",
     "iopub.status.idle": "2026-02-10T12:25:17.082205Z",
     "shell.execute_reply": "2026-02-10T12:25:17.081153Z",
     "shell.execute_reply.started": "2026-02-10T12:06:27.539705Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUNS] Total SupInfoNCE runs: 3\n",
      "\n",
      "[RUN 1/3] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'eta_min': 1e-06, 'milestones': [16], 'gamma': 0.1, 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'init_from_arcface': True, 'arc_ckpt_path': '/kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch05.pth', 'temperature': 0.05}\n",
      "[INIT] Loaded 1/320 params from /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch05.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260210_120908-h17lvgu7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/h17lvgu7' target=\"_blank\">reid_r50_supinfonce_af_P16K4_tau50</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/h17lvgu7' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/h17lvgu7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train_loss=3.7695 | val_loss=3.0816 | val_1NN=0.6198 | lr=3.00e-04 | 10.7s\n",
      "[Epoch 01] train_loss=2.7240 | val_loss=2.3003 | val_1NN=0.8229 | lr=3.00e-04 | 10.5s\n",
      "[Epoch 02] train_loss=2.1855 | val_loss=2.1596 | val_1NN=0.8594 | lr=3.00e-04 | 10.7s\n",
      "[Epoch 03] train_loss=2.0082 | val_loss=2.0262 | val_1NN=0.8958 | lr=3.00e-04 | 10.8s\n",
      "[Epoch 04] train_loss=1.8314 | val_loss=1.9312 | val_1NN=0.9010 | lr=3.00e-04 | 10.7s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau50_epoch05.pth\n",
      "[Epoch 05] train_loss=1.7593 | val_loss=1.9123 | val_1NN=0.9062 | lr=3.00e-04 | 10.5s\n",
      "[Epoch 06] train_loss=1.7761 | val_loss=1.8786 | val_1NN=0.9167 | lr=3.00e-04 | 10.3s\n",
      "[Epoch 07] train_loss=1.6355 | val_loss=1.8321 | val_1NN=0.9323 | lr=3.00e-04 | 10.5s\n",
      "[Epoch 08] train_loss=1.5872 | val_loss=1.7330 | val_1NN=0.9479 | lr=3.00e-04 | 10.5s\n",
      "[Epoch 09] train_loss=1.5749 | val_loss=1.8194 | val_1NN=0.9323 | lr=3.00e-04 | 10.2s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau50_epoch10.pth\n",
      "[Epoch 10] train_loss=1.5555 | val_loss=1.7857 | val_1NN=0.9271 | lr=3.00e-04 | 10.4s\n",
      "[Epoch 11] train_loss=1.5289 | val_loss=1.7828 | val_1NN=0.9479 | lr=3.00e-04 | 10.6s\n",
      "[Epoch 12] train_loss=1.4903 | val_loss=1.7572 | val_1NN=0.9375 | lr=3.00e-04 | 10.6s\n",
      "[Epoch 13] train_loss=1.4704 | val_loss=1.7231 | val_1NN=0.9427 | lr=3.00e-04 | 10.5s\n",
      "[Epoch 14] train_loss=1.4627 | val_loss=1.6440 | val_1NN=0.9427 | lr=3.00e-04 | 10.5s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau50_epoch15.pth\n",
      "[Epoch 15] train_loss=1.4520 | val_loss=1.7434 | val_1NN=0.9375 | lr=3.00e-04 | 10.4s\n",
      "[Epoch 16] train_loss=1.3864 | val_loss=1.6833 | val_1NN=0.9271 | lr=3.00e-05 | 10.5s\n",
      "[Epoch 17] train_loss=1.4007 | val_loss=1.6707 | val_1NN=0.9583 | lr=3.00e-05 | 11.0s\n",
      "[Epoch 18] train_loss=1.3898 | val_loss=1.6690 | val_1NN=0.9479 | lr=3.00e-05 | 11.4s\n",
      "[Epoch 19] train_loss=1.3995 | val_loss=1.7555 | val_1NN=0.9062 | lr=3.00e-05 | 10.4s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau50_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>time/epoch_sec</td><td></td></tr><tr><td>train/1nn_acc_batch</td><td></td></tr><tr><td>train/1nn_acc_epoch</td><td></td></tr><tr><td>train/loss_epoch</td><td></td></tr><tr><td>train/loss_step</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/neg_angle_mean</td><td></td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>step</td><td>399</td></tr><tr><td>time/epoch_sec</td><td>10.36485</td></tr><tr><td>train/1nn_acc_batch</td><td>0.96875</td></tr><tr><td>train/1nn_acc_epoch</td><td>0.97969</td></tr><tr><td>train/loss_epoch</td><td>1.39946</td></tr><tr><td>train/loss_step</td><td>1.35553</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/neg_angle_mean</td><td>1.13504</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_supinfonce_af_P16K4_tau50</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/h17lvgu7' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/h17lvgu7</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260210_120908-h17lvgu7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 2/3] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'eta_min': 1e-06, 'milestones': [16], 'gamma': 0.1, 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'init_from_arcface': True, 'arc_ckpt_path': '/kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch05.pth', 'temperature': 0.07}\n",
      "[INIT] Loaded 1/320 params from /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch05.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260210_121533-gcem1xwt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/gcem1xwt' target=\"_blank\">reid_r50_supinfonce_af_P16K4_tau70</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/gcem1xwt' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/gcem1xwt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train_loss=3.6046 | val_loss=2.9660 | val_1NN=0.6458 | lr=3.00e-04 | 10.8s\n",
      "[Epoch 01] train_loss=2.6293 | val_loss=2.2403 | val_1NN=0.8281 | lr=3.00e-04 | 10.4s\n",
      "[Epoch 02] train_loss=2.1034 | val_loss=2.1753 | val_1NN=0.8490 | lr=3.00e-04 | 10.7s\n",
      "[Epoch 03] train_loss=1.9532 | val_loss=1.9482 | val_1NN=0.8854 | lr=3.00e-04 | 10.7s\n",
      "[Epoch 04] train_loss=1.7913 | val_loss=1.9212 | val_1NN=0.8594 | lr=3.00e-04 | 10.7s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau70_epoch05.pth\n",
      "[Epoch 05] train_loss=1.7155 | val_loss=1.8911 | val_1NN=0.9010 | lr=3.00e-04 | 10.5s\n",
      "[Epoch 06] train_loss=1.7279 | val_loss=1.8912 | val_1NN=0.9115 | lr=3.00e-04 | 10.6s\n",
      "[Epoch 07] train_loss=1.6255 | val_loss=1.8490 | val_1NN=0.9010 | lr=3.00e-04 | 10.4s\n",
      "[Epoch 08] train_loss=1.5552 | val_loss=1.7141 | val_1NN=0.9323 | lr=3.00e-04 | 10.3s\n",
      "[Epoch 09] train_loss=1.5504 | val_loss=1.7603 | val_1NN=0.9583 | lr=3.00e-04 | 10.2s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau70_epoch10.pth\n",
      "[Epoch 10] train_loss=1.5426 | val_loss=1.7296 | val_1NN=0.9323 | lr=3.00e-04 | 10.3s\n",
      "[Epoch 11] train_loss=1.5072 | val_loss=1.7446 | val_1NN=0.9740 | lr=3.00e-04 | 10.5s\n",
      "[Epoch 12] train_loss=1.4769 | val_loss=1.7898 | val_1NN=0.9427 | lr=3.00e-04 | 10.5s\n",
      "[Epoch 13] train_loss=1.4699 | val_loss=1.7698 | val_1NN=0.9219 | lr=3.00e-04 | 10.5s\n",
      "[Epoch 14] train_loss=1.4617 | val_loss=1.6411 | val_1NN=0.9375 | lr=3.00e-04 | 10.5s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau70_epoch15.pth\n",
      "[Epoch 15] train_loss=1.4417 | val_loss=1.7259 | val_1NN=0.9375 | lr=3.00e-04 | 10.4s\n",
      "[Epoch 16] train_loss=1.3816 | val_loss=1.6277 | val_1NN=0.9375 | lr=3.00e-05 | 10.5s\n",
      "[Epoch 17] train_loss=1.3803 | val_loss=1.6855 | val_1NN=0.9635 | lr=3.00e-05 | 10.4s\n",
      "[Epoch 18] train_loss=1.3762 | val_loss=1.6894 | val_1NN=0.9375 | lr=3.00e-05 | 10.5s\n",
      "[Epoch 19] train_loss=1.3889 | val_loss=1.7859 | val_1NN=0.9271 | lr=3.00e-05 | 10.5s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau70_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>time/epoch_sec</td><td></td></tr><tr><td>train/1nn_acc_batch</td><td></td></tr><tr><td>train/1nn_acc_epoch</td><td></td></tr><tr><td>train/loss_epoch</td><td></td></tr><tr><td>train/loss_step</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/neg_angle_mean</td><td></td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>step</td><td>399</td></tr><tr><td>time/epoch_sec</td><td>10.46512</td></tr><tr><td>train/1nn_acc_batch</td><td>0.96875</td></tr><tr><td>train/1nn_acc_epoch</td><td>0.98281</td></tr><tr><td>train/loss_epoch</td><td>1.3889</td></tr><tr><td>train/loss_step</td><td>1.33634</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/neg_angle_mean</td><td>1.33712</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_supinfonce_af_P16K4_tau70</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/gcem1xwt' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/gcem1xwt</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260210_121533-gcem1xwt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN 3/3] {'lr': 0.0003, 'weight_decay': 0.0001, 'epochs': 20, 'warmup_epochs': 1, 'eta_min': 1e-06, 'milestones': [16], 'gamma': 0.1, 'seed': 42, 'emb_dim': 512, 'P': 16, 'K': 4, 'init_from_arcface': True, 'arc_ckpt_path': '/kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch05.pth', 'temperature': 0.1}\n",
      "[INIT] Loaded 1/320 params from /kaggle/input/arcface-cx-weights/r50_arcface_cx_m25_s30_epoch05.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260210_122143-vf0otepy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/vf0otepy' target=\"_blank\">reid_r50_supinfonce_af_P16K4_tau100</a></strong> to <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/vf0otepy' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/vf0otepy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] train_loss=3.5808 | val_loss=2.9314 | val_1NN=0.6250 | lr=3.00e-04 | 10.3s\n",
      "[Epoch 01] train_loss=2.6116 | val_loss=2.2347 | val_1NN=0.8385 | lr=3.00e-04 | 10.4s\n",
      "[Epoch 02] train_loss=2.0733 | val_loss=2.1616 | val_1NN=0.8333 | lr=3.00e-04 | 10.3s\n",
      "[Epoch 03] train_loss=1.9386 | val_loss=1.9427 | val_1NN=0.8698 | lr=3.00e-04 | 10.2s\n",
      "[Epoch 04] train_loss=1.7797 | val_loss=1.8929 | val_1NN=0.8854 | lr=3.00e-04 | 10.1s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau100_epoch05.pth\n",
      "[Epoch 05] train_loss=1.7080 | val_loss=1.8765 | val_1NN=0.8958 | lr=3.00e-04 | 10.1s\n",
      "[Epoch 06] train_loss=1.7316 | val_loss=1.8757 | val_1NN=0.9167 | lr=3.00e-04 | 10.1s\n",
      "[Epoch 07] train_loss=1.6046 | val_loss=1.7519 | val_1NN=0.9219 | lr=3.00e-04 | 10.2s\n",
      "[Epoch 08] train_loss=1.5526 | val_loss=1.6576 | val_1NN=0.9531 | lr=3.00e-04 | 10.2s\n",
      "[Epoch 09] train_loss=1.5595 | val_loss=1.7608 | val_1NN=0.9375 | lr=3.00e-04 | 10.0s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau100_epoch10.pth\n",
      "[Epoch 10] train_loss=1.5175 | val_loss=1.8114 | val_1NN=0.9115 | lr=3.00e-04 | 10.1s\n",
      "[Epoch 11] train_loss=1.5037 | val_loss=1.8246 | val_1NN=0.9271 | lr=3.00e-04 | 10.2s\n",
      "[Epoch 12] train_loss=1.4620 | val_loss=1.7540 | val_1NN=0.9323 | lr=3.00e-04 | 10.2s\n",
      "[Epoch 13] train_loss=1.4654 | val_loss=1.7608 | val_1NN=0.9479 | lr=3.00e-04 | 10.3s\n",
      "[Epoch 14] train_loss=1.4521 | val_loss=1.5953 | val_1NN=0.9479 | lr=3.00e-04 | 10.2s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau100_epoch15.pth\n",
      "[Epoch 15] train_loss=1.4374 | val_loss=1.8010 | val_1NN=0.9323 | lr=3.00e-04 | 10.2s\n",
      "[Epoch 16] train_loss=1.3696 | val_loss=1.6231 | val_1NN=0.9427 | lr=3.00e-05 | 10.2s\n",
      "[Epoch 17] train_loss=1.3894 | val_loss=1.7020 | val_1NN=0.9375 | lr=3.00e-05 | 10.1s\n",
      "[Epoch 18] train_loss=1.3868 | val_loss=1.7168 | val_1NN=0.9635 | lr=3.00e-05 | 10.2s\n",
      "[Epoch 19] train_loss=1.3879 | val_loss=1.7732 | val_1NN=0.9062 | lr=3.00e-05 | 10.0s\n",
      "[CKPT] Saved ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau100_epoch20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>step</td><td></td></tr><tr><td>time/epoch_sec</td><td></td></tr><tr><td>train/1nn_acc_batch</td><td></td></tr><tr><td>train/1nn_acc_epoch</td><td></td></tr><tr><td>train/loss_epoch</td><td></td></tr><tr><td>train/loss_step</td><td></td></tr><tr><td>train/lr</td><td></td></tr><tr><td>train/neg_angle_mean</td><td></td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>step</td><td>399</td></tr><tr><td>time/epoch_sec</td><td>10.01115</td></tr><tr><td>train/1nn_acc_batch</td><td>0.98438</td></tr><tr><td>train/1nn_acc_epoch</td><td>0.98516</td></tr><tr><td>train/loss_epoch</td><td>1.38786</td></tr><tr><td>train/loss_step</td><td>1.35633</td></tr><tr><td>train/lr</td><td>3e-05</td></tr><tr><td>train/neg_angle_mean</td><td>1.57603</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">reid_r50_supinfonce_af_P16K4_tau100</strong> at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/vf0otepy' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit/runs/vf0otepy</a><br> View project at: <a href='https://wandb.ai/unibo-ai/person%20re-id%20valsplit' target=\"_blank\">https://wandb.ai/unibo-ai/person%20re-id%20valsplit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260210_122143-vf0otepy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = supinfonce_grid()\n",
    "\n",
    "results = run_grid_supinfonce(\n",
    "    train_reid_ds=train_reid_ds,\n",
    "    val_reid_ds=val_reid_ds,\n",
    "    device=device,\n",
    "    grid=grid,\n",
    "    num_workers=4,      \n",
    "    use_amp=True,\n",
    "    wandb_project=\"person re-id valsplit\",\n",
    "    wandb_entity=\"unibo-ai\",\n",
    "    save_dir=\"./ckpts_supinfonce_val_cx\",\n",
    "    save_every=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:36:57.115505Z",
     "iopub.status.busy": "2026-02-10T12:36:57.114292Z",
     "iopub.status.idle": "2026-02-10T12:47:37.637879Z",
     "shell.execute_reply": "2026-02-10T12:47:37.637125Z",
     "shell.execute_reply.started": "2026-02-10T12:36:57.115109Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will evaluate SupInfoNCE:\n",
      "  tau=0.05 | epoch=5 -> ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau50_epoch05.pth\n",
      "  tau=0.07 | epoch=5 -> ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau70_epoch05.pth\n",
      "  tau=0.1 | epoch=5 -> ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau100_epoch05.pth\n",
      "\n",
      "[Eval] Loading checkpoint: ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau50_epoch05.pth\n",
      "search ranking:\n",
      "  mAP = 37.42%\n",
      "  top- 1 = 82.76%\n",
      "[DONE] tau=0.05 | epoch=05 -> mAP=0.3742 | top1=0.8276\n",
      "\n",
      "[Eval] Loading checkpoint: ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau70_epoch05.pth\n",
      "search ranking:\n",
      "  mAP = 39.18%\n",
      "  top- 1 = 77.59%\n",
      "[DONE] tau=0.07 | epoch=05 -> mAP=0.3918 | top1=0.7759\n",
      "\n",
      "[Eval] Loading checkpoint: ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau100_epoch05.pth\n",
      "search ranking:\n",
      "  mAP = 39.92%\n",
      "  top- 1 = 77.59%\n",
      "[DONE] tau=0.1 | epoch=05 -> mAP=0.3992 | top1=0.7759\n",
      "\n",
      "Summary (mAP/top-1):\n",
      "tau=0.05 | epoch= 5 | mAP=0.3742 | top1=0.8276\n",
      "tau=0.07 | epoch= 5 | mAP=0.3918 | top1=0.7759\n",
      "tau= 0.1 | epoch= 5 | mAP=0.3992 | top1=0.7759\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Eval SupInfoNCE (ArcFace init + InfoNCE) @ epoch 20\n",
    "# taus: 0.05, 0.07, 0.10\n",
    "# ==========================\n",
    "taus = [0.05, 0.07, 0.10]\n",
    "epoch = 5\n",
    "\n",
    "run_name_prefix = \"reid_r50_supinfonce\"   \n",
    "save_dir = \"./ckpts_supinfonce_val_cx\"          \n",
    "tag = \"af\"                               \n",
    "\n",
    "P, K = 16, 4\n",
    "emb_dim = 512\n",
    "\n",
    "def build_model_infonce(emb_dim: int):\n",
    "    # InfoNCE training uses embedding-only model for retrieval\n",
    "    return ReIDNetEmbed(emb_dim=emb_dim)\n",
    "\n",
    "# Build ckpt list\n",
    "ckpt_items = []\n",
    "for tau in taus:\n",
    "    tau_tag = int(tau * 1000)  # 0.07 -> 70\n",
    "    ckpt_path = f\"{save_dir}/{run_name_prefix}_{tag}_P{P}K{K}_tau{tau_tag}_epoch{epoch:02d}.pth\"\n",
    "    ckpt_items.append((tau, epoch, ckpt_path))\n",
    "\n",
    "print(\"Will evaluate SupInfoNCE:\")\n",
    "for tau, e, p in ckpt_items:\n",
    "    print(f\"  tau={tau} | epoch={e} -> {p}\")\n",
    "\n",
    "# Run eval\n",
    "results_infonce = {}  # key: (tau, epoch)\n",
    "for tau, e, ckpt_path in ckpt_items:\n",
    "    model = build_model_infonce(emb_dim=emb_dim).to(device)\n",
    "\n",
    "    ret = eval_prw_validation_person_search(\n",
    "        ckpt_path=ckpt_path,\n",
    "        model=model,\n",
    "        val_view=val_view,\n",
    "        val_ds=det_train_ds,                 # gallery dataset (train split)\n",
    "        val_detections=train_detections,     # detections computed on det_train_ds\n",
    "        transform=test_reid_tf,\n",
    "        device=device,\n",
    "        det_thresh=0.3,\n",
    "        ignore_cam_id=True,\n",
    "    )\n",
    "\n",
    "    results_infonce[(tau, e)] = ret\n",
    "    print(f\"[DONE] tau={tau} | epoch={e:02d} -> mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nSummary (mAP/top-1):\")\n",
    "for (tau, e), ret in sorted(results_infonce.items(), key=lambda x: (x[0][0], x[0][1])):\n",
    "    print(f\"tau={tau:>4} | epoch={e:>2} | mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Very bad results! It seems the 5-epochs model is under-trained. Let's test with the model trained for 20 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:48:13.580414Z",
     "iopub.status.busy": "2026-02-10T12:48:13.579575Z",
     "iopub.status.idle": "2026-02-10T12:58:48.295382Z",
     "shell.execute_reply": "2026-02-10T12:58:48.294693Z",
     "shell.execute_reply.started": "2026-02-10T12:48:13.580381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will evaluate SupInfoNCE:\n",
      "  tau=0.05 | epoch=20 -> ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau50_epoch20.pth\n",
      "  tau=0.07 | epoch=20 -> ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau70_epoch20.pth\n",
      "  tau=0.1 | epoch=20 -> ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau100_epoch20.pth\n",
      "\n",
      "[Eval] Loading checkpoint: ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau50_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 48.38%\n",
      "  top- 1 = 86.21%\n",
      "[DONE] tau=0.05 | epoch=20 -> mAP=0.4838 | top1=0.8621\n",
      "\n",
      "[Eval] Loading checkpoint: ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau70_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 48.92%\n",
      "  top- 1 = 84.48%\n",
      "[DONE] tau=0.07 | epoch=20 -> mAP=0.4892 | top1=0.8448\n",
      "\n",
      "[Eval] Loading checkpoint: ./ckpts_supinfonce_val_cx/reid_r50_supinfonce_af_P16K4_tau100_epoch20.pth\n",
      "search ranking:\n",
      "  mAP = 47.27%\n",
      "  top- 1 = 81.03%\n",
      "[DONE] tau=0.1 | epoch=20 -> mAP=0.4727 | top1=0.8103\n",
      "\n",
      "Summary (mAP/top-1):\n",
      "tau=0.05 | epoch=20 | mAP=0.4838 | top1=0.8621\n",
      "tau=0.07 | epoch=20 | mAP=0.4892 | top1=0.8448\n",
      "tau= 0.1 | epoch=20 | mAP=0.4727 | top1=0.8103\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Eval SupInfoNCE (ArcFace init + InfoNCE) @ epoch 20\n",
    "# taus: 0.05, 0.07, 0.10\n",
    "# ==========================\n",
    "taus = [0.05, 0.07, 0.10]\n",
    "epoch = 20\n",
    "\n",
    "run_name_prefix = \"reid_r50_supinfonce\"   \n",
    "save_dir = \"./ckpts_supinfonce_val_cx\"     \n",
    "tag = \"af\"                               \n",
    "\n",
    "P, K = 16, 4\n",
    "emb_dim = 512\n",
    "# Build ckpt list\n",
    "ckpt_items = []\n",
    "for tau in taus:\n",
    "    tau_tag = int(tau * 1000)  # 0.07 -> 70\n",
    "    ckpt_path = f\"{save_dir}/{run_name_prefix}_{tag}_P{P}K{K}_tau{tau_tag}_epoch{epoch:02d}.pth\"\n",
    "    ckpt_items.append((tau, epoch, ckpt_path))\n",
    "\n",
    "print(\"Will evaluate SupInfoNCE:\")\n",
    "for tau, e, p in ckpt_items:\n",
    "    print(f\"  tau={tau} | epoch={e} -> {p}\")\n",
    "\n",
    "# Run eval\n",
    "results_infonce = {}  # key: (tau, epoch)\n",
    "for tau, e, ckpt_path in ckpt_items:\n",
    "    model = build_model_infonce(emb_dim=emb_dim).to(device)\n",
    "\n",
    "    ret = eval_prw_validation_person_search(\n",
    "        ckpt_path=ckpt_path,\n",
    "        model=model,\n",
    "        val_view=val_view,\n",
    "        val_ds=det_train_ds,                 # gallery dataset (train split)\n",
    "        val_detections=train_detections,     # detections computed on det_train_ds\n",
    "        transform=test_reid_tf,\n",
    "        device=device,\n",
    "        det_thresh=0.3,\n",
    "        ignore_cam_id=True,\n",
    "    )\n",
    "\n",
    "    results_infonce[(tau, e)] = ret\n",
    "    print(f\"[DONE] tau={tau} | epoch={e:02d} -> mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nSummary (mAP/top-1):\")\n",
    "for (tau, e), ret in sorted(results_infonce.items(), key=lambda x: (x[0][0], x[0][1])):\n",
    "    print(f\"tau={tau:>4} | epoch={e:>2} | mAP={ret['mAP']:.4f} | top1={ret['accs'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> On ConvNeXt, supervised InfoNCE keeps improving up to 20 epochs (val mAP: 0.37  0.48 from epoch 5 to 20), suggesting that longer fine-tuning (or a smaller LR / different schedule) could further improve results. Future work will explore extended fine-tuning (e.g., 4060 epochs) with early stopping and a tuned learning-rate schedule.\n",
    "> \n",
    ">> This is probably due to an over-regularization issue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final considerations\n",
    "All the experiments and their quantitaive results with the best models can be summarized with the following table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model             | Backbone      | Training recipe      | Epoch |       mAP | Top-1 |\n",
    "| ----------------- | ------------- | -------------------- | ----: | --------: | ----: |\n",
    "| ArcFace           | ResNet50      | ArcFace              |    20 | **0.531** | 0.879 |\n",
    "| ArcFace           | ConvNeXt-Tiny | ArcFace              |     5 | **0.607** | 0.897 |\n",
    "| ArcFace  InfoNCE | ResNet50      | ArcFace + SupInfoNCE |    20 | **0.543** | 0.845 |\n",
    "| ArcFace  InfoNCE | ConvNeXt-Tiny | ArcFace + SupInfoNCE |    20 | **0.484** | 0.862 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More general validation phase considerations\n",
    "\n",
    "During the validation phase, multiple loss functions and training configurations were evaluated, including standard softmax classification, CosFace, and ArcFace.\n",
    "\n",
    "#### Softmax\n",
    "\n",
    "The standard softmax loss treats re-identification as a closed-set classification problem. While it provides stable convergence, it does not explicitly enforce geometric constraints in the embedding space. As a result:\n",
    "\n",
    "- intra-class compactness is not directly controlled,\n",
    "\n",
    "- inter-class separation depends solely on linear decision boundaries,\n",
    "\n",
    "- generalization to unseen identities is limited.\n",
    "\n",
    "In practice, validation results showed that Softmax achieved reasonable performance but consistently underperformed compared to margin-based losses in terms of mAP.\n",
    "\n",
    "#### CosFace\n",
    "\n",
    "CosFace introduces an additive cosine margin, enforcing a stronger separation between classes directly in cosine space. Compared to Softmax, it better shapes the embedding geometry by increasing inter-class margins.\n",
    "\n",
    "However, CosFace operates in cosine space rather than strictly angular space. Although it improves discrimination, its margin formulation is slightly less geometrically consistent than ArcFace in hyperspherical embedding spaces.\n",
    "\n",
    "Validation results showed improvements over Softmax, but performance remained slightly below ArcFace in terms of mAP stability and ranking consistency.\n",
    "\n",
    "#### ArcFace\n",
    "\n",
    "ArcFace introduces an additive angular margin, directly manipulating the angle between feature vectors and class weights. This produces a more interpretable and well-structured embedding space:\n",
    "\n",
    "- tighter intra-class clusters,\n",
    "\n",
    "- clearer angular separation between identities,\n",
    "\n",
    "- better alignment with cosine-based retrieval.\n",
    "\n",
    "Across validation experiments, ArcFace consistently achieved the best balance between mAP and Top-1 accuracy, particularly when combined with stronger backbones. It also showed more stable behavior across epochs compared to alternative formulations.\n",
    "\n",
    "#### Why ArcFace Was Selected\n",
    "\n",
    "Based on validation performance:\n",
    "\n",
    "ArcFace provided the most consistent improvements in mAP.\n",
    "\n",
    "- It demonstrated better ranking behavior, especially in medium-rank retrieval.\n",
    "\n",
    "- Its geometric formulation aligns naturally with cosine similarity used during inference.\n",
    "\n",
    "For these reasons, ArcFace was selected as the primary loss function for subsequent backbone and training recipe ablations."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8908164,
     "sourceId": 13973040,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9271237,
     "sourceId": 14515974,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9421117,
     "sourceId": 14741572,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9428607,
     "sourceId": 14752233,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9430040,
     "sourceId": 14754193,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9430223,
     "sourceId": 14754433,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9453794,
     "sourceId": 14787782,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
